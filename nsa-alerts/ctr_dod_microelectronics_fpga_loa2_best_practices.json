{
  "markdown": " \n \n \n \nNational Security Agency  \nCybersecurity  Technical Report  \n \n \n \n \n \nDoD Microelectronics:  \nField Programmable Gate Array  \nLevel of Assurance 2  Best Practices  \n \n \n \n \nFebruary  2023 \n \nU/OO/ 120910 -23 \nPP-23-0199  \nVersion 1.0 \n \n \n \n \n  \n\n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  ii \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n \n For additional information, guidance, or assistance with this \ndocument, please contact the Joint Federated Assurance Center \n(JFAC) at https://jfac.navy.mil . \n  \n  \n\n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  iii \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nNotices and history   \nDocument change history  \nDate  Version  Description  \nFEB 2023  1.0 Initial Publication  \n   \nDisclaimer of warranties and endorsement  \nThe information and opinions containe d in this document are provided \"as is\" and without any warranties \nor guarantees. Reference herein to any specific commercial products, process, or service by trade name, \ntrademark, manufacturer, or otherwise, does not constitute or imply its endorsement, recommendation, or \nfavoring by the Unite d States Government, and this guidance shall not be used for advertising or product \nendorsement purposes.  \nPublication information  \nAuthor(s)   \nNational Security Agency  \nCybersecurity Directorate  \nJoint Federated Assurance Center  \nContact information  \nJoint Fede rated Assurance Center: https://jfac.navy.mil   \nCybersecurity Report Feedback / General Cybersecurity Inquiries: CybersecurityReports@nsa.gov   \nDefense Industrial Base Inquiries and Cybersecurity Services: DIB_Defense@cyber.nsa.gov   \nMedia inquiries / Press Desk: Media Relations, 443-634-0721, MediaRelati ons@nsa.gov   \nPurpose  \nThis document was developed in furtherance of NSAs cybersecurity missions . This  includ es its \nresponsibilities to identify and disseminate threats to National Security Systems, Department of Defense \ninformation systems, and the Defense  Industrial Base, and to develop and issue cybersecurity \nspecifications and mitigations. This information may be shared broadly to reach all appropriate \nstakeholders.   \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  iv \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nExecutive summary  \nIn support of securing Field Programmable Gate Array (FPGA)  based systems from \nadversary influence during the manufacturing process, this report outlines  the \ncategories of relevant threats and the best practices for mitigating them at Level of \nAssurance 2 (LoA2). LoA2 captures the threats most lik ely to be exercise d against a \nDoD system based upon their cost and high value of return. This level is defined as \ncausing serious harm to U.S. personnel, property, or interests if the systems fails.  At \nthis level, these threats have the following characteristics:  \n Access   Exploit a difficult point of access  or multiple points of access.  Difficult \nincludes a single cleared insider.  \n Technology   Use of technology with low risks from implementation . Technology \nmay not  be accessible commercially but proven technology.  \n Investment   Require a large multidisciplinary team.  \n Value of effect   Establish vulnerabilities  for future exploitation.  \n Targetability   Affect only a subset of systems . \nOrganized by threat, this report provides  multiple technical mitigations to choose from to \naddress each threat  and to allow the user the best fit for their program needs. The \nfollowing table identifies the ten threat descriptions (TD) addressed by this guidance.  \n# Threat description (TD)  \nTD 1  Adversary utilizes a known FPGA platform vulnerability  \nTD 2  Adversary inserts malicious counterfeit  \nTD 3  Adversary compromises application design cycle  \nTD 4  Adversary compromises system assembly, keying, or provisioning  \nTD 5  Adversary compromises third -party soft intellectual property (IP)  \nTD 6  Adversary swaps configuration file on target  \nTD 7  Adversary substitutes modified FPGA software design suite  \nTD 8  Adversary modifies FPGA platform family at design  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  v \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n# Threat description (TD)  \nTD 9  Adversary compromises single -board computing system (SBCS)  \nTD 10  Adversary modifies vendor FPGA software design suite during \ndevelopment  \nEach subsection in this report contains mitigations described in detail to enable clear \nimplementation. Secondary documents are referenced in cases where the suggested \nmitigation is highly detailed, specific to individual FPGA platforms, or subject to frequent \nchange.  Appendix C, Checklists and Data Requirements  contains a quick reference \nlist of threats , associated mitigations , and associated documentation . \nOnce the program has mitigated these threats, they  have achieved an assurance level \nof LoA2.  \n  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  vi \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nContents  \nDoD Microelectronics: Field Programmable Gate Array Level of Assurance 2 \nBest Practices  ................................ ................................ ................................ ............................. i \nExecutive summary  ................................ ................................ ................................ ......................  iv \nContents  ................................ ................................ ................................ ................................ ...... vi \n1 Overview of Level of Assurance 2 threats and mitigations  ................................ ..................  1 \n1.1 Complementary standards and guidance  ................................ ................................ ................................ . 4 \n1.2 Exclusions  ................................ ................................ ................................ ................................ .............................  5 \n1.3 Document use  ................................ ................................ ................................ ................................ ................  5 \n1.4 General Comments on Mitigations  ................................ ................................ ................................ ..............  6 \n2 Threat descriptions (TD)  ................................ ................................ ................................ ...........  7 \nTD 1: Adversary utilizes a known FPGA platform vulnerability  ................................ ..............  7 \nTD 1 mitigations  ................................ ................................ ................................ ................................ ..........................  7 \nTD 1 mitigation descriptions  ................................ ................................ ................................ ................................ .. 8 \nUse caution when selecting tools or platforms  ................................ ................................ ..........................  8 \nUse cleared personnel  ................................ ................................ ................................ ................................ ........ 8 \nResearch vulnerabilities  ................................ ................................ ................................ ................................ ...... 8 \nUse revision control/version management  ................................ ................................ ................................ .. 9 \nEnforce auditability  ................................ ................................ ................................ ................................ .............  10 \nEnforce approved design process  ................................ ................................ ................................ ................  10 \nTD 2: Adversary inserts malicious counterfeit  ................................ ................................ ....... 10 \nTD 2 mitigations  ................................ ................................ ................................ ................................ ........................  12 \nTD 2 mitigation descriptions  ................................ ................................ ................................ ................................  12 \nPurchase from DoD -authorized vendors and distributors  ................................ ................................ ... 12 \nConsult GIDEP  ................................ ................................ ................................ ................................ .....................  12 \nFollow storage and shipping guidance  ................................ ................................ ................................ ....... 12 \nVerify FPGA crypto graphically secure identifiers  ................................ ................................ ...................  13 \nPerform physical inspection/analysis  ................................ ................................ ................................ ..........  15 \nMitigate risk of a cleared insider  ................................ ................................ ................................ ....................  19 \nTD 3: Adversary compromises application design cycle  ................................ ......................  21 \nTD 3 mitigations  ................................ ................................ ................................ ................................ ........................  21 \nTD 3 mitigation descriptions  ................................ ................................ ................................ ................................  22 \nTrack critical data in a revision control system  ................................ ................................ ........................  22 \nEnforce auditability  ................................ ................................ ................................ ................................ .............  22 \nUse revision control and version management tools  ................................ ................................ ............  22 \nTD 3.1 Mitigating the introduction of a compromised design into the application  ..........................  23 \nIsolate and store the application design  ................................ ................................ ................................ ..... 24 \nPerform reproducible build  ................................ ................................ ................................ ..............................  24 \nTD 3.2 Mitigating the modification of test benches or plans to reduce coverage or hide Trojan \ncode  ................................ ................................ ................................ ................................ ................................ ...............  24 \nExecute a documented test plan  ................................ ................................ ................................ ...................  25 \nValidate and verify test processes  ................................ ................................ ................................ ................  26 \nMaintain test environment via configuration management  ................................ ................................ . 26 \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  vii \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 3.3 Mitigating the introduction of a Trojan into the application design during \ndevelopment  ................................ ................................ ................................ ................................ ...............................  26 \nMaintain bi -directional link to requirements  ................................ ................................ ..............................  26 \nEnforce peer rev iew ................................ ................................ ................................ ................................ ...........  26 \nExecute a documented test plan  ................................ ................................ ................................ ...................  27 \nImplement, validate, and verify test processes  ................................ ................................ .......................  28 \nSelect a formal proof process  ................................ ................................ ................................ ......................  28 \nTD 3.4 Mitigating the introduction of compromised tooling or software into the environment  .. 28 \nValidate cryptographic hashes  ................................ ................................ ................................ .......................  29 \nResearch vulnerabilities  ................................ ................................ ................................ ................................ .... 29 \nValidate tools  ................................ ................................ ................................ ................................ .........................  30 \nTD 3.5 Mitigating intrusion into the internal network  ................................ ................................ ..................  31 \nAssign roles  ................................ ................................ ................................ ................................ ...........................  31 \nControl an d monitor access  ................................ ................................ ................................ ............................  32 \nResearch vulnerabilities  ................................ ................................ ................................ ................................ .... 32 \nPurchase from DoD -authorized vendors and distributors  ................................ ................................ ... 33 \nUse trusted computing environments  ................................ ................................ ................................ ..........  33 \nTD 3.6 Mitigating risk from a compromised hire or employee ................................ ................................  33 \nEnforce auditability  ................................ ................................ ................................ ................................ .............  34 \nAdhere to an approved design process  ................................ ................................ ................................ ..... 34 \nReview critical activities  ................................ ................................ ................................ ................................ .... 34 \nUse cleared personnel  ................................ ................................ ................................ ................................ ...... 34 \nTD 4: Adversary compromises system assembly, keying, or provisioning  ........................  34 \nTD 4 m itigations  ................................ ................................ ................................ ................................ ........................  35 \nTD 4 mitigation descriptions  ................................ ................................ ................................ ................................  36 \nPurchase from DoD -authorized vendors and distributors  ................................ ................................ ... 36 \nFollow storage and shipping guidance  ................................ ................................ ................................ ....... 36 \nProvide keys and configuration data  ................................ ................................ ................................ ...........  37 \nClear memory devices  ................................ ................................ ................................ ................................ ....... 37 \nProvision private keys  ................................ ................................ ................................ ................................ ........ 37 \nProtect the configuration data package  ................................ ................................ ................................ ...... 37 \nPerform verification activities  ................................ ................................ ................................ ..........................  38 \nAuthenticate the FPGA device  ................................ ................................ ................................ .......................  39 \nTD 5: Adversary compromises third -party soft IP  ................................ ................................ .. 40 \nTD 5 mitigations  ................................ ................................ ................................ ................................ ........................  40 \nTD 5 mitigat ion descriptions  ................................ ................................ ................................ ................................  40 \nPurchase from DoD -authorized vendors and distributors  ................................ ................................ ... 40 \nOnly accept IP that is unobfuscated  ................................ ................................ ................................ ............  40 \nValidate the cryptographic hash of the IP  ................................ ................................ ................................ .. 40 \nStore IP in a revision control repository ................................ ................................ ................................ ...... 41 \nExamine IP for malicious functions  ................................ ................................ ................................ ..............  41 \nTD 6: Adversary swaps configuration file on target  ................................ ...............................  41 \nTD 6 mitigations  ................................ ................................ ................................ ................................ ........................  43 \nTD 6 mitigation descriptions  ................................ ................................ ................................ ................................  43 \nIncorporate cryptographic authentication  ................................ ................................ ................................ .. 43 \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  viii \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nAuthen ticate configuration data each time the data is loaded  ................................ ..........................  43 \nPrevent direct read back ................................ ................................ ................................ ................................ ... 43 \nUse a CNSS/NIST approved algorithm and key length  ................................ ................................ ....... 43 \nUse security -evaluated authentication  ................................ ................................ ................................ ........ 44 \nTest access pins  ................................ ................................ ................................ ................................ ..................  44 \nEnsure authentication for modifications  ................................ ................................ ................................ ..... 44 \nGenera te and store all authentication keys on a program -controlled, FIPS 140 -2 compliant, \nLevel 2 HSM  ................................ ................................ ................................ ................................ ..........................  46 \nTD 7: Adversary substitutes modified FPGA software design suite  ................................ .... 47 \nTD 7 mitigations  ................................ ................................ ................................ ................................ ........................  47 \nTD 7 mitigation descriptions  ................................ ................................ ................................ ................................  48 \nPurchase from DoD -authorized vendors and d istributors  ................................ ................................ ... 48 \nPrevent automatic tool updates  ................................ ................................ ................................ .....................  48 \nUse a trusted computing environment  ................................ ................................ ................................ ........ 48 \nUse cleared personnel  ................................ ................................ ................................ ................................ ...... 48 \nValidate the cryptographic hash  ................................ ................................ ................................ ....................  48 \nTD 8: Adversary modifies FPGA platform family at design  ................................ ...................  51 \nTD 8 mitigations  ................................ ................................ ................................ ................................ ........................  51 \nTD 8 mitigat ion description  ................................ ................................ ................................ ................................ ... 51 \nEngage JFAC  ................................ ................................ ................................ ................................ ........................  51 \nTD 9: Adversary compromises single board computing system (SBCS)  ............................  52 \nTD 9 mitigations  ................................ ................................ ................................ ................................ ........................  52 \nTD 9 mitigat ion descriptions  ................................ ................................ ................................ ................................  53 \nPurchase from DoD -authorized vendors and distributors  ................................ ................................ ... 53 \nVerify and authenticate with independent teams  ................................ ................................ ....................  53 \nAuthenticate the FPGA devices ................................ ................................ ................................ .....................  53 \nVerify PCB connections  ................................ ................................ ................................ ................................ .... 53 \nVerify the SBCS configuration process  ................................ ................................ ................................ ...... 54 \nReview and evaluate SBCS vendor code  ................................ ................................ ................................ . 54 \nPoll FPGA settings captured in non -volatile memory  ................................ ................................ ...........  54 \nDocument compliance steps  ................................ ................................ ................................ ...........................  54 \nTD 10: Adversary modifies vendor FPGA software design suite during development  ..... 54 \nTD 10 mitigations  ................................ ................................ ................................ ................................ .....................  55 \nTD 10 mitigation descriptions  ................................ ................................ ................................ ..............................  55 \nPerform logical equivalency checking  ................................ ................................ ................................ ......... 55 \n3 Summary  ................................ ................................ ................................ ................................ ... 56 \nAppendix A: Standa rdized terminology  ................................ ................................ ...................  57 \nAppendix B: JFAC FPGA reporting template  ................................ ................................ ..........  60 \nAppendix C: Mitigations with data/documentation requirements  ................................ ........  64 \nChecklist for TD 1: Adversary utilizes a known FPGA platform vulnerability  ................................ ... 64 \nChecklist for TD 2: Adversary inserts malicious coun terfeit  ................................ ................................ .... 67 \nChecklist for TD 3: Adversary compromises application design cycle  ................................ ...............  70 \nChecklist for TD 4: Adversary compromises system assembly, keying, or provisioning  ............  79 \nChecklist for TD 5: Adversary compromises third -party soft IP  ................................ .............................  81 \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  ix \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nChecklist for TD 6: Adversary swaps configuration file on target  ................................ .........................  83 \nChecklist for TD 7: Adversary substitutes modified FPGA software design suite ..........................  84 \nChecklist for TD 8: Adversary modifies FPGA platform family at design  ................................ ..........  86 \nChecklist for TD 9: Adversary compromises single -board computing system (SBCS)  ...............  86 \nChecklist for TD 10: Adversary modifies vendor FPGA software design suite during \ndevelopment  ................................ ................................ ................................ ................................ ...............................  87 \n \nTable s \nTable 1: LoA2 threats  ................................ ................................ ................................ ................................ .................  3 \nTable 2: List of AS6171 slash sheets ................................ ................................ ................................ ...............  16 \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  1 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n1 Overview of Level of Assurance 2  threats and \nmitigations   \nThis document provides JFACs recommended hardware assurance \nstrategies for Field Programmable Gate Array (FPGA) devices.  The guidance outlined \nby this document provides hardware assurance to systems requiring Level of Assurance \n2 (LoA2). Additionally, it provides the requisite strategies and details for implementing \neach threat mitigat ion. Secondary documents are referenced in cases where the \nsuggested mitigation is highly detailed, specific to individual FPGA platforms, or subject \nto frequent change.  \nThis guidance is meant to stand on its own and not require the participation of JFAC i n \nthe development process of a programs product, unless required by a specific \nmitigation. However, JFAC does remain at the ready to aid programs who seek to better \nunderstand this guidance, to incorporate a program specific mitigation or are seeking \nalternatives to the guidance contained herein. For further information or support, please \nvisit the JFAC portal at https://jfac.navy.mil.  \nIn addition, to threats and mitigations identified at LoA1, LoA2 requires mitigations \nagainst FPGA assurance threats that have the following characteristics:  \n Access  A difficult point of access  requires the adversary to compromise a \nsystem or an individual to circumvent extensive practices taken to protect that \naccess. This is defined by the following list:   \n A single air -gapped computer network  \n A single cleared U.S. person  \n A group of uncleared U.S. persons, such as a small corporate office operated in \nthe U.S.  \n Shipping practices that  are documented and program approved  \n Threats may take advantage of multiple available poin ts of access.  \nFor a mitigation based on access to be effective, it needs to raise the access required to \ncarry out the attack to one necessitating multiple points of difficult access, either in \ndiffering areas of the supply chain or o f multiple personnel in the supply chain.  \nLoA2  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  2 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Technology  Low implementation risk technology  includes any technology \nwhich, while not publicly available now, could be implemented with sufficient \neffort and minimal risk of outright failure. These include:  \n Capabilities that public  academic research has identified, or internal U .S. \nGovernment research and development  has shown to be practical.  \n Techniques that have, according to substantial amounts of open research, been \nperformed successfully, but for which commercial tools are not available.  \n In addition, these threats may take advantage of existing public technology.  \nFor a mitigation based on technological complexity to be effective, it must increase the \nlevel of technology needed to carry out the attack to that which is beyond what  is \nrecognized as technically feasible and practical. This includes areas for which there is \nno known research.  \n Investment  A large multidisciplinary team  indicates that the team \nconducting the operation may draw on multiple skills not necessarily directl y \nassociated with the Custom Microelectronic Component. A large multidisciplinary \nteam is defined as any effort consisting of roughly fifty person -years of a wide \nrange of technical expertise, focused solely on attacking the device of interest. \nFor example , physics and materials science experts may have suitable technical \nskills. This level also accounts for a more substantial amount of effort, potentially \na sizeable organization working on the attack for a year or more.  \nFor a mitigation based on investmen t of resources to be effective, it must force the \nattacker to expend greater resources in the form of engaging the resources of a nation \nacross a wide scope to facilitate an attack.  \n Value of Effect  Establish vulnerabilities  pre-positions a change that is  not by \nitself a complete attack and requires additional access and technical \ndevelopment to complete an attack. Additionally,  attacks that disable or subvert \ncapabilities are included at LoA2.  \nTo be effective , a mitigation based upon value of effect to th e adversary must constrain \nthe severity of the outcome on the target to one of lesser effect. In this case, the \nmitigation must limit the LoA2 attack to degradation of performance of the device in a \ngeneral non -targeted manner.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  3 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Targetability  The attack a ffects only a subset of systems , and the \nadversary has no control over that subset. For systems that are affected, the \nbehavior must still be inherently targetable and controllable.  \n In addition, any inherently targetable and controllable attacks from LoA1  are \nrelevant at this level.  \nFor a mitigation based on targetability to be effective, it must remove the ability of the \nadversary to target specific systems and rely upon general and blind attacks.  \nFor a program to achieve Level of Assurance 2, it must pro vide mitigations against \nthreats that possess  these characteristics. Of prime importance in LoA2 is the assumed \npresence of a compromised cleared insider. This new condition renders classified \nfacilities and cleared people ineffective as a sole means of mi tigation. As such, many of \nthe mitigations offered in this guide focus on nullifying this adversarial advantage \nthrough the use of dual or independent teams. LoA2 addresses threats that originate \nfrom an adversary whose intent is malicious and does not cov er commercial assurance \nrisks such as re -marked parts. Economically motivated assurance threats have \nreliability risks associated with them. These threats should be addressed by the \nreliability testing of a program. For programs with stringent or specific reliability \nrequirements, it is strongly recommended that the appropriate level of testing be \nconducted to ensure the proper operation of the product rather than relying on \nassurance mitigations.  \nThe following table lists the ten FPGA threats that are addr essed by LoA2. Each threat \nis explained and accompanied by examples  in more detail within the JFAC FPGA Best \nPractices  Threat Catalog.  \nTable 1: LoA2 threats  \n# Threat description (TD)  \nTD 1  Adversary utilizes a known FPGA platform vulnerability  \nTD 2  Adversary inserts malicious counterfeit  \nTD 3  Adversary compromises application design cycle  \nTD 4  Adversary compromises system assembly, keying, or provisioning  \nTD 5  Adversary compromises third -party soft intellectual property (IP)  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  4 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n# Threat description (TD)  \nTD 6  Adversary swaps configuration file on target  \nTD 7  Adversary substitutes modified FPGA software design suite  \nTD 8  Adversary modifies FPGA platform family at design  \nTD 9  Adversary compromises single -board computing system (SBCS)  \nTD 10  Adversary modifies vendor FPGA software design suite during \ndevelopment  \nEach threat  listed here has corresponding mitigations . These mitigations are derived \nfrom various commercial/government standards and existing best practices . The use of \nthese standards/best practices should not preclude the use of any other standards or \nbest practices.  In particular, DoD projects identified as National Security Systems (NSS) \nshould utilize the appropriate guidance as required by the Committee on National \nSecurity Systems (CNS S) Policy 15 and other CNSS documents.  \n1.1 Complementary  standards and guidance  \nMicroelectronic  quantifiable assurance (MQA) standards are intended to be \ncomplementary to other government - and industry -recognized risk management \npractices and standards. The following are standards for various mitigations:  \n CNSS Policy on the use of Commercial Solutio ns to Protect National Security \nSystems Policy 7  \n CNSS Cryptographic Key Protection Policy 30  \n National Institute of Standards and Technology (NIST ) Federal Information \nProcessing Standards (FIPS)  Publication  186 Digital Signature Standard  \n NIST FIPS  198 The Keyed -Hash Mes sage Authentication Code (HMAC)  \n NIST Special Publication (SP) 800-53 Security and Privacy Controls for Federal \nInforma tion Systems and Organizations  \n NIST SP 800-57 Recommendation for Key Man agement  \n The Configuration Management section of NIST  SP 800-60 Systems Security \nEngineering: Considerations for a Multidisciplinary Approach in the Engineering  \nof Trustworthy Secure Systems  \n NIST SP 800-171 Protecting Controlled Unclassified Information in Nonfedera l \nSystems and Organizations  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  5 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n NIST SP 800-172 Enhanced Security Requirements for Protecting Cont rolled \nUnclassified Information  \n SAE International AS6171 Test Methods Standard; General Requirements, \nSuspect/Counterfeit, Electrical, Electro nic and Electromechanical Parts  \n Trusted Sys tems and Network (TS N) Analysis  \n Defense Acquisition Guidebook Chapter  Nine, Program Protection Plan  \n DoD guidance for storage of Secret  materials can be found in DODM 5200.01 -V3 \n JFAC FPGA Best Practices Documents  contact JFAC for available documents \nto support implementation  practices for t he FPGA standards in this guide  \nProgram offices should review and adhere to the standards provided in each document, \nas applicable. Additionally, programs are encouraged to apply  applicable  standards in \naddition to the standards described i n this document . \n1.2 Exclusions  \nThis FPGA Level of Assurance 2 Best P ractice  guide  does not address the following \nconcerns:  \n Non-malicious and profit driven reliability risks such as re -marked parts. \nPrograms are responsible for establishing and enforcing system reliability \nrequirements. However, compliance with SAE International AS 6171 Test \nMethods Standard: General Requirement s Suspec t/Counterfeit, Electrical, \nElectronic and Electromechanical Parts  as recommended by this report  is an \neffective detection mechanism for these kinds of counterfeit parts.  \n Threats to the confidentiality of the application design. The program applicat ion \ncan be loaded apart from the manufacturing process and under the protection \nand oversight of the program. Confidentiality is preserved using existing \nengineering practices, bitstream encryption and other anti -tamper practices. For \nmore guidance in this  area, see the D oDs Anti -tamper Executive Agent  \n(https://at.dod.mil ). \n1.3 Document use  \nThese FPGA assurance best practices instruct programs on protecting manufacturing \nand provisioning processes from adversarial influence. Specifically, they apply to the \nmanufacturing, acquisition, programming and first attachment of the FPGA devices. The \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  6 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nprogram must define its own protection methods as boards become integrated into \nsubcomponents, components, and then final systems.  \nFor LoA2 compliance, each program should perform each mitigation listed in the  TD # \nmitigation s section.  The  TD # mitigation d escription s section provides details for each \nmitigation.  In some cases, the full description contains additional options that are  \nrequired to be LoA2 compliant.  An asterisk * next to any mitigation indicates additional \noptions must be implemented.  \nWhen mitigations for all the threats listed under LoA2 are completed, that device can be \nsaid to have achieved LoA2. However, complianc e with LoA2 can be impacted by \nchanges in several areas during the systems life.  \nThe Program Protection Plan (PPP) emphasizes the need to maintain and update \nprotection measures throughout life cycle of a program. It is strongly recommended that \neach prog ram identify events that would trigger a review of the PPP and hardware \nassurance practices after fielding. These events should include but not be limited to:  \n Changes to the system , \n Changes to the supplier of critical components including the FPGA devices , \n Changes to the FPGA design software (new releases, fixes, etc.),  \n Changes to the threat environment , and  \n Revelations of new vuln erabilities to the FPGA devices . \nThe PPP documents list resources with which the program can track the latest available \nintellig ence on threats  and supply chain vulnerabilities. Changes in any of these areas \nshould trigger a review of the most up -to-date assurance mitigations against the \ntriggering event. If threats or vulnerabilities threaten the system, new mitigations should \nbe implemented to remain compliant to LoA2. Absent any changes in these areas, the \ndevices should be considered to have achieved LoA2.  \n1.4 General Comments on Mitigations  \n Programs are encouraged to own as much of the fabrication process as possible \nand avoid  third parties to the fullest extent possible.  \n Programs are encouraged to diversify their supply sources to minimize malicious \ntargeting.  \n Programs are encouraged to utilize cleared personnel and classified resources to \nthe fullest extent possible.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  7 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Progr ams are encouraged to use verification of all manufacturing steps to the \nfullest extent possible.  \n2 Threat descriptions (TD)  \nTD 1: Adversary utilizes  a known FPGA platform v ulnerability  \nIn this t hreat , an adversary uses a known vulnerability in an FPGA platform or vendor \ndevelopment software package to initiate an attack that is not specific to a program or \nsystem. A known vulnerability is an unclassified published  weakness in the design of a \nspecific FPGA platform or sof tware program that would allow an adversary the ability to \nuse it for malicious purposes. This threat does not focus on a particular vulnerability but \nis any weakness in the FPGA device.  These vulnerabilities are published in public \ndatabases , such as the Common Vulnerabilities and Exposures (CVE) and the \nNational Vulnerabilities Database (NVD), vendor advisories, errata bulletins, etc. Such \nvulnerabilities could allow for  leakage of sensitive information or keys; allow for the \ncompromise of security or  tamper detection functions; or allow the unauthorized \nreconfiguration of the product. This threat can be introduced by  a program not \nperforming vulnerability research,  an insider not disclosing the fact of the vulnerability , \nmodifying data to cover up the  existence of a vulnerability , or adding/modifying design \nfeatures for use with the vulnerability.  \nTD 1 mitigations  \n Use caution when select ing tools or platforms . When possible do not select tools \nor platforms  that are end -of-life or beta/initial releases . Also, ensure previously \nidentified vulnerabilities existing in previous tools/platforms have been \nadequately addressed in newer releases.  \n Use cleared  personnel  that possess at least a  Secret  level clearance.  \n *Research vulnerabilities  affecting  tools/plat forms . \n Use revision control/version management  that includes document/data control, \ndocument/data release, backups and archives, refresh of backup media, \nretention of tools and software, test equipment , and test environment.  \n Enforce auditability  of the requirements, architecture, design , code, test s, bugs, \nand fixes. At a minimum, audit data should include what decisions were made, by \nwhom, for what reason, and on what date.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  8 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Enforce approved  design process  that has clear and entry and exit criter ia. Entry \nand exit criteria incorporate peer reviews and technical reviews with \nmanagement approval to exit a phase.  \nTD 1 m itigation descriptions  \nUse caution when s electing tools or platforms  \nConsider the longevity of selected tools and FPGA platforms. New ly released devices \nmay not y et have a vulnerability history.  Programs  should proceed with caution  when \nusing newly released devices . End-of-life devices may not have support to mitigate \nvulnerabilities once identified.  \nUse cleared personnel  \nUse personnel with at least a Secret  level clearance to perform designated work.  \nResearch vulnerabilities  \nResearch the respective FPGA platform and software for existing vulnerabilities in \ndatabases such as:  \n Common Vulnerabilities and Exposures (CVE)  https://cve.mitre.org   \n NIST National Vulnerability  Database (NVD)  https://nvd.nist.gov   \n Government Industry Data Exchange Program (GIDEP)  \nhttps://www.gidep.org/products/products.htm  \n DISA Security Technical Implementation Guides (STIG s)  \nhttps://public.cyber.mil/stigs/   \n Searches for vendor advisories, publications , and academ ic papers detailing \nvulnerabilities in the device in question.  \nIf vulnerabilities are found in the FPGA device, choose one  of the following options:  \nOption 1 : Select a different FPGA platform device or software that does not have \npublished vulnerabilities and meets the program requirements.  \nOption 2:  Use standard formal processes and procedures to work with the vendor to \nresolve the vulnerability. Once a fix is identified, only accept formal releases, do not \naccept custom beta fixes,  custom pat ches, etc. for incorporation.  \nOption 3 : The program can internally determine the vulnerability poses no significant \nrisk to their product.  JFAC is available to provide assistance in assessing the risk that \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  9 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nthe vulnerability poses to the system a nd recommend mitigations for a particular \nvulnerability.  \nNote: If a vulnerability is identified,  a program should  report it to the Government \nIndustry Data Exchange Program (GIDEP) and contact the vendor so they may correct \nit. \nUse r evision control/versio n management  \nTo prevent vulnerable software from being loaded into the environment, it is important \nthat robust configuration management and revision management systems are in place. \nAll changes to the system or artifacts should be documented, approved , and auditable.  \nThese systems should fulfill the following requirements:  \n Allow only authorized system administrators to make changes to the underlying \nrevision control tool and underlying server.  \n Use a backup system that syncs to the primary and is maintained by a separate \nadministrator. Each system should be managed by separate system \nadministrators . \n Enforce administrative restrictions ; restrict privileged access to authorized \npersonnel only ; limit what users can do to the database; ensure all users are \nverified; encrypt database information both in transit and at rest; enforce secure \npasswords; enforce role-based access control and privileges; and remove \nunused accounts.  \n Remove any components or f unctions that are not necessary (for example, \nremove all sample files and default passwords).  \n Ensure the system provides a complete and immutable , long-term change history \nof every file. The system must log every change made by individuals. This \nincludes changes such as creating and deleting files and editing content.  The \nhistory must identify the person who made  the change, what was changed, the \ndate of the change, and the purpose of the change.  \n Ensure the system stores a reliable copy of assets that are currently in \nproduction.  \n Ensure the system stores reliable copies of previous production versions of \nassets, allowing for the complete retrieval of those versions.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  10 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Ensure password best practices (password rotation, length, etc.) are enforced. In \nlieu of a password, two -factor authentication can be utilized.  \n All changes to the system or artifacts should be documented, approved, and \nauditable.  \nEnforce auditability  \nThe program should maintain audit logs on all design data to include req uirements, \narchitecture,  design, code, test s, bugs , and fixes. The audit data minimally should \ndocument who requested the change with date timestamp, what  decision was made \nregarding the change, who made the decision w ith date and timestamp, why the change \nwas requested, and who made the change with date timestamp .  \nEnforce approved  design process  \nTo prevent a compromised insider from hiding a vulnerability  ensure  all critical activities \nare identified and documented . Ensure the entire  design is reviewed by multiple cleared \nindividuals . The original designer should not be the responsible party for performing the \nreview . The cleared reviewers should assess  all vulnerability activities, including  \nidentification of vulnerabilities and the appropriateness of the mitigations.  \nTD 2: Adversary inserts malicious counterfeit  \nIn this threat, an adversary with access to a fabrication process for manufacturing \ncounterfeits inserts additional logic in the FPGA die for their malicious purposes. This \nincludes c ounterfeit parts made in an unauthorized fabrication facility and inserted into \nthe supply chain,  as well as, counterfeit parts made in an authorized fabrication facility \nthrough the compromise of the manufacturing process . In either scenario the  \nadversarial intent is to insert  a malicious function into the package of an authentic \ndevice.  \nAdditionally, this threat assumes that there is a compromised cleared insider in the \nprogram. Adversaries may use cleared insiders to introduce malicious counter feit parts \nat any point in the product manufacturing cycle or may compromise a piece of the \nFPGA device verification process. Overlapping checks are therefore necessary for each \nthreat commensurate to this level of assurance.  \nInsertion of counterfeit parts  into the supply chain can happen at any point in the  \ndevice's lifecycle. This includes prior to purchase, in transit, while in storage by the \nprogram, during assembly , and at distribution prior to fielding.   \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  11 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nCompromising the manufacturing process in an au thorized facility in order to make and \ninsert c ounterfeit parts could happen during  any of the following phases of the \nmanufacturing process :  \n Transfer of graphic \ndesign system 2 \n(GDSII ) mask data  \n Mask fabrication  \n Mask storage   Wafer manufacturing  \n Wafer testing  \n Wafer dicing and \npackaging   Package testing  \n Device \npersonalization  \nInsertion of a malicious function into the package of an authentic device  includes:  \n Insertion of a snooping die stacked in the package , \n Introduction of a kill switch in the package , or \n Alteration of the bond out to compromise some FPGA feature . \nThese challenges are addressed with a combination of:  \n Physical device inspection,  \n Overlapping personnel and multi -party review in the verification process, and  \n Cryptographically protected IDs . \nThe LoA2 mitigations  for this threat rely heavily on a physical inspection of the parts. \nPhysical inspections are an extensive counterfeit detection approach used to identify a \ncounterfeit device from an unauthorized fab rication facility v ersus a device from an \nauthorized fabrication facility . JFAC relies on substantial physical analysis to address \nthese threats for the following reasons:  \n The program has no positive control over the fabric ation facility or its processes,  \n JFAC can identify numerous technic ally feasible attacks for all fabrica tion \ncountermeasures considered, and  \n Most FPGA fabrication facilities are foreign owned . They are not loyal to the \ngoals of the United States , and are not c ontrollable by the program or Do D. \nWhile c ommercial (non-malicious) counterfeits such as re -marked parts may represent \na reliability risk , they are not included under levels of a ssurance. Those counterfeits are \nnot malicious by design, not controllable/ targetable , and are economic in nature. \nPrograms with s pecific reliability requirements should plan for the appropriate level of \ntesting to verify that their design and components meet those goals.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  12 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 2 mitigations  \n Purchase from DoD -authorized vendors and distributors . The Do D program \nacquisition group can pr ovide this information.  \n Consult GIDEP  and follow their guidance on counterfeit risk mitigation, including \nguidance on known counterfeit parts. The program should use this information to \ninform their physical analysis efforts.  \n Follow storage and shipping  guidance  for FPGA devices . \n Verify  FPGA cryptographically  secure  identifier s (IDs) against information sent by \nthe vendor (not the authorized distributor).  \n Using AS6171 , perform physical inspection/analysis  on a sampling of random \ndevices to detect counterfeit parts . \n Mitigate risk of a cleared insider  involved in the physical inspection process . \nTD 2 mitigation descriptions  \nPurchase from DoD -authorized vendors and distributors  \nUse DoD -authorized vendors and dis tributors for all purchases . Authorized vendors c an \nbe identified  through the acquisition organization.  \nConsu lt GIDEP  \nGIDEP provides technical data comp iled by government and i ndustry  to be used for \nsystem design, development, production, and logistics support processes . This \ninformation contains counterfeit risk mitigations and physical analysis results.  \nFollow s torage and shipping  guidance  \nThe program should document, maintain , and e nforce both device storage and shipping \nprocedures. Minimally , the plan should enforce the verification of all devices  upon \nreceipt.  Once verification has taken place , production devices should be stored and \nmaintained in a restricted area separate from no n-production devices (design, test, \netc.). Production devices should be continuously tracked to include arrival of the device \nby unique identifier, interaction anyone has with the device, and exit of the device from \ninventory.  The restricted area should en force access control that limits access to only a \nminimum subset of people that require access to support direct job responsibilities and \nexcludes all members of the design team.  The restricted area should have a clearly \ndefined perimeter, but physical bar riers are not required. Personnel within the area \nshould be responsible for challenging all persons who may lack appropriate access \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  13 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nauthority.  The restricted area access should be audited to include data containing who \nentered/exited the area , with a timestamp , and reason for entry.  \nShipping should be controlled and managed.  JFAC recommends shipping material \nusing a commercial carrier that has been approved by the CSA to transport Secret  \nshipments, although the material is not Secret . Commercia l carriers may be used only \nwithin and between the 48 contiguous States and the District of Columbia or wholly \nwithin Alaska, Hawaii, Puerto Rico, or a U.S. possession or trust territory.  When \nshipping using a commercial carrier , take efforts to afford add itional protection against \npilferage, theft, and compromise as follows.  This includes using hardened containers , \nunless specifically authorized otherwise , and ensuring the packages are sealed.  The \nseals should be numbered and the numbers indicated on all c opies of the bill of lading \n(BL). When seals are used, the BL shall be annotated substantially as follows: DO NOT \nBREAK SEALS EXCEPT IN CASE OF EMERGENCY OR UPON PRIOR AUTHORITY \nOF THE CONSIGNOR OR CONSIGNEE. IF FOUND BROKEN OR IF BROKEN FOR \nEMERGENCY REAS ONS, APPLY CARRIER'S SEALS AS SOON AS POSSIBLE AND \nIMMEDIATELY NOTIFY BOTH THE CONSIGNOR AND THE CONSIGNEE.  \nVerify FPGA c ryptographic ally secure  identifier s \nThe use of this type of device ID mitigates the threat from counterfeit  parts made in an \nexisting, unauthorized fabrication facility  as described at the beginning of this threat \ndescription.  While the specifics of each FPGA vendor and platform vary, many newer \nFPGA platforms contain this type of anti -counterfeiting feature. When these features are \nsufficiently secure, they provide an extremely cost -effective method to detect \ncounterfeits both at acquisition and throughout the FPGA devices lifecycle in a system. \nThe two biggest advantages of such mechanisms  are the ability to validate a device \nremotely and the ability to non -destructively re -validate  a device at any time.  \nWhile remote attestation cannot be used during acquisition and assembly, it can be \nused throughout the lifecycle of the device. This provides the possibility of devices and \ntheir configu rations be ing validated and monitored remotely. Capabi lities for remote \nattestation of  hardware, firmware, and software are currently being developed in the \ncybersecurity space as enterprise management tools.  \nMultiple devices currently provide a mechan ism for remote attestation ; however , remote \nattestation is not approved for initial counterfeit screening. Remote attestation is a \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  14 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \npowerful and valuable technique and JFAC can consult on appropriate remote \nattestation schemes, potentially based on these same mechanisms. However, the initial \ncounterfeit screening must be done locally, verifying that each specific device is the one \nconnected and cryptographically verified.  \nIn contrast to physical anti -counterfeiting techniques, properly implemented \ncryptographic identifiers do not require destructive analysis for verification. A typical \nscheme could validate such a device simply by placing it in a socket. A design can \nfacilitat e access to the identifier either remotely or through local access , such as a \nboard header. Depending on the exact mitigations selected, this potentially saves two \ndistinct destructive steps: one at acquisition of the devices, and one after assembly of \nthe board.  \nImplementation details matter when validating the authenticity of an FPGA device. E ach \nFPGA vendor offers their own authentication approach and each FPGA platform offers \na unique variation. In no case is a fully readable ID acceptable. Instead, \ncryptographically protected IDs include  cases where the device possesses a specific \nprivate cryptographic key. The device ID in these cases  can be cloned only if an \nadversary is able to get access to that private key. Regardless of the specific platform \nused , the public keys/identifiers of the devices being authenticated must be delivered \nand maintained in a secure way.  \nThe following points describe  at the highest leve l the specific criteria required for an \nappropriate device ID to support anti -counterfeiting : \n Cryptographically protected IDs must utilize a private asymmetric key for which \nno read function exists. This must use a CNSS Policy compliant algorithm if it is a \nNational Secur ity System . If CNSS is not a program requirement , the program \nshould use a N ational Institute of Standards and Technology (NIST) approved \nasymmetric authentication algorithm . \n The provenance of the key must be understood in detail.  \n The device must be able to authenticate a nonce using this key. Each devices ID \nmust  be authenticate d by the vendo r-provided public key through decryption of \nthe nonce.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  15 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nProtect identifier delivery data  \nFor delivery, the vendor must  provide this information to the program using a NIST -\napproved authentication algorithm to transmit the data. Examples would be an elliptic -\ncurve cryptography ( ECC )-signed email with a verified certificate, or an HTTPS -based \nfile distribution system using a verified certificate. Once received, the integrity of that list \nmust be maintained, by storing w ith protections appropriate  to critical  protected \ninformation. This should include restricted role -based access on a network that is \ncompliant with NIST SP 800-171, Protecting Controlled Unclassified Information in \nNonfederal Systems and Organizations.  \nPerform p hysical inspection /analysis  \nIn LoA2, two new attacks are introduced under TD 2:  \n Insertion of a malicious function into the package of an authentic device , and   \n Counterfeit parts made in an authorized fabrication facility .  \nIt is due to these new threats that a physical inspection is required in all cases. In LoA1, \ncryptographically protected IDs were sufficient to address the counterfeit threat. \nHowever, this would not be sufficient at LoA2 since these IDs would not preclude \ninserting a malicious function into the packag e of a device nor identify devices where \nmalicious features were added to the die during manufacturing.  \nPhysical  analysis applies specific, industry standard counterfeit inspection techniques, \nincluding package analysis, x -ray of the part, and examination of the die with \ncomparisons against FPGA vendor provided golden (known good) samples. This \nphysical analysis is intended to catch parts that have been remarked or contain \ncounterfeit die.  \nThe details of what steps to conduct in the physical analysis and r ecommendations on \nhow to execute them are contained in the commer cial standard document, SAE \nInternational AS6171 Test Methods Standard; General Requirements, \nSuspect/Counterfeit, Electrical, Electronic and Electromechanical (EEE) Parts . \nCleared persons or  a lab independent of the program or its performers  should carry out \nthese inspections.  \nThe steps of a physical analysis are conducted from least destructive to most \ndestructive  and determine if the part in question is authentic. If a device fails a given  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  16 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nstep, it is not authentic, and there is no need to complete further steps.  If all steps are \ncompleted and the device passes, it is likely authentic .  \nEach AS6171 test is detailed in a separate document called a slash sheet . The \nfollowing table lists the slash sheets that comprise the  AS6171  standard.  Users should \nensure to use the latest version of AS6171 and associated slash sheets.  \nTable 2: List of AS6171 slash s heets \nTest \nNumber  Description  \nAS6171  Test Methods Standard; General Requirements, Suspect/Counterfeit, \nElectrical, Electronic, and Electromechanical Parts  \nAS6171/1  Suspect/Counterfeit Test Evaluation Method  \nAS6171/2  Techniques for Suspect/Counterfeit EEE Parts Detection by External \nVisual Inspection, Remarking and Resurfacing, and Surface Texture \nAnalysis Test Methods  \nAS6171/3  Techniques for Suspect/Counterfeit EEE Parts Detection by X -ray \nFluorescence Test Methods  \nAS6171/4  Techniques for Suspect/Counterfeit EEE Parts Detection by \nDelid/Decapsulation Physical Analysis Test Methods  \nAS6171/5  Techniques for Suspect/Counterfeit EEE Parts Detection by \nRadiological Test Methods  \nAS6171/6  Techniques for Suspect/Counterfeit EEE Parts Detection by Acoustic \nMicroscopy (AM) Test Methods  \nAS6171/7  Techniques for Suspect/Counterfeit EEE Parts Detection by Electrical \nTest Methods  \nAS6171/8  Techniques for Suspect/Counterfeit EEE Parts Detection by Raman \nSpectroscopy Test Methods  \nAS6171/9  Techniques for Suspect/Counterfeit EEE Parts Detection by Fourier \nTransform Infrared Spectroscopy (FTIR) Test Methods  \nAS6171/10  Techniques for Suspect/Co unterfeit EEE Parts Detection by \nThermogravimetric Analysis (TGA) Test Methods  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  17 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTest \nNumber  Description  \nAS6171/11  Techniques for Suspect/Counterfeit EEE Parts Detection by Design \nRecovery Test Methods  \nFor LoA2, the program should follow the lot sampling guidelines found in the AS6171 \ndocument and perform  the tests defined by slash sheets 1 through 11.  \nSheets 1 through 10 should uncover a counterfeit f abricated in an unauthorized facility  \nor a malicious package insert. Sheet 11 should uncover a counterfeit fabricated in the \nauthorized fabrication (fab) facility . \nIf the device family possesses cryptographically protected IDs:  \n Perform slash sheets 2 and 3 that incorporate a visual inspection and 3D x -ray. \nThis effort analyzes the parts for an additive malicious manufacturing insert \ninside the package. The number of parts sampled should be guided by the \nsampling standard found in slash sheet 1.  \nIf the device family does not possess cryptographically protected IDs:  \n Perform slash sheets 2  through 10 to detect an in -package malici ous insert and a \ndie manufactured in an unauthorized fab.  \n Perform the steps outlined below as they relate to slash sheet 11 to identify \nmalicious functions added to the die during manufacture in an authorized fab. \nThis test may be limited to a single devic e. \nSlash s heet 11 provides  instructions for performing a full delayering, imaging of die , and \ncomparison against a vendor -provided  GDSII or an exemplar device.  Ideally, an \nexemplar part is one provided by the FPGA vendor directly to the program for this \nspecific purpose.  However, if that is not possible, a device purchased from a vendor -\nauthorized distribut or would be acceptable. Preferably, the distributo r is a differ ent one \nfrom where t he product lots were obtained. However, u tilize DoD -authorized vendors  for \nall purchases . At LoA2, a full tear down is not necessary, nor even possible in some \ncases.  Instead, JFAC recommends the following procedures for  carrying out slash s heet \n11. \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  18 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nWhen process geometries are beyond the state of the art in reverse engineeri ng, \ncontact  JFAC for guidance.  \nFull backside delayering  \nThis includes imaging and comparison of layers active, poly, contact , and metal 1 ( M1). \nThis is the ideal option for detecting malicious changes.  \nWindowing  \nWhen full delayering is not an option, the program should:  \n Use a plasma focused ion beam ( FIB) to expose windows on the backside to \nexamine areas of interest on layers active, poly, contact , and M1 , or  \n Expose windows on the die front side to examine areas of interest on all l ayers \nfrom passivation  down to M1 . The program should target windows of \napproximately 200x200 m. \nAt each layer, the structures should be compared with information from the FPGA \nvendor or with an exemplar device.  \nThe windows should focus on non -fabric areas of the die.  JFAC rec ommends  that the \nwindows target areas of interest to an adversary including, but not limited to:  \n Cryptographic functions  \n Microprocessors  \n Transceiver logic  \n Tamper sense and response logic  \n Configuration logic  \n Input/output  (I/O) programming logic  \n Key storage elements  \nIf the program is unable to determine the physical location of these sensitive areas of \ninterest, it should  target every feature type. In this case, a visible examination is made \nof the die , noting areas of different structures and macro types. Th ese areas could \ninclude various logic areas, memory macros, hard analog cells, I /Os, fabric , etc. Each \none should be examined using a plasma FIB window and compared against the same \nlocation o n an exemplar device.  \n The windows should comprise no less than 1 % of the die surface area.   \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  19 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nIn the case of FPGA multi -chip modules ,  \n All the dies should b e examined using this technique, and   \n Special care should be taken to validate the internal packaging connections.   \nForward the results of the examination to JFAC with information regarding the FPGA \ntype and lot. The results should include a description of the verification method and the \ncoordinates of the windows opened for evaluation. JFAC will compile this information \nover time to develop better insight into mali cious attacks on the manufacturing process.  \nMitigate risk of a  cleared insider  \nTo mitigate  the risk of a cleared insider compromising the physical inspection process , \nprograms  should:  \n *Select sample parts  bound  for physical inspection in ways that  specifi cally \ndefeat insider compromise.  \n *Verify  independent lab work  using o verlapping p ersonnel and mu lti-party review.  \n Create cryptographically protected IDs  post verification . \n Follow the mitigation guidance in  TD 4: Adversary compromises system \nassembly, keying, or provisioning .  \nSelect sampl e parts  \nThe selection of parts to be physically sampled must be handled in such a way that a \ncompromised cleared insider could not just select good parts to be sampled. Possible \noptions include the following:  \nOption 1: Multiple independent parties handle  part selection before shipping.  They \nshould physically verify that the parts selected make it all the way to the physical \ninspection processes.  \nOption 2: An independent party veri fies sampling before shipping, and multiple parties \nverify upon receipt that the right parts were received.  \nOption 3: Use a non -human random selection automated process for sampling.  \nVerif y independent lab work  \nIf a program insider is working with a compro mised lab to pass counterfeit parts off as \ngood , the compromised lab could throw away all the devices submitted for examination \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  20 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nand simply create reports and photos of an exemplary device. Or they could do all the \nwork but falsify the reports.  \nThis threat  is not completely mitigated with the following steps , but these steps  increase \nthe difficulty of returning false reports : \n Insist on the return of residual materials and detailed reports after evaluation. \nThis serves as a check that the lab did the work an d serves as an additional \nmeans to verify that sampling guidelines were followed.  \n Require lock and key storage of all parts to be physically inspected, whether that \ninspection is done by the program or by  independent lab(s).  \nAdditionally, choose one  of the  following : \nOption 1 : Insert known bad parts into the samples to be physically verified. Track which \nparts those are using custom bad data and/or markings. If the independent lab does not \nreport those parts as bad, then either they, or who they are reporti ng bad parts to, or \nboth, may be compromised.  \nOption 2:  Use two labs, use an independent expert observer , or both . This creates a \ncheck against the lab being compromised.  \nOption 3:  Perform any p hysical inspections done by the program, rather than a n \nindependent lab, with two -person authentication, or duplicate  them independently, or \nboth.  \nCreat e cryptographically protected IDs  post verification  \nFollowing the physical verification above, JFAC recommends  using soft physically \nunclonable function s (PUF) to protect  the authentic parts from being swapped out \nduring the subsequent program manufacturing process :  \n Load the soft PUF into the fabric and generate a unique ID for the FPGA die.  \n Record the device serial number and PUF ID.  \n Erase the soft PUF.  \nAt an y time during the lifecycle of the FPGA device, the soft PUF can be reloaded  and \nthe unique ID  can be  extracted and compared against the expected value for \nconfirmation of the authenticity of the part.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  21 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 3: Adversary compromises application design cycle  \nIn this threat , a compromised insider has access to the design process and data related \nto an FPGA application development effort . This insider can use their access to modify \ndesign code  or design constraints, change FPGA configuration settings , or swap in a \ndistinct configuration file that is authenticated and built with the same tools and keys \nbeing used by the design team. The actor  is in a particularly advantageous position \nbecause they can modify the product during any phase of the design process. This \nsame threat surface may also be attacked via remote network intrusion. An attacker \nwith network access may also be able to modify important design data in a way that \nintroduces a Trojan or other nefarious function.  \nAt LoA2, it is assumed that  multiple uncleared persons may be  working in conjunction \nwith the adversary. The uncleared persons  may hold different  positions  within the \nsupply chain.  The actors could be working independently , with each other , or with a \ncleared insider.  Using cleared personnel  does not completely mitigate  this threat , as the \ninsider may be a single cleared person.   \nThis section  describes mitigations that should be taken for the overall threat, as well as \nmitigations that are associated with the following specific scenar ios: \n Introduction of a compromised design into the application ,  \n Modification of test benches  or plans to reduce coverage or hide Trojan code ,  \n Introduction of a Trojan into the application design during development , \n Introduction of compromised tooling or software into the environment ,  \n Intrusion into the internal n etwork ,  \n Compromised employee , \n Modification  of revision control that hides code or test bench modification \n(associated mitigations are captured in the  TD 3 mitigations  section below  for \nall sub -threats ), and  \n Introduction of modified configuration data after generation (associated \nmitigations are captured in the  TD 3 mitigations  section below  for all sub -\nthreats ). \nTD 3 mitigations   \nThe best practices presented here  do not constitute a standalon e FPGA design flow , \nbut rather should be integrated into the existing design procedures. These assurance  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  22 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \npractices incorporate industry -accepted design be st practices with emphasis on \ndocumented and approved design, review , and test procedures.  \nThe following set of best practices should be used  to assure an FPGA application \ndesign at LoA2  and are applicable to all the sub -threats identified in this section : \n Track critical data in  a revision control  system . \n Enforce auditability  of the requir ements, a rchitecture, design,  code, test s, bugs, \nand fixes. At a minimum, audit data includes what decisions were made, by \nwhom, for what reason, and on what date.  \n Use revision control and version management tools  that meet the requirements \ndescribed later in this section.  \nTD 3 mitigation descriptions  \nTrack critical data in a revision control  system  \nThe program should identify and document all data that is considered critical.  Each \ncritical data item should be stored and tracked in the revision control system.  Minimally, \nthe following documents, data artifacts and tool configurations should be managed in \nthe revision control system.  \n Third -party intellectual property  (3PIP)  \n Utilized libraries  \n Development files, code, software used for development, synthesis scripts, and \ntools  \n Test benches, test plans, test procedures, and test reports  \n Tool configuration settings  \n Design documents  \nEnforce auditability  \nThe program should maintain audit logs on all design data to include req uirements, \narchitecture, design, code, test s, bugs , and fixes. The audit data minimally should \ndocument who requested the change with date timestamp, what  decision was made \nregarding the change, who made the decision w ith date and timestamp, why the change \nwas requested, and who made the change with d ate timestamp .  \nUse r evision control  and version management tools  \nRevision control/version management systems should meet the following requirements:  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  23 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Allow only authorized system administrators to make changes to the underlying \nrevision control tool and underlying server.  \n Implement a backup system that mimics the primary system and is maintained by \na separate administrator. Separate system administrato rs should manage each \nsystem.  \n Enforce admin istrative  restrictions;  restrict privileged access to authorized \npersonnel only ; limit what users can do to the database;  ensure all users are \nverified; encrypt database information both in transit and at rest; e nforce secure \npasswords; enforce  role-based access control and privileges; and remove \nunused accounts.  \n Remove any components or functions that are not needed; for example, remove \nall sample files and default passwords.  \n Ensure the system provides a comple te and immutable long -term change history \nof every file. The system must log every change made by individuals. This \nincludes creation and deletion of files and content edits. The history must include \nthe person who made the change, what was changed, the da te, and written \nnotes on the purpose of each change.  \n Ensure the system stores a reliable copy of assets that are currently in \nproduction.  \n Ensure the system stores reliable copies of previous production versions of \nassets, allowing for the complete retrie val of those versions.  \n Enforce password best practices (password rotation, length, etc.). In lieu of a \npassword, two -factor authentication can be u tilized. \n All changes to the system or artifacts should be documented, approved, and \nauditable.  \nTD 3.1 Mitiga ting the introduction of a compromised design  into the \napplication  \nIn this scenario , the adversary is able to insert a Trojan into the design after the design \nhas been verified, but before the design is loaded for final deployment. Strict controls on \nboth configuration management and the revision control system will help prevent the \nadversary from making unmonitored changes.   \nAt LoA 2, programs should ensure no changes have been made to the application \ndesign.  This can be done by isolating the deployable version with the associated hash \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  24 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nand verifying the hash before loading . Alternatively , this can be done by performing a \nreproducible build and verifying the results of the verifie d version a gainst  the results of  \nthe to be loaded  version . The verification should produce the same  results . \nMitigations  \n Physically isolate and store the application design  until it is delivered.  \n Perform reproducible build  of the application.  \nDescriptions  \nIsolat e and stor e the application design  \nTo prote ct the application design after verification but before deployment, the final \nconfiguration file and hash should be physically isolated and stored until it is delivered \nfor provisioning. Ensure the file s can only be accessed via authentication of two disti nct \nparties. No single individual should be able to access the configuration file and the \nstored value of the hash . The limited set of people with access should have to follow \naccess control procedures such that access is controlled, monitored, logged , and \nauditable.  Before the file is loaded, the hash should be recalculated and compared \nagainst the stored hash.  \nPerform reproducible build  \nUse a reproducible build process to verify the integrity of the FPGA synthesis and build \nsoftware. The r eproducible build performs the synthesis process that takes  in human \nreadable hardware descriptor language ( HDL) and other human readable inputs, and \nconsistently generates the same final  configuration file (bitstream).  It is expected that \nthis process wil l, in most cases, require the use of the same version of the Electronic \nDesign Automation ( EDA) tools, and in some cases the same operating system version. \nThis process will highlight the possession of modified software where there is a \nmismatch. Contact t he FPGA software vendors for more information on how to perform \nreproducible builds.  \nTD 3.2 Mitigating the m odification of test benches  or plans to reduce \ncoverage or hide Trojan code  \nIn this threat, the adversary makes changes to the test bench to hi de malicious code, \nreduce coverage , or reduce functionality.   \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  25 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nMitigations  \n Create and execute a documented test plan  that identifies the various test \nreviews that will take place, analys es to be performed, type of testing to be \nperformed, and the methods used  to accomplish the test.  \n Validate and verify test processes  which include design/test team separation, \npeer reviews, and use of automated tools where applicable . \n Maintain  test environment  via configuration management , similar to that of a \ncritical system.  \nDescriptions  \nExecute a documented test plan  \nThe program should consider assurance when creating and maintain ing the test plan.  \nThe test plan and processes should at least:  \n Provide a  mechanism to verify all requirements.   \n Explicitly list code coverage metrics, the type of testing that will be performed, \nand acceptable testing guidelines.  Code coverage should state how much code \nis checked by the test bench, providing information about dead code in the \ndesign and holes in the test suites. D ocument the decision to use/not use other \ntypes of testing , such as directed test, constrained random stimulus, and \nassertion.  \n Specify the verification environment which describes the tools, the software, and \nthe equipment needed to perform the reviews, a nalys es, and tests. Each of these \nitems should be maintained under revision control.  \n Document and analyze unexpected behavior and final implementation \nconclusions.  \n Ensure code coverage includes statement coverage, branch coverage, Finite \nState Machine (FS M), condition, expression, and toggle coverage. Document \nany code that will not be covered and why. Ensure untested code is documented \nand reviewed through the review process. Use functional tests to verify the FPGA \ndoes what it is supposed to do. Any devi ations must be documented and \napproved.  \n Ensure all test discrepancies, bugs, etc., are resolved via a change process.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  26 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nValidate and verify  test processes  \nThe program should take care to ensure test processes consider assurance needs.  This \nincludes design/test team separation, peer reviews, and use of automated tools where \napplicable . All test discrepancies, bugs, etc. , should be res olved via a change process  \nutilizing  a change management system.  The established processes should be \ndocumented, enforc ed, and audited.  \nMaintain t est environment via configuration management  \nThe test environment should be treated as a critical system and maintain ed similarly to \nthe production environment.  \nTD 3.3 Mitigating the introduction of a Trojan in to the application \ndesign during development  \nIn this scenario, malicious functionality is introduced into the application design during \nthe development phase.   \nMitigations   \n Maintain bi-directional link to requirements . Tracing to design decisions is \npermitted in support of derived requirements.  \n Enforce peer review  best practices.  \n Create and execute a documented test plan .  \n Implement, v alidate , and verify test processes  which include design/test team \nseparation, peer reviews, and use of automated tools where applicable . \n Select a formal proof process  that can validate the equivalency of the HDL and \nthe final configuration file. For more information on proof tools, con tact JFAC.  \nDescriptions  \nMaintain b i-directional link to  requirements  \nAll requirements should be documented and traced.  Functionality that is not associated \nwith a requirement should not be allowed.   \nEnforce peer review  \nEstablish and enforce peer review pra ctices with the following:  \n The author and the reviewer must be different people.  \n Ensure the design process has time allocated for code reviews.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  27 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Code review should be done in parallel with development, reviewing small \nchunks at a time.  \n Anyone reviewing t he code should already be familiar with the approved  \narchitecture.  \n All black box portions of the design must be identified, justified , and approved.  \n All scripts that produce design artifacts (HDL, Netlist, etc.) must be reviewed and \napproved. Ensure ther e are no unexpected paths, filenames , or suppressed \noutputs.  \n Ensure the code reviews, at a minimum, verify:  \n The code does what it is intended to do.  \n The code can be traced to requirements.  \n The code is not needlessly complex.  \n Coding standards are being utilized.  \n No extraneous code exists. T he developer is not implementing \nunapproved items that may have future utility.  \n The code has appropriate unit tests.  \n Tests are well designed.  \n The code uses  clear names for everything.  \n Comments are clear and useful , and mostly explain why instead of \nwhat.  \nExecute a documented test plan  \nThe programs should consider assurance when creating and maintain ing the test plan.  \nThe test plan and processes should at least:  \n Provide a  mechanism to verify all requirements.   \n Explicitly list code coverage metrics, the type of testing that will be performed, \nand acceptable testing guidelines.  Code coverage should state how much code \nis checked by the test bench, providing information about dead code in the \ndesign and holes in the test suites. Document the  decision to use/not use other \ntypes of testing , such as directed test, constrained random stimulus, and \nassertion.  \n Specify the verification environment which describes the tools, the software, and \nthe equipment needed to perform the reviews, analys es, and tests. Each of these \nitems should be maintained under revision control.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  28 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Document and analyze unexpected  behavior and final implementation \nconclusions.  \n Ensure code coverage includes statement coverage, branch coverage, FS M, \ncondition, expression, and toggle coverage. Document any code that will not be \ncovered and why. Ensure untested code is documented and reviewed through \nthe review process. Use functional test s to verify the FPGA does what it is \nsupposed to do. Any devia tions must be documented and approved.  \n Ensure all test discrepancies, bugs, etc., are resolved via a change process.  \nImplement, validate , and verify test processes  \nThe program should take care to ensure test processes con sider assurance needs.  This \ninclude s design/test team separation, peer reviews, and use of automated tools where \napplicable.  All test discrepancies, bugs, etc. , should be resol ved via a change process \nutilizing  a change management system.  The established p rocesses should be \ndocumented, enfo rced, and audited . \nSelect a formal proof process  \nUse logical equivalency checking to the greatest extent possible. Equivalency checking \nis used to prove the tools did not modify the logic or configuration settings. To do this, \nthe final bitstream  is comp ared to the originating application HDL  to demonstrate they \nare logically equivalent with no extraneous logic in the final format. This approach \nconfirms Trojans were not inserted during the implementation steps.  This check also \nconfirms configuration sett ings ar e maintained and not altered. Configuration settings \nare those parameters included in the configuration file that affect the behavior of the \nFPGA device itself , but are not a part of the program application. Examples would \ninclude tamper settings, Joint Test Action Group ( JTAG ) settings , and key storage.  \nThere are technical challenges associated with performing logical equivalency checking \n(LEC) on FPGA data . Contact JFAC for information on  emerging industry tools that can \nassist in identifying configuration data in the FPGA formats  or automate the creation of \nhints files.  \nTD 3.4 Mitigating the i ntroduction of compromised tooling  or software \ninto the e nvironment  \nIn this scenario, the adversa ry introduces compromised tooling or software into the \nenvironment. This can be accomplished by an insider or through network intrusion.   \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  29 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nMitigations   \n Validate cryptographic hashes  against hash es signed by the vendor.  \n *Research vulnerabilities  affecting  tools/platforms using commercial and JFAC -\nprovided resources. If vulnerabilities are found, use an alternate or newer version \nthat does not have the vulnerability. Alternatively, perform a risk assessment and \ncoordinate findings with JFAC.  \n *Validate tools , ensuring they deliver the expected output . \nDescriptions  \nValidat e cryptographic hashes  \nAll parts of the software delivery should be authenticated by comparing the \ncryptographic hash of all received software against the hash signed by the vendor. This \nincludes  install macros and other support functions. Only accept certificates validated \nby reputable third parties. Only accept publicly released software and document the \nsource of the hash signature and the hash itself.  \nResearch vulnerabilities  \nSoftwa re and tooling vulnerabilities can be exploited for nefarious purposes. The \nprogram should actively monitor for vulnerabilities and perform risk assessment for any \nsoftware or tools selected.  Platforms and tool vulnerabilities can be found in databases \nsuch as:  \n Common Vulnerabilities and Exposures (CVE)  https://cve.mitre.org   \n National Vulnerabilities Database (NVD)  https://nvd.nist.gov   \n Government Industry Data Exchange Program ( GIDEP)  \nhttps://www.gidep.org/products/products.htm  \n DISA Security Technical Implementation Guides (STIG s)  \nhttps://public.cyber.mil/stigs/  \n Searches for vendor advisories, publications , and academic papers detailing \nvulnerabilities in the device in question.  \nIf vulnerabilities are found in the software or tools , choose one  of the following options:  \nOption 1: Select a different  tool or software that does not have published vulnerabilities  \nand meets the program requirements . \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  30 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nOption 2: Use standard formal processes and procedures to work with the vendor to \nresolve the vulnerability. Once a fix is identified, only accept formal releases, do not \naccept custom beta fixes, custom patches, etc. f or incorporation . \nOption 3 : The program can internally determine the vulnerability poses no significant \nrisk to their product . JFAC is available to provide assistance in assessing the risk that \nthe vulnerability poses to the system and acquire recommended mitigations for a \nparticular vulnerability.  \nNote:  If a vulnerability is identified, it is recommended to report it to the Government \nIndustry Data Exchange Program ( GIDEP) and to contact the vendor so they may \ncorrect it . \nValidate tools  \nValidate that the t ool delivers the expected output by selecting from one of the options \nbelow:  \nOption 1: Utilize a reproducible build process  to generate any deployable configuration \nfiles. \nOption 2: Select a formal proof process  that can validate the equivalency  of the HDL \nand final configuration file.  \nReproducible build process  \nA reproducible build process is a methodology to verify the integrity of the FPGA \nsynthesis and build software. A reproducible build performs the synthesis process \ntaking  in human readabl e HDL, and other human readable inputs, and consistently \ngenerates the same final configuration file (bitstream) . At LoA 2 reproducible builds \nshould be performed using in dependently acquired software and installed independently \non two distinct computers. I t is expected that this process will, in most cases, require the \nuse of the same version of the EDA tools, and in some cases the same operating \nsystem version. This process will highlight the possession of modified software where \nthere is a mismatch. Conta ct the FPGA software vendors for more information on how \nto perform reproducible builds.  \nSelect a f ormal proof process  \nUse logical equivalency checking (LEC) to the greatest extent possible.  LEC checking is \nused to prove the tools did not modify the logic or configuration s ettings.  To do this , the \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  31 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nfinal bitstream  is compared to the originating application HDL  to demonstrate they are \nlogically equivalent with no extraneous logic in the final format. This approach c onfirms \nTrojans were not inserted during the implementation steps.  This check also confirms \nconfiguration settings ar e maintained and not altered. Configuration settings are those \nparameters included in the configuration file that affect the behavior of the FPGA device \nitself, but are not a part of the program application. Examples would include tamper \nsettings, JTAG settings , and key storage.  \nThere are technical challenges associated with performing logical LEC on FPGA data . \nContact JFAC for information on  emerging industry tools that can assist in identifying \nconfiguration data in the FPGA formats  or automate the creation of hints files.  \nTD 3.5 Mitigating  intrusion into the internal network  \nIn this scenario, an adversary gains access to the internal network. With this access, the \nadversary can em ploy multi ple methods to achieve  nefarious intention s, such as \nmodif ying tools, swap files, etc.   \nMitigations   \n Assign roles . \n Control and monitor access  based on job requirements  including use of physical \nrestrictions.  \n Periodically research  vulnerabilities  using commercial and JFAC -provided \ninformation. If vulnerabilities are found, use an alternate or newer version that  \ndoes not have the vulnerabilities . Alternatively, perform a risk assessment and \ncoordinate findings with JFAC.   \n Purchase from DoD-authorized vendor s and  distributors  per D oD guidance.  \n *Use trusted  computing environment s to protect from remote attack . \nDescriptions   \nAssign r oles  \nEmployees should be assigned a specified role with associated accesses and privileges \nbased on the rol e. At a minimum, these roles should include design, test, network \nadministration , and system administration. Roles should also be defined and \ndocumented with no overlap. Users should not have multiple roles.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  32 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nNote : In many real -world flows, designers and te sters will require elevated privileges . \nSome of these elevated privileges may be shared with system administrators. Some \nmay have names (\"local admin,\" \"root,\" etc.) that imply system administration. For \nexample, a member of the design team working on a so ftware hardware interface may \nrequire local administrati ve privileges to install and debug their work. A member of the \ntest team for an FPGA -based device connected to an IP network might require the \nability to configure multiple network devices in the test  environment, as well as to \nconnect a computer in promiscuous mode to that same test environment. Those \naccesses represent a part of the design or test role. However, these must be based on \nthe needs of the design or test process.  \nElevated privileges on co mputers should be grant ed only as needed, and kept local to \nspecific computers. Elevated privileges should never include administrative access to \nrevision control servers, software installation, or other corporate infrastructure.  \nElevated privileges on net works should be limited to distinct test networks, properly \nisolated from the design environment and the corporate network.  \nControl and monitor access  \nEmployees should only have access to areas, equipment, data, and information \nnecessary to meet the requirements of their assigned job. Entry/access to appropriate \nareas should be recorded, monitored, and logged for auditability.  \nResearch vulnerabilities  \nSoftware and tooling vulnerabilities can be exploited for nefarious purposes. The \nprogram should act ively monitor for vulnerabilities and perform risk assessment for any \nsoftware or tools selected. Platforms and tool vulnerabilities can be found in databases \nsuch as:  \n Common Vulnerabilities and Exposures (CVE)  https://cve.mitre.org   \n National Vulnerabilities Database (NVD)  https://nvd.nist.gov   \n Government Industry Data Exchange Program (GIDEP)  \nhttps://www.gidep.or g/products/products.htm  \n DISA Security Techni cal Implementation Guides (STIG s)  \nhttps://public.cyber.mil/stigs/  \n Searches for vendor advisories, publications , and academic papers detailing \nvulnerabilities in the device in question.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  33 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nPurchase from DoD -authorized vendors and distributors  \nUse DoD -authorized vendors and distributors for all purchases . Authorized vendors can \nbe located through the acquisition organization.  \nUse t rusted computing environments  \nPrograms should select one of the trusted computin g environment  options below, to \nprotect from remote attack.   \nOption 1: A computer and network classified at the Defense Security Cooperation \nAgency (DSCA ) Secret  level or above.  \nOption 2:  A computer and network certified for use in a Trust Category 1 faci lity as \ndefined by Defense Microelectronics Activity (DMEA ).  \nOption 3 : A network -isolated computer enclave with limited and controlled access. This \nis a computer with the vendor software installed by a network administrator. This \nadministrator should not be a designer working on the application design.   \nOption 4:  An infrastr ucture minimally compliant with NIST SP 800 -171 and NIST SP \n800-172, preferably compliant with Cybersecurity Maturity Model Certification (CMMC).  \nTD 3.6 Mitigating risk from a c ompromised hire or employee  \nThis scenario involves the compromise of an employe e with access to the design, tools, \nor network being used for design or test.   \nMitigations   \n Enforce auditability  of the requirements, architecture, design , code, test s, bugs, \nand fixes. At a minimum, audit data includes what decisions were made, by \nwhom, f or what reason, and on what date.  \n Adhere to an approved design process . \n Identify, document , and review critical activities . These items should be reviewed \nby a cle ared individual that is different than the o riginal designer.  \n Use cleared pe rsonnel  to perform  the design work in an environment certified to \nhandle classified material at the Secret  level or higher by  DSCA . This would also \ninclude design centers certified for Trust Category I by the DMEA.  \nDescriptions  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  34 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nEnforce auditability  \nThe program should maintain audit logs on all design data to include req uirements, \narchitecture, design, code, test s, bugs , and fixes. The audit data minimally should \ndocument who requested the change with date timestamp, what  decision was made \nregarding the change, who made  the decision w ith date and timestamp, why the change \nwas requested, and who made the change with date timestamp . \nAdhere to an approved design process  \nThe design process should contain clear entry and exit criteria. Entry and exit criteria  \nshould  incorpora te peer reviews and technical reviews with management approval to \nexit a phase.  \nReview critical activities  \nEnsure all critical activities are identified, documented, and the entire design is reviewed \nby multiple cleared individuals other than the original designer. Reviewers should \nassess all critical activities . Specific considerations include:   \n Design source files in conjunction with behavioral simulations   \n Design synthesis in conjunction with functi onal verification   \n Design i mplementation in conjunction with static timing analysis   \n Bitstream generation with reproducible build results   \n Programming in conjunction with in -circuit verification  \nEnsure that the review teams do not in clude the original desi gners. E ach reviewer \nshould hold a U .S. Secret  security clearance.  \nUse cleared personnel  \nUse personnel with at least a Secret  level clearance to perform designated work . \nTD 4: Adversary compromises system assembly , keying , or \nprovisioning  \nIn this threat, an adversary has carried out an attack on the system during printed circuit \nboard ( PCB) assembly, key injection , or flash provisioning. This attack could include the \nassembly house acquiring counterfeit parts on behalf of the end customer, swapping out  \nauthentic  FPGA parts for counterfeit ones, stealing  or compromising configuration data, \nor stealing or modifying keys. Multiple parties can be involved during th e system \nassembly phase. The following areas of the supply chain are included in this threat:  \n Shipping devices to the PCB assembly facility  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  35 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Transmitting keys, configuration data , and FPGA part numbers to the assembly \nfacility  \n Injecting keys into the FPGA devices  \n Provisioning the configuration storage devices  \n Attaching the FPGA devices to the PCB  \n Testing PCBs \n Shipping the PCBs to the next manufacturing stage  \nOf particular concern in this attack is the assumed existence of a cleared insider \nworking maliciously in some portion of this manufacturing process. At LoA2, this insider \ncould be working alon e or in partnership with an external party to influence the outcome. \nThe mitigations for this threat  are built upon the  following  premises:  \n All assembly work requires after -the-fact validation in a cleared facility.  \n If assembly work is conducted in a class ified facility, a single verification team \nindependent of those who conducted the assembly work, can do the post -fab \nvalidation . In this case, the cleared insider can compromise the device, or the \nvalidation process, but not both, which would be necessary to enable the threat.  \n If assembly work is conducted in an external ( i.e., third-party  unclassified) facility, \nthen two independent cleared teams made up of different individuals can do the \nvalidation process . In this scenario, the cleared insider could com promise the \nvalidation process to allow compromi se while the parts were outside the control \nof the program. However, t he dual nature of the validation prevents this from \nhappening.  \nTherefore, this document recommend s mitigations for the two paths: assembly  in a \nclassified facility or inclusion of an external facility.  \nTD 4 mitigations  \nRegardless of where the work is performed, th e program should  implement the following \nlist of mitigations in the assembly, keying and provisioning process:  \n Purchase from DoD -authorized vendors and distributors . The Do D program \nacquisition group can provide this information.  \n Follow storage and shipping guidance  for FPGA devices . \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  36 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Provide keys  and configuration data  to the provisioning house in digitally signed \npackages and with hashes .  \n Prior to provisioning, clear memory devices  that store configuration data  \n Provision private keys  into the FPGA devices in a DSCA -classified Secret  or \nTrust Category I certified facil ity after the assembly process.  \n Protect  the configuration data package  for the assembly house and the validation \nteam .  \n Following assembly and provisioning, perform verification  activities  in a DSCA -\nclassified Secret  or Trust Category I certified facility.  \n *Authenticate the FPGA device  after being ou t of the control of the program . \nTD 4 m itigation descriptions  \nPurchase from DoD -authorized vendors and distributors  \nUse DoD -authorized vendors and distributors for all purchases . Authorized vendors can \nbe locate d through the acquisition organization . \nFollow s torage and shipping  guidance  \nThe program should document, maintain , and enforce both device storage and shipping \nprocedures. Minimally, the plan should enforce the verification of all devices  upon \nreceipt.  Once verification has taken place, production devices should be stored and \nmaintained in a restricted area separate from non -production devices (design, test, \netc.). Production devices should be continuously tracked to include arrival of the device \nby uni que identifier, interaction anyone has with the device, and exit of the device from \ninventory.  The restricted area should enforce access control that limits access to only a \nminimum subset of people that require access to support direct job responsibilitie s and \nexcludes all members of the design team.  The restricted area should have a clearly \ndefined perimeter, but physical barriers are not required. Personnel within the area \nshould be responsible for challenging all persons who may lack appropriate access \nauthority.  The restricted area access should be audited to include data containing who \nentered/exited the area , with a timestamp , and reason for entry.  \nShipping should be controlled and managed. JFAC recommends shipping material \nusing a commercial carrier that has been approved by the CSA to transport Secret  \nshipments, although the material is not Secret . Commercial carriers may be used only \nwithin and between the 48 contiguous States and the District of Columbia or wholly \nwithin Alaska, Hawaii, Puerto Rico , or a U.S. possession or trust territory.  When \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  37 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nshipping using a commercial carrier , take efforts to afford additional protection against \npilferage, theft, and compromise as follows.  This includes using hardened containers , \nunless specifically authorized o therwise , and ensuring the packages are sealed.  The \nseals should be numbered and the numbers indicated on all copies of the bill of lading \n(BL). When seals are used, the BL shall be annotated substantially as follows: DO NOT \nBREAK SEALS EXCEPT IN CASE OF E MERGENCY OR UPON PRIOR AUTHORITY \nOF THE CONSIGNOR OR CONSIGNEE. IF FOUND BROKEN OR IF BROKEN FOR \nEMERGENCY REASONS, APPLY CARRIER'S SEALS AS SOON AS POSSIBLE AND \nIMMEDIATELY NOTIFY BOTH THE CONSIGNOR AND THE CONSIGNEE.  \nProvide k eys and configuration data  \nProvide keys and configuration data to the provisioning house in digitally signed \npackages and with hashes. JFAC recommends that these data packages be encrypted \nusing the A dvanced Encryption Standard (AES)  algorithm with a key of at least 256 -bit \nlength. T he assembly house should verify the signature and hash to verify the integrity \nof the contents .  \nClear memory devices  \nPrior to provisioning, clear memory devices  that store configuration data . This prevent s \nan adversary from storing malicious configuration data in non -used areas of the memory \ndevice . These memory devices could include a discrete PCB component like a Flash or \nthe on -chip FPGA non -volatile storage available on certain devices.  \nProvision privat e keys  \nProvision private keys  into the FPGA devices in a DSCA -classified Secret  or Trust \nCategory I certified facility after the assembly process.  \nProtect the configuration data package  \nThe program should ensure there are processes in place to provide the configuration \ndata to each entity . The data should be provided directly and independently to each \ndestination . The assembly house should not be used to pass the data to the test facility . \nEnsure there is a golden copy provided to each functional area , ensu ring the same data \nis transmitted.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  38 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nPerform v erification activities  \nFollowing assembly and provisioning, perform all verification activities  in a DSCA -\nclassified Secret  or Trust Category I certified facility.   \nIf all the work is conducted in a classified setting, a group independent from the \nassembly and provisioning team should be utilized to conduct the validation . As LoA2 \nassumes a single compromised insider, th is mitigation strategy means that the insider \ncan only be in either the assembly team or the validation team , but not both.  \nIf any of the work is done in an external facility, use two separate groups independent \nfrom the assembly process to conduct the validation. As LoA2 assumes a single \ncompromised insider, th is mitigation strategy means that th e insider can be in only one \nof the validation teams.  \nNo matter where the work is perfo rmed the following actions must be completed:  \n Verify  the PCB traces related to the FPGA device, the configuration memory \ndevices, and any other devices related to  the au thentication of the configuration \ndata. The program should rely on guidance from the JFAC PCB Executive Agent \nto perform this verification.  \n Verify  the authenticity of the configuration data loaded on the FPGA memory \ndevice following provisioning and assemb ly. The verification can be executed by \na bit comparison or a hash. A team independent of the assembly and \nprovisioning process must perform this verification.  The verification should cover \nthe entire contents of the memory device and not just the addresse s containing \nthe configuration data.  It is recommended to program the entire memory space to \ndisallow unused memory for nefarious purposes.  \n Verify  using cryptographic authentication of all loaded configuration data as part \nof the system containing the FPGA . The authentication methodology should \nverify both the source and contents.  \n Verify  that the proper post assembly keys have been loaded into the FPGA key \nstorage elements. A team independent of the assembly and provisioning process \nmust perform this verifi cation. Some FPGA devices allow a hash of the keys to \nbe read out for confirmation . Additionally, the program can create test bitfiles to \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  39 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nverify that the devices can properly use the keys and can reject actions using  the \nwrong keys.  \n Verify  the authenticity of the FPGA device to rule out the introduction of a \ncounterfeit part during assembly.  \nAuthenticate the FPGA device  \nWhen the FPGA has been out of positive control of the program it must be \nauthenticated.  The program should select one of the options below:  \nOption 1: Verify the device on the PCB is an authentic and authorized device by \nvalidating that each device has a unique cryptographic ID signed by the vendor. Each \ndevice must contain a unique private asymmetric key for which no read fu nction exists, \nand validation must involve the device signing a nonce. A NIST -approved asymmetric \nauthentication algorithm  must be used for this. The program should authenticate the \nFPGA devices utilizing this ID when they have been out of the positive con trol of the \nprogram.  \nOption 2: Verify the device on the PCB is an authentic and authorized device by \nperforming physical counterfeit inspection with destructive sampling  as described in \nPerform p hysical inspection /analysis  under TD 2: Adversary inserts malicious \ncounterfeit . This is primarily an SAE International A S6171 Test Methods Standard; \nGeneral Requirements, Suspect/Counterfeit, Electrical, Electronic and \nElectromechanical Parts -based evaluation, with requirements to obtain vendor \ninformation.  \nOption 3: Use a soft PUF. Verify the device on the PCB is an authentic and authorized \ndevice by utilizing a soft PUF to create unique IDs. The soft PUF is used to validate the \nintegrity of the devices when they are outside of the program's control. The program \nshould generate these IDs when FPGAs are in their contro l by loading the soft PUF into \nthe FPGA fabric, use it to generate a unique ID for the respective device , and then \ndelete the PUF. Following assembly, the program should repeat this process and \nensure the ID matches, authenticating the device.  If the soft PUF will be used  to \nauthenticate the device when it is outside the program control, it is recommended that \nthe following be done:  \n Prevent readout of the PUF output to the FPGA s external pins.  \n Utilize the PUF to encrypt a nonce that can transmit outside th e device.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  40 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Utilize  a public key based on the PUF value to decrypt the nonce and \nauthenticate the device.  \nThis approach can be used to support remote attestation when needed.  \nTD 5: Adversary compromises third-party soft IP  \nIn this threat,  an adversary compr omises third -party soft IP intended for integration into \nthe configuration of the FPGA. The compromise can occur during the vendors \ndevelopment cycle, during its delivery or while at rest at the programs design center. In \nall scenarios, the compromised I P contains a malicious function that was inserted during \nits design and can be triggered through some input to the FPGA, or when a specific \nscenario occurs. In all cases, it is important to remember the purpose of the Trojan is \nunknown, but probably impact s include performance, power, and reliability. The \nmitigations to these attacks focus on verifying integrity of the delivery of the IP and \nreviews of its HDL code.  \nTD 5  mitigations  \n Purchase from DoD -authorized vendors and distributors . \n Only a ccept IP that is unobfuscated  and distributed as source  code.  \n Validate  the cryptographic  hash of the IP  against the hash signed by the vendor.  \n Store IP in a revision  control  repository  immediately upon receipt with the hashes \nused to authenticate the contents. Protect ion of the hash es will allow for re -\nverification of the IP at a later date.  \n *Examine IP for malicious functions . \nTD 5 mitigation d escriptions  \nPurchase from DoD -authorized vendors and distributors  \nUse DoD -authorized vendors and distributors for all purchase s. Authorized vendors can \nbe identified  through the acquisition organization . \nOnly accept  IP that is un obfuscat ed  \nOnly accept IP that is  unencrypted, unobfuscated , and distributed as source code.  \nValidate the c ryptographic hash  of the IP  \nEnsure that the cryptographic hash of the IP  is validated against the hash signed by the \nvendor.  All parts of the software delivery should be authenticated in this manner \nincluding install macros and other support functions. The program should only accept \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  41 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \ncertificates v alidated by reputable third parties. The program should be limited to \npublicly released software. The program should maintain documentation of the source \nof the hash and the actual software hash.  \nStore IP in  a revision control  repository  \nImmediately upon receipt , the IP with its associated hash should be checked into \nversion control.  The hash of the IP should be verified at various stages to ensure there \nhave been no modifications . \nExamine IP for malicious functions  \nTo examine  the IP for malicious functions  choose one of the following options : \nOption 1: Using JFAC guidance captured in Third -Party IP Review Process for Level of \nAssurance 2,  two cleared personnel review the IP. JFAC can provide this document \nupon request.  \nOption  2: Contact JFAC to determine if an IP review of the complete IP package has \nbeen successfully completed.  \nNote: Although the results may not be perfect, it is good practice to utilize Trojan \ndetection tools. Contact JFAC for more information.  \nTD 6: Adversa ry swaps configuration file on target  \nIn this threat, an adversary obtains access to the system during or after assembly and \ncan compromise the FPGA devices operation via the configuration data.  \nFor assurance purposes, these guidelines are not concerned w ith the exposure of the \nconfiguration data or the confidentiality of the public keys, as they do not compromise \nthe authentication of the data. However, programs with security requirements may need \nto protect this information and can choose to implement ad ditional protections.  \nTechnological mitigations exist publicly for this threat , such as configuration data \nauthentication. Mitigations must involve authenticating the configuration file for both \nintegrity and provenance.  JFAC encourages programs to use dev ice families that \nsupport configuration data authentication .  \nFor legacy devices that do not have authentication functions, mitigations lean on \nexternal authentication functions or the use of symmetrically encrypted data files. In this \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  42 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \ncase , authentication  practices apply to all configuration file loads , including local  loads , \nremote updates, multi -boot scenarios , configuration via software , and configuration via \nprotocol where the configuration file is loaded into the FPGA. For devices that store the \ndata internally in non-volatile memory , this requirement only applies to the initial loading.  \nAs of October  2022 , all the major U.S. FPGA vendors provide built -in functionality to \nauthenticate configuration files either at load into internal memory or at config uration. \nThe specifics of this authentication vary greatly , with some older devices relying on \nsymmetric cryptography rather than asymmetric cryptography. Older devices supported \nencryption but not authentication, leading some organizations to confuse the two.  \nThe exact details of key management and storage vary from device to device. Some \noffer facilities to store many authentication keys, some use fuses, and others use \nindependently powered random access memory  (RAM). Further, there are public \ntechniques  to subvert the authentication, which  have complex implications for the \nsecur ity of built -in authentication1. \nThe result is that the exact security of each method is not apparent without a detailed \nevaluation. This report communicates  the specific mechanis ms that meet JFAC \nexpectations, as well as caveats for their use.  \nAt LoA2 , the program must use NIST -approved asymmetric cryptographic algorithms.  \nTo achieve LoA2, all boot/configuration images must be authenticated with respect to \ntheir source and data i ntegrity. That is, the device must validate that the file comes from \nan authorized provider and that the data has not been modified prior to loading. For \nLoA2, the recommended method for authenticating the data source is to use an \nasymmetric algorithm reco mmended by NIST.  Asymmetric algorithms are preferred \nbecause they do not require the protection of a secret key. For data integrity, a hashing \nalgorithm , such as the secure hashing algorithm  (SHA), is recommended. Many of the \nexisting FPGA devices provide these functions for the user.  \nThis level of assurance addresses  the compromise of a single cleared insider. That \ninsider can introduce malicious counterfeit parts at any part of the device creation \nlifecycle or can compromise any single part of the valida tion process.  \n                                                \n1 The Unpatchable Silicon: A Full Break of the Bitstream Encryption of Xilinx 7 -Series FPGAs. Usenix Security 20. Maik Ender, Amir Moradi, Christof Paar.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  43 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 6  mitigations  \n Incorporate cryptographic authentication  of all loaded configuration data as part \nof the system containing the FPGA.  \n Design the system to authenticate configuration data each time the data is \nloaded  into the FPGA device.  \n Configure all production devices in a way to prevent direct read back  of the \nprivate keys through electrical means.  \n Use a CNSS/NIST  approved algorithm and key length . CNSS  for National \nSecurity  Systems ; otherwise , use a NIST approved algorithm and key length, as  \ndescribed in the latest approved version of FIPS 186 , Digital Signature Standard , \nor FIPS 198 , The Keyed -Hash Message Authentication Code (HMAC) . \n Use security -evaluated authentication  mechanisms . \n Disable operation or use of test access pins  in fielded products.  \n *When the program selects mechanisms that allow application modifications , \nensure authentication for modifications  is enabled following the required  NIST  \nstandards.  \n Generate and store all a uthentication keys on a program -controlled, FIPS 140 -2 \ncompliant, Level 2 Hardware Security Module (HSM) . \nTD 6 m itigation descriptions  \nIncorporate c ryptographic authentication  \nThe program should  enforce cryptographic authentication.  In addition, the progra m \nshould  maintain documentation including the authentication methodology, its \narchitecture , and compliance with appropriate NIST standards.  \nAuthenticate configuration data each time the data is loaded  \nDesign the system to authenticate configuration data ea ch time the data is loaded  into \nthe FPGA device.  \nPrevent direct read back  \nConfigure all production devices in a way that prevents direct read back  of the private \nkeys through electrical means.  \nUse a  CNSS/NIST approved algorithm and key length  \nIf the project is identified as an NSS, u se a CNSS Policy approved algorithm and key \nlength . Otherwise use a NIST approved algorithm and key length , as described in the \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  44 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nlatest approved version of FIPS 186 , Digital Signature Standard , or FIPS 198 , The \nKeyed -Hash M essage Authentication Code (HMAC) . \nUse security -evaluated authentication  \nThe program can either select an authentication mechanism with an existing evaluation \nor sponsor the evaluation itself. JFAC can perform evaluations and maintains best \npractices in us ing commercia l technology for this purpose. At a minimum, any \nevaluation must:  \n Ensure compliance with the current version of FIPS 186 , Digital Signature  \nStandard.  \n Authenticate all boot configuration data.  \n Confirm its ability to verify data integrity  using  positive and negative testing . \n Confirm its ability to verify the authorized source  using positive and negative \ntesting .  \n Ensure authentication is verified for  all configuration data regardless of how it is \nstored or delivered prior to or in parallel to co nfiguration.  \n Verify the authentication mechanisms do not contain any known vulnerabilities.  \n All keys must be generated and protected in accordance with FIPS 140 -2 Level \n22.  \n The use and operation of application test access is disabled in fielded products.  \nTest access pins  \nAll modern FPGA family devices have hardware test interfaces to support fabrication \ntesting of the device and testing of the user product.  These interfaces usually include \nJTAG pins and dedicated test pins.  \nJFAC recommends disabling  operation or use of these test access pins in fielded \nproducts. It is a common practice to disable these access points prior to fielding the \ndevice. JFAC recommends  disabling this in non -volatile fuses when available.  \nEnsure authentication for  modificati ons \nMany FPGA platforms contain mechanisms that allow the application to change itself. \nSome allow for true in -flight reprogramming, where some portion of the FPGA continues \nnormal operation while another portion changes its behavior. Others allow for \n                                                \n2 FIPS 140 -2 will be replaced at  a future date with FIPS 140 -3. \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  45 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nreprogramming via external storage.  Verify that the built -in application change technique \napplies authentication to all the reconfiguration data.  \nThe names of these operations are system specific and include terms like dynamic \nreconfiguration,  partial recon figuration,  in-application programming,  etc. In practice, \nthese mechanisms do not  provide the same degree of authentication that the primary \nprogramming mechanisms provide. Under these best practices, an application designer \nusing these techniques must either validate that the technique they use applies the \nauthentication scheme described below to all the configuration data or perform \nauthentication of this data in the application itself . \nAuthenticate  reconfiguration data in the application  itself  \nIn thi s case, the program incorporates functions in the application to perform \nauthentication on configuration data when the FPGA device cannot. When utilizing this \noption, the program should pay attention to the following considerations.  \nSystem -on-chip FPGAs (SoC FPGA s) incorporate central processing units  (CPU s) as a \ncomponent of a reconfigurable platform. The JFAC FPGA Best Practices do not seek to \nprovide software assurance to the application running in the CPUs of a SoC FPGA. \nHowever, the best practices li sted here will provide the same degree of assurance to \nthe initial user code (sometimes called a bootloader) executed by the CPU.  \nFrom there , it is possible for a designer to extend the same authenticity to the user code \nif their system requires it. In ca ses where the program uses an interface between the \nFPGA fabric and the SoC in order to have one function load the other, it is vital that no \npath exists from this interface to the I/O. It is up to the program to ensure that only the \napplication has access  to it.  \nIn some platforms, security settings can be programmed into both non -volatile storage \nin the device itself and as a setting in the configuration file loaded into the device. \nSetting s should always be programmed in the non -volatile storage of the d evice. In \nthose cases where use of security settings within the configuration file is acceptable, it \nmust  be explicitly noted.  \nSome platforms provide support for remotely updating the boot or configuration data on \nthe FPGA device. This update is sent via a  network, stored local ly on the FPGA device, \nand then loaded into the device by the application.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  46 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nAn application designer using these operations should implement one of the following \ntwo options:  \nOption  1: Validate that the built -in application change tech nique being used  fully applies \nauthentication to all the reconfiguration data.  \nOption 2:  Perform authentication of th e reconfiguration data in the application itself. \nMany platforms support the ability to load different boot or configuration files from a \nlocal memory. This methodology involves the current application instructing the device \nto point to a new memory location for the boot/configuration information. In these cases, \nthe device maintains a pointer to the original data if there  is a load error wit h new file. It \nis necessary to ensure that all boot/configurations can be authenticated with respect to \nits source and data integrity in the same manner as the base load. Many devices leave \nthis to the application to perform.  \nGenerate and store all authent ication keys on a program -controlled, FIPS 140 -2 \ncompliant, Level 2 HSM  \nGenerate and store all authentication keys on a program -controlled, FIPS 140 -2 \ncompliant, Level 2 Hardware Security Module (HSM) with the HSM configured to \nenforce role -based restricti ons on the use of the keys. Maintain an approved list of \nindividuals who can access the keys.  \nIt is worth noting that there are additional protections that can be applied to the FPGA \nconfiguration data when its fielded location is physically unguarded. The se include:  \n Configuration file encryption using a NIST - or DoD -approved algorithm.  \n The use of split decryption keys to make key theft more difficult. This involves \nstoring multiple keys throughout the system, concatenating them, and then using \nthe hash of the concatenation as the decryption key.  \n The use of PUFs for key generation or a combination of PUF output and stored \nkey. \n Utilize any additional key protection mechanisms provided by the vendors.  \n Utilize good physical access protections for the PCB.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  47 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 7: Adversary substitutes modified FPGA software design \nsuite \nIn this threat , an adversary replaces the design suite an  application designer uses  with \none modified to subvert the application during synthesis, place and route , or \nconfiguration data generation. To accomplish this , the adversary would have access to \na modified version of commercial vendor software and would use the modified software \nto: \n Subvert the security features of an FPGA during configuration data generation . \n Insert a malicious function into the device during synthesis, place and route or \nconfiguration data generation.  \n Insert a data leak or backdoor into the synthesized device during synthesis , place \nand route , or configuration data generation.  \nThis subverted  tool would then be entered into the programs design environment by a \nvendor insider, an adversary -in-the-middle  technique,  or through a network intrusion. \nThis threat does not  include the scenario where an FPGA vendor insider modifies the \nauthorized soft ware for maliciou s purposes. That is covered by TD 10: Adversary \nmodifies vendor FPGA software design suite during development.   \nTD 7  mitigations  \n Purchase from DoD -authorized vendors and distributors . The Do D program \nacquisition group can provide this info rmation.  \n Prevent automatic  tool updates  by using a n installation  and update process  that \ndoes not require I nternet connectivity.  \n Install and execute software using a trusted  comp uting environment . \n Use cleared  personnel  with at least a Secret  level clearance . \n *Validate the  cryptographic  hash  against the hash signed by the vendor. All parts \nof the software delivery should be authenticated in this manner including install \nmacros and other support functions. The program should only accept certificates  \nvalidated by reputable third parties. The program should be limited to publicly \nreleased software. The program should maintain documentation with the source \nof the vendor -provided has h and the actual software hash.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  48 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 7 mitigation d escriptions  \nPurchase fr om DoD -authorized vendors and distributors  \nUse DoD -authorized vendors and distributors for all purchases . Authorized vendors can \nbe identified  through the acquisition organization.  \nPrevent a utomatic tool updates  \nPrevent automatic tool updates  by using an installation and update process that does \nnot require Internet connectivity.  \nUse a t rusted computing environment  \nPrograms should select one of the trusted computing environment options below, to \nprotect from remote attack.  \nOption 1: A computer and network classified at the Defense Security Cooperation \nAgency (DSCA ) Secret  level or above.  \nOption 2:  A computer and network certified for use in a Trust Category 1 facility as \ndefined by Defense Microelectronics Activity (DMEA ).  \nOption 3 : A network -isolated computer enclave with limited and controlled access. This \nis a computer with the vendor software installed by a network administrator. This \nadministrator should not be a designer working on the application design.   \nOption 4:  An infrastr ucture minimally compliant with NIST SP 800 -171 and NIST SP \n800-172, preferably compliant with Cybersecurity Maturity Model Certification (CMMC).  \nUse cleared personnel  \nUse personnel with at least a Secret  level clearance to perform designated work.  \nValidat e the c ryptographic hash  \nEnsure the cryptographic hash of the software deliverable is validated against the hash \nsigned by the vendor. All parts of the software delivery should be authenticated in this \nmanner including install macros and other support fu nctions. The program should only \naccept certificates validated by reputable third parties. The program should be limited to \npublicly released software. The program should maintain documentation with the source \nof the vendor provided hash and the actual sof tware hash.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  49 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nWhen  the hash of the software deliverable does n ot match the expected authorized \nhash value , work with the vendor to understand what caused the mismatch and take \ncorrective action.  If a resolution cannot be found, use a different software packa ge in \nwhich the hash can be validated.  All non -hash -validated software is a risk.  \nWhen  the hash is not provided  choose one of the following options : \nOption 1: Independently validate the hash , ensuring  at least two cleared individuals \nseparately validate the cryptographic hash of two separately purchased versions of the \ntool.  \nOption 2: Select a formal proof process  to perform logical equivalency checking \nbetween the application HDL and final configuration data.  \nOption 3: Use a reproducible build process  to validate the software.   \nSelect a formal proof process  \nUse logical equivalency checking to the greatest extent possible. Equivalency checking \nis used to prove the tools did not modify the logic or configuration settings. To do this, \nthe final bitstrea m is compared to the originating application HDL  to demonstrate they \nare logically equivalent with no extraneous logic in the final format. This approach \nconfirms Trojans were not inserted during the implementation steps.  This check also \nconfirms configura tion settings ar e maintained and not altered. Configuration settings \nare those parameters included in the configuration file that affect the behavior of the \nFPGA device itself , but are not a part of the program application. Examples would \ninclude tamper se ttings, JTAG settings , and key storage.  \nThere are technical challenges associated with performing logical equivalency checking \n(LEC) on FPGA data . Contact JFAC for information on  emerging industry tools that can \nassist in identifying configuration data in the FPGA formats  or automate the creation of \nhints files.  \nUse a r eproducible build process  \nWhen using reproducible builds to validate software , enlist a third party to mirror the \nFPGAs synthesis, place and route, and configuration file generation. If the mirroring is \nexecuted properly and independently, the outputs can be compared to verify that the \nvendor software package is unmodified or modifie d in a way that does not affect the \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  50 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \napplication design. To ensure proper execution of this mitigation, the following must be \nobserved:  \n The software used to mirror the programs synthesis effort must be procured in a \nmanner to make it independent from the procurement of the original version.  \n The reproducible build software should be loaded/installed by a different \nadministrator than the administrator that performed the original install.  \n This mitigation requires independent duplicative activities since  the \nadversary could have knowledge about the project and how it obtains, \nloads , and controls its tools.  \n The mirrored effort should utilize the same version of the software on the same \noperating system and version.  \n The application development teams software and  the mirroring software should \npossess matching hashes and size values.  \n The mirrored effort must utilize the same HDL code, IP , and synthesis scripts.  \n The mirrored effort must utilize the same vendor tool settings.  \n The output of the effort is an unencrypt ed, uncompressed configuration data file.  \nContact  the FPGA software vendor for more detailed guidance on creating reproducible \nbuilds. They have already performed work in this area and can assist with documented \ninstructions.  \nBoth the development effort an d the mirror effort should execute the FPGA \ndevelopment flow from synthesis to configuration file output and then perform the \nfollowing steps:  \n Throughout the flow, output any intermediary files that can be used to compare \nresults at various stages. This ca n include primitive netlists, synthesized netlists, \nphysical netlists , and final configuration data files.  \n Compare the final configuration files for size and content. They should match in \nall respects except for header information that may include timesta mps and other \nproperty information.  \n If the files are encrypted, take steps to ensure that any nonces, such as the \ninitialization vector, used by both efforts are the same.  \nIf discrepancies are found in the comparison, the following steps should be followe d: \n Contact  the software vendors for assistance.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  51 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Contact  JFAC for assistance in resolving the discrepancy.  \nIf a software version does  not match what was expected, JFAC recommends  report ing it \nto the vendor for further analysis and correction.  \nTD 8: Adversar y modifies FPGA platform family at design  \nIn this threat, an adversary inserts a malicious function or preplaces a vulnerability for \nlater use in an FPGA device during its hardware design phase. This attack involves a \nnetwork intrusion  or a compromised insider working for the vendor or one of its \nsubcontractors. While this attack lacks the ability to target an individual program, it can \npreposition a vulnerability for later use.  \nTD 8  mitigations  \n Engage JFAC  to evaluate the FPGA device fami ly. \nTD 8 mitigation description  \nEngage JFAC  \nJFAC recommends  the program engag e JFAC  to evaluate the chosen FPGA device \nfamily of choice or to acquire information garnered from previous evaluations. JFAC will \nthen instruct the  program on what steps to take to identify malicious code or \nweaknesses in their FPGA platform. The program may be asked to conduct a subset of \nthe evaluation steps in partnership with JFAC. In parallel, JFAC may evaluat e the  FPGA \ndevice famil y for malicious  behavior and operational weaknesses. In addition, JFAC has \nbeen evaluating commonly used FPGA device families proactively.  \nIn support of this mitigation, JFAC asks all programs seeking LoA compliance at any \nlevel to provide JFAC with information regarding  the FPGA devices they are using along \nwith a brief summary of the ir use. This information will be comp iled to create a picture of \nwhich  FPGA s are of greatest interest to Do D and which ones might represent a \nvulnerability to multiple programs. This informa tion will drive the decision -making behind \nwhich device families to analyze for vulnerabilities.  \nJFAC communicates this information at a variety of classification levels. Please contact  \nJFAC to obtain the appropriate email address  at https://jfac.navy.mil.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  52 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nRefer to Appendix B: JFAC FPGA Reporting Template  for the information a program \nshould include in the e -mail.  \nAs evaluations are completed, JFAC will document the findings for programs to use in \ntheir vulnerabilit y research.  \nFinal ly, JFAC recommends  that program s utilize newer and more modern device \nfamilies when possible . The se families  possess more mature design architectures that \nencompass vulnerability fixes and advanced assurance features.  \nTD 9: Adversary compromises single board computing \nsystem (SBCS)  \nIn this threat, an adversary compromises a n SBCS  purchased by a program for use in a \nsystem. An SBCS is a commercial off -the-shelf product consisting of a PCB with FPGAs \nand computer processing resources. These boards are common  throughout Do D \nsystems as they are readily available in the marketplace. Additionally, their relative \ntechnical simplicity and low expense do not justify the fabrication of custom solutions by \nprograms.  \nIn this scenario, since t he program does not have c ontrol of the manufacturing process \nof the SBCS it is forced  to rely on a verification -heavy approach to mitigating attacks. Of \nprimary concern in this scenario are threats to:  \n Authenticity of the FPGA devices  \n PCB connections to the FPGA  \n The configuration  methodology  \n Test interfaces  \nThe following mitigations only address the hardware assurance concerns related to the \nmanufacturing and operation of the FPGA device and do not consider other \ncomponents of the SBCS.  \nTD 9 mitigations  \n Purchase from DoD -authorized vendors and distributors . The Do D program \nacquisition group can provide this information.  \n Verify and authenticate with independent teams .  \n Authenticate the FPGA  devices .  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  53 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Verify PCB c onnections  using the SBSCs schematic . \n Verify the SBCS configu ration process  and board -level connections comply with \nLoA2 mitigation requiremen ts.  \n If the configuration file memory storage device contains SBCS vendor code, the \nprogram should review and evaluate SBCS vendor code  for malicious function s. \n Poll FPGA settings  captured in non -volatile memory , such as fuses, to determine \nif the SBC vendor has preprogrammed any settings in a manner conflicting with \nthese assurance guidelines or that conflict with the user application needs.  \n Document compliance steps  taken  to comply with these requirements. This \nincludes hardware and software features.  \nTD 9 mitigation d escriptions  \nPurchase from DoD -authorized vendors and distributors   \nUse DoD -authorized vendors and distributors for all purchases . Authorized vendors can \nbe identified through the acquisition organization.   \nVerify and authenticate with independent  teams  \nAll verification and authentication steps should be conducted by two independent \nteams . Personnel cannot overlap between teams and e ach team should be comprised \nof personnel cleared to the Secret  level at a minimum . These teams are in place to \neliminate the influence of a cleared insider working with an outside adversary . \nAuthenticate the FPGA devices  \nIn this mitigation, the program sh ould authenticate the devices utilizing the \nrecommendations found under TD 2:  Adversary inserts malicious counterfeit . \nVerify PCB c onnections  \nObtain and review the SBCS schematics for functional correctness, vulnerabilities, and \nsecurity concerns as they relate to the FPGA configuration process and security \nconnections.  Verify  the PCB traces related to the FPGA device, the configuration \nmemory devices, and any other devices related to the authentication of the \nconfiguration data. The program should rely on  guidance from the JFAC PCB Executive \nAgent to perform this verification. This evaluation should be performed on all devices.  \nOnce the SBCS has been evaluated for PCB connections and correct configuration, t he \nprogram should craft a set of test s that verify all the devices comply with the evaluation . \nThis set of tests should be maintained and stored in the revision management system.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  54 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nVerify the SBCS configuration process   \nThe SC BS should be compliant with LoA 2. This includes , but is not limited to , \nrequirem ents for:  \n NIST -compliant authentication algorithms  \n Differential power analysis resistant authentication  \n Protected key storage  \n Anti-tamper detection and response  \n Being f ree of known vulnerabilities in the configuration and security functions  \n All encryp tion and authentication keys lengths must be compliant with the \nrequirements outlined NIST SP 800 -57 Cryptographic Key Management \nGuidelines   \n The ability to disable FPGA test pins , such as JTAG  \nReview and evaluate SBCS vendor code  \nThe program should review and evaluate all vendor code contained with in the \nconfiguration file memory for malicious function s. While reviewing the code, the \nreviewer should ensure a ny proprietary SBCS vendor methodology  for configuration is \nfully understood  and validated.  SBCS configuration processes that cannot be fully \nevaluated should not be used at LoA2.  \nPoll FPGA settings  captured in non -volatile memory  \nPoll the FPGA settings captured in non -volatile memory , such as fuses,  to determine if \nthe SBC S vendor has preprogrammed any settings in a manner conflicting with these \nassurance guidelines or that conflict with user application needs.  \nDocument compliance steps  \nDocument all steps taken to demonstrate compliance with TD 9.  These steps and \nassociated data artifacts should be auditable.  \nTD 10: Adversary modifies vendor FPGA software design \nsuite during development  \nIn this threat , an adversary modifies the vendor design suite during its development to \nsubvert the Do D application during FPGA implementatio n. This subversion could \ninclude:  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  55 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n Inserting a malicious function or vulnerability into the device during synthesis, \nplace and route , or configuration data generation.  \n Enabl ing the exfiltration of program application design data over a network \nconnection.  \nThis subverted tool would then be part of the authorized software delivered by the \nvendor and its distributors. In this light, delivery protections such as encryption, package \nsigning, and hashes would have no mitigating value. Evaluating the vendor  softwa re \nand certifying it as Trojan  free is a prohibitively large and costly venture that is not \npractical at the program level.  \nAt present, the only approach to addressing this attack is to verify the results of the \nFPGA implementation steps. Rather than dete rmine that the tool is Trojan  free, the \napproach is to verify that the tool suite did nothing malicious to the application design. \nLogical equivalence checking (LEC) is the tool used to perform this verification .  \nJFAC is currently investigating additional  measures to detect and thwart compromised \nvendor tools. Pending new advances, JFAC can assist programs with overcoming the \ndifficulties of performing LEC.  \nTD 10  mitigations  \n To prevent exfiltration of data from a malicious FPGA EDA tool, perform all \nFPGA d esign work on an isolated network as recommended in the Isolat e and \nstore the application design  mitigation  under  TD 3.  \n Perform  logical equivalency checking  between the application HDL and the final \nconfiguration data.  \nTD 10  mitigation d escriptions  \nPerform l ogical equivalency checking  \nTo the greatest extent possible, LEC verifie s that the vendor tools did not modify the \nlogic or configuration settin gs. The goal is to verify  that the final bitstream and \noriginating application HDL are logically equivalent with no extraneous logic in the fi nal \nformat. This confirms that Trojans were not inserted during the implementation steps.  \nThe LEC also verifies  that the configuration settings were maintained and not altered. \nConfiguration settings are those parameters included in the configuration file that affect \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  56 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nthe behavior of the FPGA device itself but are not a part of the program application. \nExamples include tamper settings, JTAG settings , and key storage.  \nThere are technical challenges associated with performing LEC on FPGA data . First, \ndue to the proprietary nature of the configuration file format, including it i n the LEC effort \nis difficult. Contact JFAC for information on commercial tools that can assist with th is for \nseveral device families.  \nAdditionally, many FPGA synthesis optimizations ma ke it difficult to perform LEC. For \nthis reason, the following are recommended:  \n Perform LEC after each implementation step to limit the amount of change that \nmust be accounted for by the tool. This includes synthesis, place and route , and \nconfiguration dat a generation.  \n Use hints files to assist in matching difficult -to-correlate logic in the compared \ndatabases.  Most LEC  tools accept these files.  \n Contact JFAC for information on  emerging industry tools that can assist in \nidentifying configuration data in the FPGA formats  or automate the creation of \nhints files.  \n3 Summary  \nThe mitigations in this report are intended to protect against adversarial  threats to  \nassurance on FPGA -based systems. Once a program incorporates the mitigations for \nthese 10 threat descriptions,  it can consider its FPGAs to have achieved LoA2.  \nIf a program has developed alternate solutions for mitigating these threats , it can \nconsult with JFAC to determine if the alternative mitigation s are sufficient .  \nFinally, if a program has questions regarding this report  or requires assistance, it should \ncontact  JFAC at https://jfac.navy.mil/  for assistance.  \n  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  57 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nAppendix  A: Standardized terminology  \nThe following terms are used in the Joint Federated Assurance Center Field \nProgrammable Gate Array Best Practices documents. These terms are modified from \nDefense Acquisition University definitions to support common un derstanding.  \nApplication design   The collection of schematics, constraints, hardware description \nlanguage (HDL), and other implementation files developed to generate an FPGA \nconfiguration file for use on one or many FPGA platforms.  \nApplication domain   This is the area of technology of the system itself, or a directly \nassociated area of technology. For instance, the system technology domain of a radar \nsystem implemented using FPGAs would be \"radar\" or \"electronic warfare.\"  \nConfiguration file   The set of all data produced by the application design team and \nloaded into an FPGA to personalize it. Referred to by some designers as a bitstream, \nthe configuration file includes that information, as well as additional configuration \nsettings and firmware, which s ome designers may not consider part of their bitstream.  \nControllable effect   Program -specific, triggerable function allowing the adversary to \nattack a specific target.  \nDevice/FPGA device   A specific physical instantiation of an FPGA.  \nExternal facility   An unclassified facility that is out of the control of the program or \ncontractor.  \nField programmable gate array (FPGA)   In this context FPGA includes the full range \nof devices containing substantial reprogrammable digital logic. This includes devices \nmarketed as FPGAs, complex programmable logic devices (CPLD), system -on-a-chip \n(SoC) FPGAs, as well as devices marketed as SoCs and containing reprogrammable \ndigital logic capable of representing arbitrary functions. In addition, some FPGAs \nincorporate analo g/mixed signal elements alongside substantial amounts of \nreprogrammable logic.  \nFPGA platform   An FPGA platform refers to a specific device type or family of devices \nfrom a vendor.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  58 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nHard IP   Hard IP is a hardware design captured as a physical layout, inte nded to be \nintegrated into a hardware design in the layout process. Hard IP is most typically \ndistributed as Graphic Design System II (GDSII). In some cases, Hard IP is provided by \na fabrication company and the user of the IP does not have access to the fu ll layout, but \nsimply a size and the information needed to connect to it. Hard IP may be distributed \nwith simulation hardware description language (HDL) and other soft components, but is \ndefined by the fact that the portion that ends up in the final hardwa re was defined by a \nphysical layout by the IP vendor.  \nLevel of assurance (LoA)   A Level of Assurance is an established guideline that \ndetails the appropriate mitigations necessary for the implementation given the impact to \nnational security associated wit h subversion of a specific system, without the need for \nsystem -by-system custom evaluation.  \nPhysical unclonable function (PUF)   This function provides a random string of bits of \na predetermined length. In the context of FPGAs, the randomness of the bitstr ing is \nbased upon  variations in the silicon of the device due to manufacturing. These bitstrings \ncan be used for device IDs or keys.   \nPlatform design   The platform design is the set of design information that specifies \nthe FPGA platform, including physica l layouts, code, etc.  \nSoft IP   Soft IP is a hardware design captured in hardware description language \n(HDL), intended to be integrated into a complete hardware design through a synthesis \nprocess. Soft IP can be distributed in a number of ways, as function al HDL or a netlist \nspecified in HDL, encrypted or unencrypted.  \nSystem   An aggregation of system elements and enabling system elements to achieve \na given purpose or provide a needed capability.  \nSystem design  System design is the set of information that defines the \nmanufacturing, behavior, and programming of a system. It may include board designs, \nfirmware, software, FPGA configuration files, etc.  \nTarget  A target refers to a specific deployed instance of a given system, or a specific \nset of systems with  a common design and function.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  59 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTargetability  The degree to which an attack may have an effect that only shows up in \ncircumstances the adversary chooses. An attack that is poorly targetable would be more \nlikely to be discovered accidentally, have unintend ed consequences, or be found in \nstandard testing.  \nThird -party intellectual property (3PIP)   Functions whose development are not \nunder the control of the designer. Use of the phrase intellectual property, IP, or 3PIP in \noutlining this methodology of desi gn review does not refer to property rights, such as, \nfor example, copyrights, patents, or trade secrets. It is the responsibility of the party \nseeking review and/or the reviewer to ensure that any rights needed to perform the \nreview in accordance with the  methodology outlined are obtained.  \nThreat category  A threat category refers to a part of the supply chain with a specific \nattack surface and set of common vulnerabilities against which many specific attacks \nmay be possible.  \nUtility  The utility of an attack is the degree to which an effect has value to an \nadversarial operation. Higher utility effects may subvert a system or provide major \ndenial of service effects. Lower utility attacks might degrade a capability to a limited \nextent.   \nVulnerability  A flaw in a software, firmware, hardware, or service component \nresulting from a weakness that can be exploited, causing a negative impact to the \nconfidentiality, integrity, or availability of an impacted component or components.   \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  60 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nAppendi x B: JFAC FPGA reporting template  \nEach program is requested to provide the following information to JFAC.  Multiple e -mail \naddresses are provided to support a variety of classification levels; only one e -mail to \nany of these is required. Please contact  JFAC to obtain the appropriate email address \nat https://jfac.navy.mil.  \nThe template and informati on to be included in the email are as follows:  \n=============================================  \n*** Please Portion Mark Appropriately ***  \n(U) POC Contact Info   \n(U) Name:  \n(U) Organization/Company:  \n(U) Email:  \n(U) Phone:  \n(U) Address:  \n  \n(U) Program Info   \n(U) Program Name (top -level program, i.e. F35, M1 tank, etc.):  \n(U) US Govt Sponsor: (Air Force, Army, Marines, Navy, DOE, other)  \n(U) Do you want to be includ ed in any future JFAC FPGA Assurance related bulletins in \nthe future?  \n(U) Estimated Number of Systems to be Built:  \n(U) Program Description (1 -3 sentences describing the top -level program in which the \nsubsystem listed below is included):  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  61 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n  \n(U) FPGA Info (for each FPGA part number used)  \n(U) FPGA Vendor: (Intel, Lattice, MicroChip, Xilinx, other)  \n(U) FPGA Device Family:  \n(U) FPGA Device Part Number:  \n(U) FPGA Design Software Used and Version #:  \n(U) Description of Subsystem Containing FPGA Device:  \n(U) Total Estimated Number of Subsystems to be Built:  \n(U) Operating Environment: (mil, ind, com, radiation, cryo)  \n(U) Source/seller of the FPGA devices:  \n(U) Date purchased:  \n(U) Anticipated Fielding date:  \n(U) LoA Level:  \n(U) Description of FPGA Role in  Subsystem.  If multiple instances of FPGA devices, \nnumber and describe the role of each.  \n1.  \n2.  \n3.  \n===============================================  \n \n  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  62 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nExample  \n=============================================  \n*** Please Portion Mark Appropriately ***  \n(U) POC Contact Info   \n(U) Name:  Jack Jackson  \n(U) Organization/Company: Army Research Lab  \n(U) Email : jjackson@army_email.mil  \n(U) Phone:  555-555-5555  \n(U) Address:  10 Main St, Fort Murphy, Illinois 55555  \n  \n(U) Program Info   \n(U) Program Name (top -level program, i.e. F35, M1 tank, etc.):  Next Generation \nCombat Vehicle (NGCV)  \n(U) US Govt Sponsor: (Air Force, Army, Marines, Navy, DOE, other) Army  \n(U) Do you want to be included in any future JFAC FPGA Assurance related bulletins in \nthe future? :  Yes \n(U) Estimated Num ber of Systems to be Built: 1400  \n(U) Program Description (1 -3 sentences describing the top -level program in which the \nsubsystem listed below is included ): \nThe Next Generation Combat Vehicle  Future Decisive Lethality (NGCV -FDL) \nwill have capabilities that  are enabled by assured position, navigation , and \ntiming and resilient networks . This will enable future maneuver formations to \nexecute semi -independent operations while conducting cross -domain \nmaneuver against a peer adversary . \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  63 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \n  \n(U) FPGA Info (for each FPGA part number used)  \n(U) FPGA Vendor: (Xilinx, Intel, MicroChip, Lattice, other):  Acme MicroElectronics  \n(U) FPGA Device Family:  Big Blue Iceberg  \n(U) FPGA Device Part Number:  BBI-624L100K  \n(U) FPGA Design Software Used and Version #:  IceBreaker V2021.15  \n(U) Description of Subsystem Containing FPGA Device:  image processing for data \noriginating from the cannon targeting sensor  \n(U) Total Estimated Number of Subsystems to be Built: 3000  \n(U) Operating Environment: (mil, ind, com, radiation, cryo):  mil \n(U) Sourc e/seller of the FPGA devices : Digikey, online  \n(U) Date purchased: 2/25/2020  \n(U) Anticipated Fielding date:  5/1/2022  \n(U) LoA Level : 1 \n(U) Description of FPGA Role in Subsystem.  If there are  multiple instances of FPGA \ndevices, number and describe the role of  each  one.  \n1. FPGA #1  is used to perform  signal processing on raw image data coming in \nfrom the externally mounted cannon . \n2. FPGA #2  is used to perform signal processing on raw image data coming \nfrom the scout drone through the external antennae #2 and synchronized with \nGPS positioning data.  \n================ ===============================  \n  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  64 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nAppendix C : Mitigations with  data/document ation  \nrequirements  \nChecklist for TD 1: Adversary utilizes a known FPGA platform \nvulnerability  \nTD 1 m itigation s Data/ Documentation requirement  \nUse caution when s electing tools or \nplatforms  The program should document the name of the person \nperforming the research, the date timestamp of  the \nresearch, the research results, the vendor -provided \nend-of-life plan or release notes (if available). If  a \nbeta/initial release is selected , the program should \ndocument the rationale behind the selection and \ncontain the signature of the programmatic approval \nauthority.  \nUse cleared personnel  In writing, t he program should designate wo rk that mus t \nbe done by cleared individuals . The program should \nkeep a log of personnel assigned to that work along \nwith their clearance level.  \nThe program should maintain a list of the m embers \ncomprising each team with their clearance level s. The \nprogram should  maintain audit logs demonstrating what \neach team member accessed.  \nResearch vulnerabilities  The program should document each publication that \nwas searched, (minimally those identified in this \nguidance should be searched) search results, the \nname of the person performing the search , and date \ntimestamp when the search was performed.  The same \ninformation should be documented by the reviewer.  \nIf a vulnerability is found, choose one of the following options:  \nOption 1: Select a different FPGA \nplatform device or software  For the different tool, t he program should document \neach publication that was searched, (minimally those \nidentified in this guidance should be searched) search \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  65 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 1 m itigation s Data/ Documentation requirement  \nresults, the name of the person performing the search , \nand date timestamp whe n the search was performed.  \nOption 2: Work with the vendor  The program should work through the vendor process \nto formally notify the vendor of any vulnerabilities, and \nonly accept fixes through formal , approved processes. \nThe program should maintain docum entation regarding \nthe identified vulnerability, log communication with the \nvendor, and document the source and method of the \nreceived fix.  \nOption 3: Risk analysis   The program should maintain documentation \nidentifying the risk, any mitigations, and the a pproval \nauthority for accepting the residual risk .  \nUse r evision control/version \nmanagement  The program should document  and enforce  a \nconfiguration management (CM) plan that is compliant \nwith CMMC Level 3 or NIST SP 800 -171 Protecting \nControlled Unclassified Information in Nonfederal \nSystems and Organizations and NIST SP 800 -172 \nEnhanced Security Requirements for Protecting \nControlled Unclassified Information . The program \nshould document how the CM plan is compliant with \nthe requirements.  \nThe configuration management plan should include \ndetails on how configuration data will be maintained for \ncontrol and audit purposes.  It should include \nmanagement of document/data, releases, backups and \narchives, refresh of backup media, rete ntion of tools \nand software, test equipment, and the test \nenvironment.  \nAudit logs should be reviewed with the results \nrecorded.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  66 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 1 m itigation s Data/ Documentation requirement  \nEnforce auditability  The program should maintain audit log s on all design \ndata to include  requirements, architecture, design, \ncode, test s, bugs and fixes. The audit data minimally \nshould document who requested the change with date \ntimestamp, the decision made regarding the change, \nwho made the decision with date and timestamp, why \nwas the change requested, and who made the change  \nwith date  and timestamp . \nEnforce approved  design process  The program should document program design \nmilestones with clear entry and exit criteria. The \nentry/exit criteria should be specifically identified to \ninclude the peer review/code review and technical \nreview processes. The entrance and exit criteria should  \nbe utilized throughout the program lifecycle. The \ndocumentation should contain artifacts demonstrating \nthat the gates were satisfied, with signed management \napproval . \nThe program should obtain the results of independent \nreviews to include:  \n Type and exte nt of verification performed, to include \nevaluation objective, methodology, and tools  \n Findings, both positive and negative, for all \nevaluations performed  \n Risks identified by the review team (e.g., quality \nissues, vulnerability to threats, etc.)  \n Recom mendatio ns to mitigate identified risks  \n Identification and credentials of each reviewer  \n Time/date stamp of when the review was performed  \nThe i ndependent review team must  be separate from \nthe team doing the design.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  67 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nChecklist for TD 2: Adversary inserts malicious counterfeit  \nTD 2 mitigation s Documentation requirements  \nPurchase from DoD -authorized \nvendors and distributors  The program should document the name and location \nof the authorized vendor along with documentation \ndemonstrating that the vendor is authorized.  \nConsult Government -Industr y Data \nExchange Program (GIDEP)   The program should document the GIDEP search \nresults, the name or ID of the person performing the \nsearch , and the date timestamp when the search was \nperformed.  \nFollow s torage and shipping  \nguidance  The program should document, maintain and enforce a \ntransportation plan which supports the movement of \nbulky classified material. Minimally the plan should \ninclude:  \n Title of Plan  \n Date of movement  \n Authorization/Approval  \n Purpose  \n Description of consignment, to include unique ID \nwhen available  \n Identification of responsible government and/or \ncompany representatives  \n Identification of commercial entities to be involved in \neach shipment  \n Packaging of the consignment   \n Routing of the consignment  \n Couriers/escorts  \n Recipient responsibilities  \n Return of material procedures  \n Other information as required  \nThe program should document, maintain , and enforce \na storage plan which supports the storage of bulky \nmaterial.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  68 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 2 mitigation s Documentation requirements  \nVerify FPGA c ryptographically \nsecure ID s  The program should documen t and store the ID of each \nFPGA, the ID that was provided directly by the vendor , \nthe date timestamp of when the  ID was validated \ncryptographically, and who performed the validation . \nPerform p hysical \ninspection/ analysis  The program should document the results of the \nphysical analysis test with each FPGA unique ID the \ntest was performed on , the date timestamp of the  \nanalysis, and who performed the analysis . \nThe program should maintain documentation on the \nsample selection process. This could be from the use \nof a non -human selection process, cleared personnel, \nor an independent party. The program should maintain \nthe list of devices used for samples. Document the \nprocess to secure the device and the results, as well \nas, documentation of all parties that touched the device \nwith the reason for the interaction.  \nTo mitigate risk of a cleared insider:  \nSelect sample parts  The program should document  the process used to \ncollect the samples, secure the device and the results , \nas well as, a ll parties that touched the device with the \nreason for the interaction.   \nCreate c ryptographically protected \nIDs The program should record the device serial number \nand PUF ID.  \nCompar e results anytime the programs compares the \nsoft PUF and unique ID for confirmation of the \nauthenticity of the part.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  69 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 2 mitigation s Documentation requirements  \nVerify independent lab work  The program should require:  \n The return of residual materials and detailed reports \nafter evaluation  \n The approved storage plan to be utilized by the lab \nwith acceptable evidence  \n Documentation that demonstrates the lab identified \nthe known bad parts ; the name, address, and division \nof the two independent labs;  or resul ts of physical \ninspection  \nIn addition  to the item above , to verify the independent lab work also choose one of the \nfollowing options:  \nOption 1:  Insert known bad parts  Document the known bad parts, the problem with the \npart, and the results from the verification facility that \nperformed the physical analysis . \nOption 2:  Use duplicate \nindependent labs  Document the credentials of the observer, the findings, \nand the conclusion.  The conclusion should confirm if \nthe lab results match or are different.  \nOption 3:  Use duplicate persons \nassigned to the program  Document the credentials of the observer s, the \nfindings, and conclusion.  The conclusion should \nconfirm if the  results match or are different.  \nFollow guidance for TD 4: \nAdversary compromises system \nassembly, keying, or provisioning  Provide all of the TD4:  Adversary compromises \nsystem assembly, keying, or provisioning data \nrequirements . \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  70 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nChecklist  for TD 3: Adversary compromises application design cycle  \nTD 3 mitigation s Documentation requirements  \nTrack critical data in a revision \ncontrol  system  The program should ensure the following data items \nare tracked in revision control:  \n Third -party IP (3PIP)  \n Utilized libraries  \n Development files, code, software used for \ndevelopment, synthesis scripts, and tools  \n Test benches, test plans and test procedures, and \ntest r eports  \n Tool configuration settings  \n Design documents to include:  \n    Critical documents, to minimally include \nrequirements, design artifacts, test repor ts, test  plans, \nand discrepancy report s \n    Documentation with approval to proceed from \norganizationally defined reviews: code reviews, \narchitecture reviews, technical design reviews, and \nverification and validation reviews  \n \nEach of the artifacts should b e identified in the \nprogram s auditing strategy and the audit logs should \nminimally include  decisions that were made, by whom, \nfor what reason, and on what date.  \nEnforce auditability  The program should maintain audit log s on all design \ndata to include  requirements, architecture, design, \ncode, test s, bugs and fixes. The audit data minimally \nshould document who requested the change with date \ntimestamp, the decision made regarding the change, \nwho made the decision with date and timestamp, why \nwas the change requested, and who made the change \nwith date timestamp . \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  71 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 3 mitigation s Documentation requirements  \nUse r evision control and version \nmanagement  tools  The program should document  and enforce  a \nconfiguration management (CM) plan that is compliant \nwith CMMC Level 3 or NIST SP 800 -171 Protecting \nContro lled Unclassified Information in Nonfederal \nSystems and Organizations and NIST SP 800 -172 \nEnhanced Security Requirements for Protecting \nControlled Unclassified Information . The program \nshould document how the CM plan is compliant with \nthe requirements.  \nThe configuration management plan should include \ndetails on how configuration data will be maintained for \ncontrol and audit purposes.  It should include \nmanagement of document/data, releases, backups and \narchives, refresh of backup media, retention of tools \nand software, test equipment, and the test \nenvironment.  \nAudit logs should be reviewed with the results \nrecorded.  \n3.1 Mitigating the i ntroduction of a compromised design  into the application  \nIsolate and store the application \ndesign  The program should document the hash of the final \nconfiguration after the final design and verify the hash \nprior to provisioning. The program should maintain the \nconfiguration management audit logs.  \nPerform reproducible build  Document the reproducible build process and results \nvalidating that the separate build s produce the same \nbinary and hash.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  72 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 3 mitigation s Documentation requirements  \n3.2 Mitigating the modification of test benches/plan to reduce coverage or hide Trojan \ncode  \nExecute a documented test plan  The program should document and  maintain a test plan \nthat includes a mechanism to verify all requirements.  \n The test plan should explicitly list code coverage \nmetrics, the type of testing that will be performed, and \nacceptable testing guidelines.  \n Code cove rage should state how much code is \nchecked by the test bench, providing information about \ndead code in the design and holes in test suites. \nEnsure code coverage includes statement coverage, \nbranch coverage, FSM, condition, expression, and \ntoggle coverage. Document any code that will not be \ncovered and why. Ensure untested code is \ndocumented and reviewed through the review process. \nUse functional test s to verify the FPGA does what it is \nsupposed to do. Any deviations must be documented \nand approved.  \n The d ecision to use/not use other types of testing \nsuch as directed test, constrained random stimulus, \nand assertion should be documented.  \n Unexpected behavior should be documented and \nanalyzed, with final implementation conclusions \ndocumented.  \n The test pl an should specify the verification \nenvironment which describes the tools, the software, \nand the equipment needed to perform the reviews, \nanalysis, and tests. Each of these items should be \nmaintained under revision control.  \n Ensure all test discrepancies,  bugs, etc. are resolved \nvia a change process.  \nValidate and verify test processes  The program should document, review, maintain, \nenforce , and archive the test plan. The test plan should \ninclude which tools will be used with names, version \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  73 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 3 mitigation s Documentation requirements  \nnumbers, and th e various test reviews that will take \nplace, type of testing to be performed, and the methods \nused to accomplish the test.  \nThe program should maintain documentation of all \ntesting performed, including members of each team \nand role, all documentation assoc iated with peer \nreviews, configuration logs indicating all actions taken \nby whom and when, and use of automated tools where \napplicable. All test discrepancies, bugs, etc. should be \nresolved via a change process utilizing a change \nmanagement system. The est ablished processes \nshould be documented, enforced, and audited.  \nMaintain test environment via \nconfiguration management  The program should maintain configuration \nmanagement documentation in accordance with \nrequirements of CMMC level 3 or NIST SP 800-171 \nProtecting Controlled Unclassified Information in \nNonfederal Systems and Organizations  and NIST SP \n800-172 Enhanced Security Requirements for \nProtecting Controlled Unclassified Information . The \nprogram should maintain CMMC audit results or NIST \nSP 800-171 self-assessments.  \n3.3 Mitigating the  introduc tion of Trojans into the application design during \ndevelopment  \nMaintain b i-directional link to \nrequir ements  The program should document bi -directional \ntraceability for all device requirements, including \nderived requirements.  \nEnforce peer review  The program should document the results of each peer \nreview to include:  \n Entry criteria and status  \n Roles and responsibilities with associated names  \n Attendees  \n Findings, including deviations or waivers , and \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  74 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 3 mitigation s Documentation requirements  \nassociated rationale and approval  \n Exit criteria and status  \nExecute a documented test plan  The program should document and  maintain a test plan \nthat includes a mechanism to verify all requirements.  \n The test plan should explicitly list code coverage \nmetrics, the type of testing that will be performed, and \nacceptable testing guidelines.  \n Code coverage should state how much code is \nchecked by the test bench, providing information about \ndead code in the design and holes in test suites. \nEnsure code coverag e includes statement coverage, \nbranch coverage, FSM, condition, expression, and \ntoggle coverage. Document any code that will not be \ncovered and why. Ensure untested code is \ndocumented and reviewed through the review process. \nUse functional test s to verify the FPGA does what it is \nsupposed to do. Any deviations must be documented \nand approved.  \n The decision to use/not use other types of testing \nsuch as directed test, constrained random stimulus, \nand assertion should be documented.  \n Unexpected behavior sh ould be documented and \nanalyzed, with final implementation conclusions \ndocumented.  \n The test plan should specify the verification \nenvironment which describes the tools, the software, \nand the equipment needed to perform the reviews, \nanalysis, and tests. E ach of these items should be \nmaintained under revision control.  \n Ensure all test discrepancies, bugs, etc. are resolved \nvia a change process.  \nImplement, validate , and verify test \nprocesses  The program should document, review, maintain, \nenforce, and archive the test plan. The test plan should \ninclude which tools will be used with names and \nversion numbers, the various test reviews that will take \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  75 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 3 mitigation s Documentation requirements  \nplace, the types of testing to be performed, an d the \nmethods used to accomplish each test.  \nThe program should maintain documentation of all \ntesting performed, including  members of each team  \nand their  roles, all documentation associated with peer \nreviews , configuration logs indicating all actions taken,  \nby whom and when , and use of automated tools where \napplicable.  All test discrepancies, bugs, etc. , should be \nresolved via a change process utiliz ing a change \nmanagement system.  The established processes \nshould be documented, enforced , and audited . \nSelect  a formal proof process  Document  all code that was reviewed using LEC, any \nfunctional discrepancies, and how those discrepancies \nwere resolved.  \n3.4 Mitigating the introduction of compromised tooling/software into the environment  \nValidate cryptographic  hash es  The program should document the value of the \ncalculated cryptographic hash and the signed hash \nprovided by the vendor , along with the software name, \nversion , and release number.  \nResearch vulnerabilities  The program should document each publication that \nwas searched, (minimally those identified in this \nguidance should be searched) search results, the \nname of the person performing the search , and the \ndate timestamp when the search was performed.  \nIf vulnerabilities are found in the softwar e or tools, choose one  of the following options:  \nOption 1: Select a different  tool For the different tool, t he program should document \neach publication that was searched, (minimally those \nidentified in this guidance should be searched) search \nresults, the  name of the person performing the search , \nand date timestamp when the search was performed.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  76 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 3 mitigation s Documentation requirements  \nOption 2: Work with vendor  The program should maintain documentation regarding \nthe identified vulnerability, log communication with the \nvendor, and document the s ource and method of the \nreceived fix.  \nOption 3 : Risk analysis  The program should maintain documentation \nidentifying the risk, any mitigations, and the approval \nauthority for accepting the residual risk . \nTo perform tool validation, choose one of the following options:  \nOption 1: Reproducible build \nprocess  Document the reproducible build process and results \nvalidating that the separate build s produce the same \nbinary and hash.  \nOption 2: Select a formal proof \nprocess  Document  all code that was reviewed using LEC, any \nfunctional discrepancies, and how those discrepancies \nwere resolved.  \n3.5 Mitigating intrusion into the internal network  \nAssign Roles  The program should approve, document , and maintain \nall individuals, the roles they perform , and the access \nallowed by that role . At a minimum, these roles should \ninclude design, test, network administration , and \nsystem administration.  \nControl and monitor access  Entry/access to appropriate a reas should be recorded, \nmonitored, and logged for auditability.  \nResearch  vulnerabilities  The program should document each publication that \nwas searched  (minimally those identified in this \nguidance should be searched) , the search  results, the \nname of  the person performing the search, and the \ndate timestamp of when the search  was performed .  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  77 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 3 mitigation s Documentation requirements  \nPurchase from DoD -authorized \nvendors and distributors  The program should document the name and location \nof the authorized vendor along with documentation \ndemonstrating that the vendor is authorized.  \nUse trusted computing \nenvironment s \n  The program should maintain documentation and audit \ndata demonstrating one of the following computing \nplatforms were utilized:  \n A computer and network classified at the DSCA \nSecret  level or above. The documentation should \ninclude a log of personnel with clearance information, \nall records in accordance with a maintaining a DSCA \nSecret  network , as well as a documented and SSP.  \n A computer and network certified for use in a Trust \nCategory 1 facility as defined by DMEA.  \n A network -isolated computer enclave with limited and \ncontrolled access.  \n An infrastructure compliant with NIST SP 800 -171 \nand NIST SP 800 -172, preferably complia nt with \nCMMC level three. If CMMC is a program requirement, \nthe program should maintain CMMC audit data.  Until \nCMMC is a program requirement, the program should \nmaintain a self -assessment demonstrating compliance . \n3.6 Mitigating risk from compromised hire  or employee  \nEnforce auditability  The program should maintain audit log s on all design \ndata to include  requirements, architecture, design, \ncode, test s, bugs and fixes. The audit data minimally \nshould document who requested the change with date \ntimestamp,  the decision made regarding the change, \nwho made the decision with date and timestamp, why \nwas the change requested, and who made the change \nwith date timestamp . \nAdhere to an approved design \nprocess  The program should document and utilize the entry and \nexit criteria of each stage of the design process. This \nincludes documentation for each peer review and \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  78 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 3 mitigation s Documentation requirements  \ndesign review with roles and responsibilities along with \nassociated names, attendees, and findings , including \ndeviations or waivers and associated rationale and \napprovals.  \n  \nAll design changes should be documented and \napproved, and testing should adhere to organizationally \napproved test standards.  \nReview c ritical  activitie s The program should obtain the results of independent \nreviews to include:  \n Type and extent of verification performed, to include \nevaluation ob jective, methodology, and tools  \n Findings, both positive and negative, for all \nevaluat ions performed  \n Risks identified by the review team (e.g., quality \nissues, vulnerability to threats, etc.)  \n Recommendatio ns to mitigate identified risks  \n Independent team should be separate  from the team \ndoing the design  \n Identification and cre dentials of each reviewer  \n Time/date stamp of when the revie w was performed  \nUse cleared personnel  In writing, t he program should designate work that mus t \nbe done by cleared Individuals . The program should \nkeep a log of personnel assigned to that work along \nwith their clearance level.  \nThe program should maintain a  list of the members \ncomprising each team  with their clearance level s. The \nprogram should  maintain audit logs demonstrating what \neach team member accessed.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  79 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nChecklist for TD 4: Adversary compromises system assembly, keying, \nor provisioning  \nTD 4 mitigation s Documentation requirements  \nPurchase from DoD -authorized \nvendors and distributors   The program should document the name and location \nof the authorized vendor along with documentation \ndemonstrating that the vendor is authorized.  \nFollow s torage and shipping \nguidance  The program should document, maintain and enforce a \ntransportation plan which supports the movement of \nbulky classified material. Minimally the plan should \ninclude:  \n Title of Plan  \n Date of movement  \n Authorization/Approval  \n Purpose  \n Description of consignment, to include unique ID \nwhen available  \n  Identification of responsible government and/or \ncompany representatives  \n Identification of commercial entities to be involved in \neach shipment  \n Packaging the consignment  \n Routing of the consignment  \n Couriers/escorts  \n Recipient responsibilities  \n Return of material procedures  \n Other information as required  \nThe program should document, maintain and enforce a \nstorage plan which supports the storage of bulky \nmaterial.  \nProvide k eys and configuration \ndata  The program should document assembly house receipt \nof data packages and the hash value of the packages.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  80 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 4 mitigation s Documentation requirements  \nClear memory devices  The program should document the company, location, \nindividual , and method for clearing the contents , along \nwith the contents before and after clearing.  \nProvision private keys  The program sh ould document:  \n The company name, location and date of provisioning  \n The number of provisioned devices and number of \nunique keys used  \n Proof of DSCA facility classification  \n Proof of DMEA Trust Cat egory  I certification  \nProtect the configuration data \npackage  The program should maintain data receipt \ndocumentation from each of the assembly and test \nteams showing each team either collected the data \nfrom a central repository or received it from a trusted \ntransfer mechanism.  \nPerform v erifica tion a ctivities  The program should maintain documentation including \nthe procedures used to verify the PCB traces, where \nthe work was performed, when it was performed and \nthe results of the verification.  \nThe program should maintain documentation including \nthe procedures used to authenticate the configuration \ndata, where the work was performed, who performed it, \nwhen it was performed and the results of the \nverification.  \nThe program should maintain documentation including \nthe authentication methodology, its architecture and \ncompliance with appropriate NIST standards.  \nThe program should maintain documentation including \nthe methodology used to verify the proper keys were \nloaded, where the work was performed, when it was \nperformed and who performed the work.  \nThe program should maintain documentation including \nthe procedures used to authenticate the post assembly \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  81 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 4 mitigation s Documentation requirements  \nFPGA device, where the authentication was performed, \nby whom, whe n and the results of the verification.  \nTo authenticate the FPGA device, c hoose one of the following option s: \nOption 1:  Verify the unique \ncryptographic ID  The program should document:  \n The authenticity verification method  \n The verification outcomes  \n The individual name or reference ID who performed \nthe verification  \nOption 2:  Verify the device on the \nPCB  The program should document:  \n The authenticity verification method  \n The verification outcomes  \n The individual name or reference ID who performed  \nthe verification  \nOption 3:  Use a soft PUF  The program should document:   \n The authenticity verification method  \n The verification outcomes  \n The individual name or reference ID who performed \nthe verification  \nChecklist for TD 5: Adversary compromises third -party soft IP  \nTD 5 mitigation s Documentation requirements  \nPurchase from DoD -authorized \nvendors and distributors   The program should document the name and location \nof the authorized vendor along with documentation \ndemonstrating that the vendor is authorized.  \nOnly a ccept only IP that is \nunobfuscated   The program should keep a copy of the clean \nunobfuscated code, along with the name and or ID of \nthe person who received it.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  82 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 5 mitigation s Documentation requirements  \nValidate the c ryptographic hash of \nthe IP The program should document the value of the \ncalculated cryptographic hash and the signed hash \nprovided by the vendor along with the software name, \nversion , and release number.  \nStore IP in a revision control \nrepository  The program should include the initial IP and hash \ncheck -in within the system.  \nTo examine the IP for malicious functions, chose one of the following options:  \nOption 1:  At least two cleared \npersonnel review the IP  The program should  document the reviews and all \nresults in accordance with the Third -Party IP Review \nProcess for Level of Assurance 2  \n \nOption 2:  Contact JFAC to \ndetermine if an IP review of the \ncomplete IP package ha s been \nsuccessfully completed  The program should maintain documentation and \nprovide it to JFAC with IP identification information , \nwhat  program the IP is used in, and the role that IP \nserves within th e system . The program should \ndocument proof of receipt from JFAC  along with all \ninteractions with JFAC.  \nThe program should obtain and review evidence of IP \nverification, including requirements sign-off.  \nNote:  This activity is intended to both provide \nconfidence that the 3PIP will meet program \nspecifications and that functionality not utilized by the \ndeveloper, including testability, is understood by the \nprogram. Data should be created and colle cted by the \nIP developer.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  83 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nChecklist for TD 6: Adversary swaps configuration file on target  \nTD 6 mitigation s Documentation requirements  \nIncorporate c ryptographic \nauthentication  The program should document:  \n The method used to authenticate the configuration file \non load.  \n The verification process used to test the \nauthentication method.  \nAuthenticate configuration data \neach time the data  is loaded  For each configuration load method used , the program \nshould document the method used to authentic ate the \nconfiguration file on load, and the verification process \nused to test the authentication method.  \nPrevent direct read back  The program should document the steps taken to \nprevent direct read back of private keys  \nUse a CNSS/N IST approved \nalgorithm and key length  The program should document the algorithm and key \nlength being used along with the version number of the \nlatest guidance and the approved key length in \naccordance with the guidance.  \nUse security -evaluat ed \nauthentication  The program should maintain documentation from \nJFAC with the security evaluation results.  \nTest a ccess pins   The program should maintain documentation including \nthe means by which the JTAG test pins were disabled.  \nEnsure authentication for \nmodifications  Document if the FPGA  allows application change s, how \nthe vendor states authentication will apply to all \nreconfiguration data, and test results indicating how \nauthentication was actually applied to all \nreconfiguration data.  \nAs part of authenticating application modifications,  in cases where security settings are set \nwithin the configuration file : \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  84 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 6 mitigation s Documentation requirements  \nAlways program security settings in \nnon-volatile storage of the device  The program should maintain documentation including \nthe means used to set security settings.  \nWhen a platform supports remote updates, chose one of the following options:  \nOption 1: Validate that the built -in \napplication change technique fully \napplies authentication to all the \nreconfiguration data  The program should maintain documentation including \nthe test used t o validate the application update \nmethodology and the outcome.  \nOption 2:  Perform authentication of \nthe reconfig uration data in the \napplication  The program should maintain documentation including \nthe methodology used to perform authentication in the \napplication using partial reconfiguration.  \nGenerate and store all \nauthentication keys on a program -\ncontrolled, FIPS 140 -2 compliant, \nLevel 2 HSM   Document how the program utilizes FIPS 140 -2. \nDocument the HSM that is being used and the spec \nsheet demonstrating FIPS compliance.  \nChecklist for TD 7: Adversary substitutes modified FPGA software \ndesign suite  \nTD 7 mitigation s Documentation requirement  \nPurchase from DoD -authorized \nvendors and distributors  The program should document the name and location \nof the authorized vendor along with documentation \ndemonstrating that the vendor is authorized.  \nPrevent a utomatic tool updates  The program should document, maintain , and follow \nthe SSP.  \nUse a t rusted compu ting \nenvironment  The program should maintain documentation and audit \ndata demonstrating one of the following computing \nplatforms were utilized:  \n A computer and network classified at the DSCA \nSecret  level or above. The documentation should \ninclude a log o f personnel with clearance information, \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  85 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 7 mitigation s Documentation requirement  \nall records in accordance with a maintaining a DSCA \nSecret  network , as well as a documented and SSP.  \n A computer and network certified for use in a Trust \nCategory 1 facility as defined by DMEA.  \n A network -isolated  computer enclave with limited and \ncontrolled access.  \n An infrastructure compliant with NIST SP 800 -171 \nand NIST SP 800 -172, preferably compliant with \nCMMC level three. If CMMC is a program requirement, \nthe program should maintain CMMC audit data.  Until \nCMMC is a program requirement, the program should \nmaintain a self -assessment demonstrating compliance . \nUse cleared personnel  In writing, t he program should designate work that mus t \nbe done by cleared Individuals . The program should \nkeep a log of personnel assigned to that work along \nwith their clearance level.  \nThe program should maintain a list of the members \ncomprising each team  with their clearance level s. The \nprogram should  maintain audit logs demonstrating wh at \neach team member accessed.  \nValidate the c ryptographic hash  The program should maintain the value of the \ncalculated hash and the hash that is provided by the \nvendor , along with the version , release number , and \ndate timestamp.  \nTo validate the tool output, choose one of the following options:  \nOption  1: Independently validate \nthe hash  Document the separate purchases of the tool, the \nhashes that were validated and when, and the two \ncleared individuals who validated them.  \nOption 2 : Select a formal proof \nprocess  Document  all code that was reviewed using LEC, any \nfunctional discrepancies, and how those discrepancies \nwere resolved.  \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  86 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 7 mitigation s Documentation requirement  \nOption 3 : Use a reproducible b uild \nprocess  Document the reproducible build process and results \nvalidat ing that the separate build s produce the same \nbinary and hash.  \nChecklist for TD 8: Adversary modifies FPGA platform family at \ndesign  \nTD 8 mitigation s Documentation requirements  \nEngage JFAC  The program should maintain a copy of the data sent to \nJFAC with a date  timestamp of when it was sent and \nan acknowledgement of when it was received.  \nChecklist for TD 9: Adversary compromises single -board computing \nsystem (SBCS)  \nTD 9 mitigation s Documentation requirements  \nPurchase from DoD -authorized \nvendors and distributors  The program should document the name and location \nof the authorized vendor along with documentation \ndemonstrating that the vendor is authorized.  \nVerify and authenticate with \nindependent teams  The program should maintain a list of the m embers \ncomprising each team with their clearance level s. The \nprogram should  maintain audit logs demonstrating what \neach team member accessed.  \nAuthenticate the FPGA devices  The program should document the physical inspection \nresults for each slash sheet and uniqu e identifier  for the \ndevice inspected.  \nVerify PCB c onnections  Document the review of the SBCS schematics and \nPCB traces and any findings, along with who \nperformed the review and the date timestamp of the \nreview. In addition the program should maintain the  \ntests that were performed for the evaluation along with \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  87 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 9 mitigation s Documentation requirements  \nthe evaluation results, timestamp, and name of \nevaluator in the revision management system.  \nVerify the SBCS configuration \nprocess  The DoD supplier should provide the document \ndemonstrating complianc e \nReview and evaluate SBCS vendor \ncode  The program should document the review of all vendor \ncode contained within the configuration file.  The vendor \nshould provide and the program should maintain \ndocumentation about all proprietary capabilities. \nRecord th e vendor documentation and the evaluation \nof the proprietary methodology.  \nPoll FOGA settings captured in \nnon-volatile memory  The program should maintain documentation that \ninclud es the FPGA settings available in the given \nFPGA device, the methodology used to read them, \nwhere and when they were tested, by whom, and the \nresults.  \nDocument the steps  Document the steps taken to comply with these \nrequirements.  These steps and associated data \nartifacts should be auditable.  \nChecklist for TD 10: Adversary modifies vendor FPGA software \ndesign suite during development  \nTD 10 mitigation s Documentation requirement  \nIsolate and store the application \ndesign  The program should document the storage plan, who \nhas access to the design, when, why and by whom the \naccessed the design.  In addition, the hash of the final \nconfiguration after the final design should be stored \nand verified prior to provisioning. The program should \nmaintain the configuration ma nagement audit logs.  \nPerform logical equivalency \nchecking  The program should document any hints, all \noptimizations, and rationale for any logic that did not \n\n \n \nU/OO/ 120910 -23 | PP-23-0199 | FEB 2023 Ver. 1.0  88 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Level of Assurance 2 Best Practices  \nTD 10 mitigation s Documentation requirement  \nmatch the equivalency checker with managerial \napproval signature.  \n \n\n",
  "cves": [],
  "techniques": [],
  "advisory": "cybersecurity-alerts",
  "title": "ctr_dod_microelectronics_fpga_loa2_best_practices",
  "source": "nsa",
  "id": "993f8ec65e29a8395e77fb5796b5dd732878505f9861c2e0837049e867ab81ea"
}