{
  "markdown": " \nU/OO/181860 -19          PP -19-1058          AUG UST 2019  1 CONTINUOUSLY HUNT FOR NETWORK INTRUSIONS  \nA QUESTION OF TIME  \nTodays network breaches often remain undetected for extended periods of time. A 2017 Ponemon Institute study found \nthat the average time to identify adversarial presence within an enterprise was 191 days  [1]. This is plenty of time for an \nattacker to wreak havoc on the enterprise network. A longer dwell time enables adversaries to establish persistence, \nperform network reconnai ssance, and exfiltrate data. Additionally, r emediation costs increase the further an attack  \nprogresses . This means that detecting network intrusions as early as possible is critical . Earlier detection minimizes \ndamage, reducing remediation costs and speeding recovery efforts. Organizations that supplement automated preventive \ncontrols with a continuous and active hunt for unauthorized activity improve their ability to detect advanced threats sooner \nand reduce the time spent investigating and manually correlating network  and host  events [2]. \nTHE HUNTING PROCESS  \nAutom ated detection methods, such as Intrusion Detection Systems (IDS), Endpoint Detection and Response (EDR)  \ncapabilities , and Security Information and Event Management (SIEM)  system  alerts  are useful , but they can not detect all \nbreaches.  Advanced attackers obfuscat e their actions to evade these common automated detection methods , ensuring \nlonger dwell times. O rganizations  that continuously hunt  for anomalous network activity  do not rely exclusively on \nautomated detection: they  assume that malicious actor s have by -passed automated detection and already reside  in the \nnetwork . They actively and continuously search for information about where the actor s are, how they got in, and what they \nintend to do.  \nIdentifying n ormal  \nEstablishing a baseline  is fundamenta l to devising a hunt strategy. A baseline  is a representation of normal activity \namong an organizations network traffic , network performance, host and application activity , and user behavior . Having a \nbaseline is necessary in order to detect anomalies.  A baseline is collected over a period of time that is long enough to get \nan accurate snapshot of normal activity , but not so long as to risk accidental ly incorporating anomalous activity.  \nIn addition to baselining, asset m anagement1 practices ensure that all assets and network topology are recorded and \nthat any changes are tracked.  Be aware of all critical assets including software, hardware, network connections, and \nconfigurations.  Knowing what assets and network topology to expect make it easier to identify suspicious changes  to \nthese assets . Information such as patching and asset  vulnerabilities can  allow a hunt team to focus efforts in the right \nareas . Actively m anaging assets will additionally make remediating issues more efficient by quickly providing information \nsuch as the assets location, what the asset should be connected to, and how the asset should be configured.  \nCollecting d ata \nAn Indicator of Compromise (IOC)  is a piece of data that a defender  uses  to detect malicious activity  (e.g. in logs, files,  \nand network traffic ). Hunters detect IOCs  or anomalies , pivot to gather additional information to understand the full extent \nof a compromise, and then evict the adversary from the network  in a permanent way . The smallest missed indicator  can \noften be an organizations downfall . In order for hunters to find malicious activity , organizations need to collect enough \ndata to provide a detailed view of all network and host activity  for comparison against IOCs  and baseline behavior . \nThere are myriad  specialized network inspection appliances  on the market to collect different types of network data. M any \nexpert network analysis shops collect long term network flow, short term packet capture, and network alerts. Such  \n                                                \n1 For more information on asset management, please r efer to  Actively Manage Systems and Configurations , part of the  NSA Cybersecurity Top 10 Mitigations . \n\n \nU/OO/181860 -19          PP -19-1058          AUG UST 2019  \n2 alerts can come from intrusion detection/ prevention systems and gateways such as proxies and next -gen  \nfirewalls, while some go further to use technologies that extract and inspect files from email, web, and other traffic.  \nAdditionally, end-user hosts, server equipment, network devices, and software services generate logs and store them \nlocally by default. These logs contain relevant information such as successful and failed authentication, account cr eation \nand deletion,  process creation and termination, driver load ing, registry change , and file creat ion and overwrit ing events, \nalong with alerts on identified malware, potential intrusions , or other suspicious behavior. A professional hunt team will \nlearn the most critical logs to look for and where they reside, often then forwarding them to a SIEM solution for centralized \nanalysis.  Some SIEM solutions provide agents that can be installed on devices to forward logs and traffic from devices \nthat do not natively provide forwarding capabilities.  \nIntrusion Detection Systems (IDS) monitor either network traffic  (Network Intrusion Detection System or NIDS)  or host \nactivity  (Host Intrusion Detection System or HIDS)  and alert on suspicious behavior. A HIDS has agents installed on \nindividual devices in a network to monitor each devices activities and state , while a  NIDS is placed in one or more \nlocations on a network and examines passing traffic. Intrusion Detection Systems ( IDSs ) are considered either rule -\nbased/knowledge- based or anomaly -based depending on how they detect intrusions. A rule-based IDS examines network \ntraffic or host activity for known attack patterns  such as signatures or behaviors . Examples include  a pattern of bits in \ntraffic matching a regular expression (signature- based) or a process calling another process it should not normally call  \n(behavior -based) . An anomaly -based IDS establishes a baseline and then samples activity  to detect deviations (e.g. a \nnew traffic flow between endpoints or a n unusual port ). Defenders who understand their network  and its baseline can \nmake sense of such anomalies.  \nEndpoint Detection and Response (EDR)  systems  analyze behavior exhibited by users, systems, processes, and \nservices to determine whether  irregular activity indicates adversarial presence on an endpoint  device . The ability to \ndiscover  previously unknown tactics  or seemingly -legitimate -but-actually -malicious techniques through the analysis of \nbehavioral metadata makes EDR a valuable supplement to existing investments in defensive software.  Important EDR \ncapabilities that distinguish it from rule-based log analysis  include  instrumentation (which provides real -time visibility into \nsecurity -relevant system functions ), the ability to scan system memory with host agents, contextual awareness (which \nhelps with incident timeline analyses), the potential for automated remediation (with severity estimation), and the ability t o \ntune countermeasures in response to intrusion evidence.  Often,  EDR solutions employ machine learning techniques for \nanomalous behavior identification and third- party threat intelligence feeds for file reputation or IOCs.  \nSearching and a nalyzing \nA SIEM system provides log aggregation and correlation, querying, visualization, and alerting, making it a necessary tool \nfor hunters. The tool collect s logs and traffic from across the enterprise and formats the data to allow for efficient \nsearching and correlation.  Hunters can leverage these features to search for IOCs and correlate data from different \nsources to follow the path an attacker took through the network. Logs and alerts from IDSs and EDRs can be forwarded to \nSIEM solutions.  Analysis of  logs in the SIEM system can uncover how attacker s got in, how they traverse d the network, \nand what activities they engage d in while in the system. SIEM tools often include built -in analytics and allow analysts to \nbuild their own analytics to develop IOCs. T hird-party threat reputation services2 can be integrated to enrich collected data \nor provide IOCs.  When an IOC is found, an alert can be created to notify administrators in real -time if this behavior is seen \nin the future. Finally, SIEM tools usually include the ability to create dash boards w ith charts and visualizations to provide \nan overview of the network , for quick access to frequently needed or important information, or to dive deep into data and \nfind relationships . When implementing a SIEM, key features to consider include data i ngestion capability for the data \ncollection products it must integrate with,  data volume constraints, canned  analytics offered, custom query development \nfunctionality , and third- party intelligence integration for enrichment.  \nOrganizations can enhance their hunting capabilities by incorporating analytics and machine learning into their SIEM \nsolution. Analytics  turn a volume of data into meaningful information. An analytic will query data to make correlations and \nfind patterns t o describe an event. Analytics can drive dashboards, generate alerts, or trigger automated responses. \nSecurity analytics can be used in real -time for threat detection.  Analytics  can also be applied to a data set in hindsight for \na reactive response (retrospective analysis) . Some SIEM tools include built -in analytics or allow analysts to build their own \n                                                \n2 For more information on threat  reputation services, please r efer to  Integr ate Threat Reputation Services , part of the NSA Cyberse curity Top 10 Mitigations . \n\n \nU/OO/181860 -19          PP -19-1058          AUG UST 2019  \n3 analytics. Many third -party organizations sell pre- built analytics or create custom analytics  as a service . \nMany SIEM products are beginning to adver tise Machine Learning (ML)  analytics, which leverage artificial intelligence \ntechniques to find patterns in data. Certain use cases for ML show immense promise, including the reduction of  false \npositives in alerting. Before relying on ML techniques, users should understand what results they want to achieve, \nbecause it is difficult to objectively compare the claims of such products.  \nFrameworks that lay out the typical steps an attacker uses to execute an attack can be used as a guide while hunting for \nintrus ions, helping network defenders identify potential vulnerabilities or IOCs. The  MITRE ATT&CK3 framework  [3] \nincludes a matrix of attacker tactics and techniques and provides drilldowns  on each technique including a description, \nexamples, mitigation recommendations, and potential detection methods. Using this matrix, organizations can prioritize \nwhich tactics and techniques would be most harmful or likely to occur, and learn how to searc h for indications that the \ntechnique is being used on the network. NSA  has also developed the NSA Technical Cyber Threat Framework (NTCTF) , \na lexicon to characterize and categorize malicious cyber activity across the adversary lifecycle [4 ]. \nAnother useful  guide while hunting is David Biancos Pyramid of P ain [5] . The Pyramid of Pain categorizes IOCs by the \namount of impact (pain) inflicted on the adversary if network defenders discover the indicator and use the information it \nprovides to block the attackers actions . The pyramid includes hash values, Internet Protocol ( IP) addresses, domain \nnames, network/host artifacts (e.g. registry keys, certain file activity, etc.), tools typically used by attackers (e.g. spear \nphishing software, software to est ablish  command and control, password crackers, etc.), and tactics, t echniques and \nprocedures (TTP).  \nAt the base of the pyramid are file hash values. Hash values are easy  to \ndetect and block because a computed hash value is almost unique to \nthe original input. This means if a file  hashes to a known- bad hash \nvalue, hunters can be sure the discovery is malware and can block \nit. However, this is not a huge inconvenience to attackers \nbecause it is easy to flip a bit , causing the hash val ue to \nchange.  \nAt the top  of the pyramid are TTPs , the fundamental \napproaches for executing an attack . It takes a mature \nhunting operation to develop effective TTP detection \nbehavioral rules  from scratch , but these rules are \nmore likely to thwart an attacker . A blocked TTP \nwill force an attacker to have to start their attack \nover from scratch using a new method.  \nDetecting TTPs in a behavioral way is \nusually preferable for a hunter, but \nidentifying specific attack infrastructure \n(e.g. by IPs and domain names ) is \ngenerally still necessary, particularly in understanding the breadth and depth of a n advanced compromise.  When possible, \nhunters should try to pivot off of perishable IOCs to discover TTPs to establish a longer lasting mitigation.  \nINCIDENT RESPONSE  \nWhen hunting leads to detection, Incident Response activities  can help minimiz e data loss, mitigat e vulnerabilities, and \nrestor e compromised services. To prepare for incidents, organizations create an incident response plan including \nprocedures for handling an incident, important contact information, and network information. When an incident occurs, the \nincident response team assesses the target and scope of the attack, and any vulnerabilities enabling it. Once an incident \nhas been detected and reported and the evidence collected it must be contained using the strategi es  \nand procedures outlined in the incident response plan. Sometimes carefully -orchestrated,  extreme  \n                                                \n3 MITRE ATT&CK is a trademark of The Mitre Corporation.  \n\n\n \nU/OO/181860 -19          PP -19-1058          AUG UST 2019  \n4 measures are required to evict persistent actors . System recovery plans may need to be exercised4. After an  \nincident, organizations should analyze how the incident was handled and make c hanges to the plan to better prepare for \nfuture incidents.5  \nPENETRATION TESTING  \nPenetration testing, while not generally a hunting activity, is a good practice to assess network boundaries and defensive \nmeasures against realistic attack scenarios  [7]. While hunting focuses on proactively searching for an attacker in the \nnetwork, penetration testing focuses on proactively searching for vulnerabilities that attackers could leverage to gain \naccess and attack an organization. P enetration testers can chain techniques  together to form an attack path and emulate \nadvanced or persistent adversaries , giving the hunting team a good trai ning opportunity . Penetration testing provides  \nvaluable information regarding defensive gaps, procedural flaws, and configuration issues , identifying high- value targets \nfor hunting. Additionally, penetration testing helps  determine the sophistication an attacker would need to compromise a \nsystem , and helps identify additional countermeasures to reduce attack surfaces and inform incident response polic ies \nand procedures . Like hunting, penetration testing works best when repeated often, and shared openly with defensive \norganizations to stay current on evolving attack methods  to improve protections and hunting processes . \nCONSIDERATIONS  \nHunting for intrusions requires the continuous collection of relevant data to examine. Permission and cooperation from the \norganization are required in order perform successful hunting operations. The cost of storing all relevant events , the \namount of time and effort  needed to  continuously  hunt, false positives and negatives , and difficulty inspecting encrypted \ntraffic , and over -reliance on automation  all pose challenges  that can  incur risk of missing  malicious activities . \nBE PROACTIVE  \nHunting for intrusions involves proactively searching for evidence of  cyber intrusions  on host devices and in network traffic \nand then remediating any  issues quickly and effectively. Continuously hunting on the network enables  defenders  to find \nattackers sooner and prevent  damage to the organization.  \nREFERENCES \n[1]  2017 Cost of Data Breach Study . Ponemon Institute, 2017. Available: https://www.ponemon.org/library/2017- cost-of-data- breach- study -united-\nstates   \n[2]  2018 Threat Hunting Report . Cybersecurity Insiders, 2018. Available: https://www.domaintools.com/content /2018- Threat -Hunting- Report.pdf  \n[3]  Att&ck Matrix for Ent erprise. MITRE, 2018. Available: https://attack.mitre.org  \n[4]  NSA/CSS Technical Cyber Threat Framework  v1. National Security Agency , 2018. Available: https://apps.nsa.gov/iaarchive/library/reports/nsa- css-\ntechnical -cyber -threat -framework -v1.cfm   \n[5]  D. Bianco, The Pyr amid of Pain. 2014 January 17.  [Blog] Available: https://detect -respond.blogspot.com/2013/03/the- pryamind- of-pain.html  \n[6]  P. Cichonski, et al.  Computer S ecurity Incident Handling Guide.  NIST , SP 800-61 Rev.2, 2012 August . Available: \nhttps://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800- 61r2.pdf  \n[7]  K. Scarfone, et al.  Technical Guide to Informa tion Security Testing and Assessment.  NIST , SP 80 0-115, 2008 September. Available: \nhttps://ws680.nist.gov/publication/get_pdf.cfm?pub_id=152164  \nDISCLAIMER OF WARRAN TIES AND ENDORSEMENT  \nThe information and opinions contained in this document are provided \"as is\" and without  any warranties or guarantees. Reference herein to any specific \ncommercial products, process, or service by trade name, trademark, manufacturer, or otherwis e, does not constitute or imply its endorsement, \nrecommendation, or favoring by the United States Government, and this guidance shall not be used for advertising or product endorsement purposes.  \nCONTACT INFORMATION  Client Requirements and General Cybersecurity Inquiries :  Cybersecurity Requirements Center (CRC),  410-854-4200, \nemail:   Cybersecurity_Requests@nsa.gov  \n                                                \n4 For more information on recovery pla ns, please refer to  Exercise a System Recovery Plan,  part of the  NSA Cybersecurity Top 10 Mitigations . \n5 Refer to  NIST SP 800 -61 Rev.2: Computer Security Incident Handling Guide  for more guidance on incident response.  \n\n",
  "cves": [],
  "techniques": [],
  "advisory": "cybersecurity-alerts",
  "title": "continuously hunt for network intrusions - copy",
  "source": "nsa",
  "id": "afcbf74f258ce2174d58b338951042d81b7ff35536762b06470cd8016819696d"
}