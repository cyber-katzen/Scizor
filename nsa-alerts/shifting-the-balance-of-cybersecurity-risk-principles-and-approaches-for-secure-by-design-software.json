{
  "markdown": "PRINCIPLES AND APPROACHES FOR\nSECURE BY DESIGN SOFTWARESHIFTING THE BALANCE OF\nCYBERSECURITY RISK:TLP:CLEAR\nTLP:CLEAR\n\n2\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS\nTLP:CLEAR\nTLP:CLEAR\n\n3\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nContents\nOverview: Vulnerable By Design  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n What's New   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\nHow To Use This Document  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\nSecure by Design   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\nSecure by Default  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\nRecommendations for Software Manufacturers   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\nSoftware Product Security Principles  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n Principle 1: Take Ownership of Customer Security Outcomes  . . . . . . . . . . . . . . . . . 11\n Explanation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n Demonstrating This Principle  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n Principle 2: Embrace Radical Transparency and Accountability   . . . . . . . . . . . . . . 20\n Explanation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n Demonstrating This Principle  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n Principle 3: Lead from the Top   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n Explanation   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n Demonstrating This Principle  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\nSecure by Design Tactics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\nSecure by Default Tactics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\nHardening vs Loosening Guides  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\nRecommendations for Customers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\nDisclaimer    . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n Resources   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n References   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n\n4\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAROVERVIEW:\nVULNERABLE BY DESIGN \nTechnology is integrated into nearly every facet of daily life, as internet-facing systems \nincreasingly connect us to critical systems that directly impact our economic prosperity, \nlivelihoods, and even health, ranging from personal identity management to medical care . \nOne example of the disadvantage of such conveniences are the global cyber breaches \nresulting in hospitals canceling surgeries and diverting patient care . Insecure technology \nand vulnerabilities in critical systems may invite malicious cyber intrusions, leading to \npotential safety1 risks .\nAs a result, it is crucial for software manufacturers to make secure by design and secure \nby default the focal points of product design and development processes . Some vendors \nhave made great strides driving the industry forward in software assurance, while others \ncontinue to lag behind . The authoring organizations strongly encourage every technology \nmanufacturer to build their products based on reducing the burden of cybersecurity on \ncustomers, including preventing them from having to constantly perform monitoring, \nroutine updates, and damage control on their systems to mitigate cyber intrusions . We \nalso urge the software manufacturers to build their products in a way that facilitates \nautomation of configuration, monitoring, and routine updates . Manufacturers are \nencouraged to take ownership of improving the security outcomes of their customers . \nHistorically, software manufacturers have relied on fixing vulnerabilities found after the \ncustomers have deployed the products, requiring the customers to apply those patches \nat their own expense . Only by incorporating secure by design practices will we break the \nvicious cycle of constantly creating and applying fixes . Note: The term secure by design \nencompasses both secure by design and secure by default .\nTo accomplish this high standard of software security, the authoring organizations \nencourage manufacturers to prioritize the integration of product security as a critical \nprerequisite to features and speed to market . Over time, engineering teams will be able \nto establish a new steady-state rhythm where security is truly designed-in and takes less \neffort to maintain .\nReflecting this perspective, the European Union reinforces the importance of product \nsecurity in the Cyber Resilience Act, emphasizing that manufacturers should implement \nsecurity throughout a products life-cycle in order to prevent manufacturers from \nintroducing vulnerable products into the market .\n1  The authoring organizations recognize that the term safety has multiple meanings depending on the context. For the purposes \nof this guide, safety will refer to raising technology security standards to protect customers from malicious cyber activity.TLP:CLEAR\n\n5\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEARTo create a future where technology and associated products are safer for customers, \nthe authoring organizations urge manufacturers to revamp their design and development \nprograms to only permit the shipping of products secure by design and default . Well \nbefore development, products that are secure by design are conceptualized with the \nsecurity of customers as a core business goal, not just a technical feature . Secure by \ndesign products start with that goal before development starts . Existing products can \nevolve to a secure by design state over multiple iterations . Secure by default products \nare those that are secure to use out of the box with little to no configuration changes \nnecessary, and security features available without additional cost . Together, these \ntwo philosophies move much of the burden of staying secure to manufacturers and \nreduce the chances that customers will fall victim to security incidents resulting from \nmisconfigurations, insufficiently fast customer patching, or many other common issues .\nThe Cybersecurity and Infrastructure Security Agency (CISA), National Security Agency \n(NSA), Federal Bureau of Investigation (FBI) and the following international partners2  \nprovide the recommendations in this guide as a roadmap for software manufacturers to \nensure security of their products:\n Australian Cyber Security Centre (ACSC)\n Canadian Centre for Cyber Security (CCCS)\n United Kingdoms National Cyber Security Centre (NCSC-UK)\n Germanys Federal Office for Information Security (BSI)\n Netherlands National Cyber Security Centre (NCSC-NL)\n Norways National Cyber Security Center (NCSC-NO)\n Computer Emergency Response Team New Zealand (CERT NZ) and New Zealands National \nCyber Security Centre (NCSC-NZ)\n Korea Internet & Security Agency (KISA)\n Israels National Cyber Directorate (INCD)\n Japans National Center of Incident Readiness and Strategy for Cybersecurity (NISC) and \nJapan Computer Emergency Response Team Coordination Center (JPCERT/CC)\n OAS/CICTE Network of Government Cyber Incident Response Teams (CSIRT) Americas \n Cyber Security Agency of Singapore (CSA)\n Czech Republics National Cyber and Information Security Agency (NKIB)\nThe authoring organizations recognize the contributions by many private sector partners \nin advancing security by design and security by default . This product is intended to \nprogress an international conversation about key priorities, investments, and decisions \nnecessary to achieve a future where technology is safe, secure, and resilient by design \nand default . To that end, the authoring organizations seek feedback on this product from \ninterested parties and intend to convene a series of listening sessions to further refine, \nspecify, and advance our guidance to achieve our shared goals .\nFor more information on the importance of product safety, see CISAs article, The Cost of \nUnsafe Technology and What We Can Do About It .\n2  Hereafter referred to as the authoring organizations.TLP:CLEAR\n\n6\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nThe initial publication of this report generated a significant amount of conversation within \nthe software industry  . Daily news of organizations and individuals being compromised \nhighlights the need for more conversation regarding how to address chronic and systemic \nproblems in software products .\nAfter the release in April 2023, the authoring organizations (henceforth referred to as we \nand our) received thoughtful feedback from hundreds of individuals, companies, and \ntrade associations . The most common request in the feedback was to provide more detail \non the three principles as they apply to both software manufacturers and their customers . \nIn this document, we expand on the original report and touch on other themes such as \nmanufacturer and customer size, customer maturity, and the scope of the principles .\nSoftware is everywhere and no single report will be able to adequately cover the entire \nrange of software systems, development of software products, customer deployment and \nmaintenance, and integration with other systems . For guidance below that does not clearly \nmap to a particular environment, we look forward to hearing from the community how the \npractices described in this paper led to particular security improvements .\nThis report applies to manufacturers of artificial intelligence (AI) software systems and \nmodels as well . While they might differ from traditional forms of software, fundamental \nsecurity practices still apply to AI systems and models . Some secure by design practices \nmay need modification to account for AI-specific considerations, but the three overarching \nsecure by design principles apply to all AI systems .\nWe recognize that transforming a software development lifecycle (SDLC) to align with \nthese secure by design principles is not a simple task and may take time . Further, smaller \nsoftware manufacturers may struggle to implement many of these suggestions . We believe \nthat the software industry needs to make widely available the tools and procedures that \nmake products safer  . As more people and organizations focus their attention on software \nsecurity improvements, we believe there is room for innovations that will narrow the gap \nbetween larger and smaller software manufacturers to the benefit of all customers . \nThis update to the original secure by design report is part of our commitment to build \npartnerships with the many interconnected stakeholder communities that underpin \nour technological ecosystem . It is the result of feedback from many parts of that \necosystem, and we will continue to listen and learn from perspectives . Although there \nare many challenges ahead, we are incredibly optimistic as we learn more about people \nand organizations that have  already adopted a secure by design philosophy, often with \nsuccess .WHATS NEW  TLP:CLEAR\n\n7\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nHOW TO USE THIS DOCUMENT\n \nWe urge software manufacturers to adhere to the principles within this \ndocument . Software manufacturers can demonstrate their commitment by \npublicly documenting their actions taken, in line with the steps listed below  . \nWe encourage software manufacturers to find tactics that meet the spirit of \nthese principles and to create artifacts that will build a compelling case to even \nskeptical current and potential customers that they are embodying the secure \nby design philosophy  .\nIn addition to actions software manufacturers should take, customers can \nalso leverage this document . Companies buying software should ask hard \nquestions of their vendors, drawing inspiration from the examples of adhering \nto the principles listed in this document . In doing so, customers can help to \nshift the market towards products that are more secure by design . An example \nof questions customers can ask of vendors is given in CISAs Guidance for K-12 \nTechnology Acquisitions .\nWe encourage enterprise customers to incorporate these practices into \nprocurement processes, vendor due diligence assessments, enterprise \nrisk acceptance decisions, and other steps taken when evaluating vendors . \nCustomers should also push their vendors to publicly document the secure by \ndesign actions each vendor takes . Collectively, this can create a strong demand \nsignal for security, which can encourage and enable software manufacturers to \ntake steps towards greater security  . In other words, just as we seek to create a \npervasive secure by design philosophy within software manufacturers, we need \nto create a secure by demand culture with their customers .\n\nSecure by DesignSecure by design means that technology products are built in a way \nthat reasonably protects against malicious cyber actors successfully \ngaining access to devices, data, and connected infrastructure . Software \nmanufacturers should perform a risk assessment to identify and enumerate \nprevalent cyber threats to critical systems, and then include protections in \nproduct blueprints that account for the evolving cyber threat landscape .\nSecure information technology (IT) development practices and multiple \nlayers of defense known as defense-in-depthare also recommended \nto prevent malicious actors from compromising systems or obtaining \nunauthorized access to sensitive data . The authoring organizations further \nrecommend manufacturers use a tailored threat model during the product \ndevelopment stage to address all potential threats to a system and account \nfor each systems deployment process .\nThe authoring organizations urge manufacturers to take a holistic security \napproach for their products and platforms . Secure by design development \nrequires the strategic investment of dedicated resources by software \nmanufacturers at each layer of the product design and development \nprocess that cannot be bolted on later  . It requires strong leadership by \nthe manufacturers top business executives to make security a business \npriority, not just a technical feature . This collaboration between business \nleaders and technical teams extends from the preliminary stages of design \nand development, through customer deployment and maintenance . \nManufacturers are encouraged to make hard tradeoffs and investments, \nincluding those that will be invisible to the customers (e .g  ., migrating to \nprogramming languages that eliminate widespread vulnerabilities) . They \nshould prioritize the features, mechanisms, and implementation of tools \nthat protect customers rather than product features that seem appealing \nbut enlarge the attack surface .\nThere is no single solution to end the persistent threat of malicious \ncyber actors exploiting technology vulnerabilities, and products that are \nsecure by design will continue to suffer vulnerabilities; however, a large \nset of vulnerabilities are due to a relatively small subset of root causes . \nManufacturers should develop written roadmaps to align their existing \nproduct portfolios with more secure by design practices, ensuring to only \ndeviate in exceptional situations .\nThe authoring organizations acknowledge that taking ownership of the \nsecurity outcomes for customers and ensuring this level of customer \nsecurity may increase development costs . However, investing in secure \nby design practices while developing innovative technology products and \nmaintaining existing ones can substantially improve the security posture \nof customers and reduce the likelihood of compromise . Secure by design \nprinciples not only strengthen the security posture for customers and \nbrand reputation for developers but the practice also lowers maintenance \nand patching costs for manufacturers in the long term .\nThe Recommendations for Software Manufacturers section listed \nbelow provides a list of product development practices and policies for \nmanufacturers to consider  .TLP:CLEAR\nTLP:CLEARCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS 8\n\n9\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEARRECOMMENDATIONS FOR SOFTWARE MANUFACTURERS\nThis joint guide provides recommendations to manufacturers for developing \na written roadmap to implement and ensure IT security  . The authoring \norganizations recommend software manufacturers implement the strategies \noutlined in the sections below to take ownership of the security outcomes of \ntheir customers through secure by design and default principles .\nSecure by default means products are resilient against prevalent \nexploitation techniques out of the box without added charge . These \nproducts protect against the most prevalent threats and vulnerabilities \nwithout end-users having to take additional steps to secure them . Secure \nby default products are designed to make customers acutely aware that \nwhen they deviate from safe defaults, they are increasing the likelihood \nof compromise unless they implement additional compensatory controls . \nSecure by default is a form of secure by design .\n A secure configuration should be the default baseline. Secure by default \nproducts automatically enable the most important security controls \nneeded to protect enterprises from malicious cyber actors, as well as \nsupply the ability to use and further configure security controls at no \nadditional cost.\n The complexity of security configuration should not be a customer problem. \nOrganizational IT staff are frequently overloaded with security and \noperational responsibilities, thus resulting in limited time to understand \nand implement the security implications and mitigations required for a \nrobust cybersecurity posture. Manufacturers can aid their customers by \noptimizing secure product configurationsecuring the default path\nensuring their products are manufactured, distributed, and used securely \nin accordance with secure by default standards.\nManufacturers of products that are secure by default do not charge \nextra for implementing added security configurations . Instead, they \ninclude them in the base product like seatbelts are included in all new cars .Secure by Default\nSecurity should not be a luxury option, but \nshould be considered a right customers receive \nwithout negotiating or paying more.TLP:CLEAR\n\nTake ownership of customer security outcomes and evolve products \naccordingly. The burden of security should not fall solely on the customer.\nEmbrace radical transparency and accountability.\nSoftware manufacturers should pride themselves in delivering safe and secure \nproducts, as well as differentiating themselves from the rest of the manufacturer \ncommunity based on their ability to do so. This may include sharing information they \nlearn from their customer deployments, such as the uptake of strong authentication \nmechanisms by default. It also includes a strong commitment to ensure vulnerability \nadvisories and associated common vulnerability and exposure (CVE) records are \ncomplete and accurate. However, beware of the temptation to count CVEs as a negative \nmetric, since such numbers are also a sign of a healthy code analysis and testing \ncommunity.\nBuild organizational structure and leadership to achieve these goals.\nWhile technical subject matter expertise is critical to product security, senior executives \nare the primary decision makers for implementing change in an organization. \nExecutives need to prioritize security as a critical element of product development \nacross the organization, and in partnership with customers.SOFTWARE PRODUCT SECURITY \nPRINCIPLES\n1\n2\n3Software manufacturers are encouraged to adopt a strategic focus that prioritizes software security. \nThe authoring organizations developed the following three core principles to guide software \nmanufacturers in building software security into their design processes prior to development, \nconfiguration, and shipment of their products.\nTLP:CLEAR\n10CISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\n\n11\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTo enable these three principles, manufacturers should consider several operational \ntactics to evolve their development processes.\nConvene routine meetings with company executive leadership to drive the importance \nof secure by design and secure by default within the organization. Policies and \nprocedures should be established to reward production teams that develop products \nadhering to these principles, which could include awards for implementing outstanding \nsoftware security practices or incentives for job ladders and promotion criteria.\nOperate around the importance of software security to business success. For example, \nconsider assigning a software security leader or a software security team that \nupholds business and IT practices that directly link software security standards \nand manufacturer accountability. Manufacturers should ensure they have robust, \nindependent product security assessment and evaluation programs for their products.\nUse a tailored threat model during resource allocation and development to prioritize \nthe most critical and high-impact features. Threat models consider a products specific \nuse-case and enable development teams to fortify products. Finally, senior leadership \nshould hold teams accountable for delivering secure products as a key element of \nproduct excellence and quality.\nAs part of the October 2023 update to this guidance, these three principles are \nexpanded upon through the following explanations, demonstrations, and evidence.\nPRINCIPLE 1: Take Ownership of \nCustomer Security Outcomes\nEXPLANATION\nModern best practices dictate that software manufacturers invest in product \nsecurity efforts that include application hardening, application features, and \napplication default settings. \nSoftware manufacturers need to implement application hardening by using \nprocesses and technologies that raise the cost for a malicious actor wishing to \ncompromise applications . Application hardening protocols and procedures help \nproducts resist attacks by intelligent malicious actors . Terms like hardening, product \nsecurity, and resilience are all closely related to product quality  . The idea is that \nsecurity must be baked in,  and not bolted on .  [1] By baking in security, software \nmanufacturers can not only increase their customers security but also increase \ntheir products quality  . Sample tactics include ensuring user input is validated \nand sanitized, and isnt entered directly into code (i . e ., by using parameterized \nqueries instead), using a memory safe programming language, rigorous software \ndevelopment life cycle (SDLC) management, and using hardware-backed \ncryptographic key management .\nApplications need to support application features that relate to cybersecurity  . \nSometimes called capabilities,  these features extend the functionality of a product \nor service in ways that help maintain or increase the security posture of a customer  . TLP:CLEAR\n\n12\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nSample security-related features include supporting transport layer security (TLS) for all \nnetwork connections, single sign on (SSO) support, multi-factor authentication (MFA) \nsupport, security event audit logging, role-based access control (RBAC), and attribute-\nbased access control (ABAC) .\nSome of these product features are configurable allowing customers to more \neasily integrate the product into their existing environments and workflows . Those \nconfigurations mean applications must have default settings set until customers \nconfigure them . Those default settings need to be set securely out of the box so that \ncustomers expend fewer resources to make their stack of technology products more \nsecure .\nEach of these elements  application hardening, application security features, and \napplication default settings  plays a role in the security of the application, and the \nresulting security posture of the customer  . Software manufacturers should think about \neach of these elements and how they relate to each other  .  Manufacturers should \nthink about more than just their investments to incorporate these elements into their \nproducts . Manufacturers should take it a step further and consider how those elements \nchange the real-world security posture of their customers, for better or for worse . \nManufacturers should take ownership of their customers security outcomes rather than \nmeasuring themselves solely on their efforts and investments . The responsibility should \nbe placed upstream, with the manufacturers, where it has the greatest likelihood of \nreducing the chances of compromise .\nUnfortunately, thats not the case today  . Too many manufacturers place the burden of \nsecurity on the customer rather than investing in comprehensive application hardening. \nFor example, when the manufacturer patches one vulnerability, we often see similar \nvulnerabilities exposed because they addressed the symptom rather than the root cause \nof that defect . The product might implement different mitigations in various parts of the \ncode base for the same class of vulnerability  . As a case in point, after the manufacturer \nfixed one input sanitization vulnerability, researchers or attackers found code paths that \ndid not benefit from the improved input sanitization . The manufacturer applied fixes one \nat a time rather than unifying the codebase to eliminate that class of vulnerability across \nthe entire application .\nApplication features can create both benefits and risk for customers . Features that \nallow integration points with many external systems and versions can greatly increase \nthe value of a product . And yet supporting features without a retirement plan, like a \nnetworking protocol, can leave customers vulnerable if they lack an understanding of the \nimplications of ongoing use of that feature . For example, some products continue to use \nnetworking protocols that have their origins in the 1990s or 2000s and are now known \nto be unsafe . There are numerous factors that can slow how fast customers upgrade \nand deploy modern security measures . They may use products that integrate with the \nrest of the organizations network, but lack modern security measures, preventing the IT \nteam from modernizing  . Still, software manufacturers can factor these patterns into their \nplanning process to encourage customers to stay current .\nApplication default settings are an added area of potential risk for customers . \nManufacturers often choose certain default settings, making it easier for customers \nto use the application features they want . The downside is that this practice increases \nthe attack surface for customers who may not need certain features and protocols that \nare enabled by default . Additionally, many security controls are toggled off by default or \nrequire customers to take time to configure their settings to increase security  . Explicit \nthreat modeling is a tactic that may help inform the decision of which features should be \non by default or which settings are needed to be secure by default . Another tactic is to \ninvestigate ways to make features more discoverable for the administrator  .\n\n13\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nThe software industry needs more secure \nproducts, not more security products. Software \nmanufacturers should lead that transformation.Some manufacturers ship products with defaults that can create risk for some or all their \ncustomers . Rather than set safer defaults, they often opt to produce a hardening guide \nthat customers must implement at their own expense . Hardening guides suffer from several \ncommon problems . Some hardening guides are hard to find and are not well supported . \nOthers are complex to implement, occasionally requiring software development to write an \nextension module . Still, others assume the reader has extensive cybersecurity experience \nto understand the ways in which various settings change the attack surface . Practitioners \nwho have an incomplete understanding of the ways in which attackers work may fail to \nproperly implement hardening guide instructions, especially if the instructions do not make \nthe trade offs clear  . Further, not all hardening guides are written by engineers who are \nintimately familiar with attacker tactics and economics, causing them to create hardening \nguides that are ineffective even if faithfully implemented . Millions of customers are taking \non the responsibility to harden multiple instances of software or systems, often in resource-\nconstrained environments . Relying on hardening guides simply doesnt scale . \nAn applications settings should be continuously evaluated whether the settings were the \ndefault or set by the customer, against the manufacturers current understanding of the \nthreat landscape . Applications should be made with clear indicators about the potential \nrisks that may result from those settings and should make those indicators known . Just like \na modern car has an indicator about seatbelts and expresses that indicator by sounding \nan alert if you try to drive without buckling up, software should express indicators about \nthe state of security of a system . If an application is configured to not require MFA for \nadministrator accounts, it should make the administrators regularly aware that they and \ntheir entire organization are in danger if they do not configure MFA . Additionally, if an \napplication is configured to support older protocols that are now known to implement weak \ncryptography, it should regularly make it clear to the administrators that the organization \nis in danger and provide resources to resolve the situation . We urge manufacturers \nto implement routine nudges that are built into the product rather than relying on \nadministrators to have the time, expertise, and awareness to interpret hardening guides . \nOpportunities clearly exist for innovation to balance security and usability considerations . \nEach of the above elements creates an untenable situation in which customers need \nto research, fund, purchase, staff, deploy, and monitor additional security products to \nreduce the chance of compromise . Small and medium sized organizations (SMOs) are \ngenerally unable to facilitate these options . They face scarcity in expertise, funding, and \ntime which taxes bandwidth and function, forcing security to a lower priority, and, in the \naggregate, exacerbates collective risk . Conversely, security investments by the relative \nfew manufacturers will scale . A common phrase that summarizes the problem is that the \nsoftware industry needs more secure products, not more security products . Software \nmanufacturers should lead that transformation .\n\n14\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nToday, we sometimes read comments from manufacturers explaining that a customer \nwas compromised due to not enabling a particular security feature or following specific \nhardening guidance . Instead, after a compromise, manufacturers should explain whether \na particular security feature or specific hardening guidance would have prevented the \ncompromise and consider making it the default at no charge . In those cases where the \nproduct itself was not sufficiently hardened in the design and implementation phases, the \nmanufacturer should explain how they are working to eliminate that class of vulnerability \nfrom their product lines . \nSoftware manufacturers have a responsibility to ensure that their products are designed \nand developed with security as a top priority  . To that end, they should objectively measure \nthe results of their efforts in the field . We call on manufacturers to not just focus on \ntheir internal efforts, but to objectively measure and regularly report the results and \neffectiveness of a products security efforts and configurations, and to build a feedback \nloop that creates changes in the SDLC that lead to measurable improvements in customer \nsafety and more secure products . Reporting should include anonymized data that the \nacademic and security research community could use to track high-level trends and \nmeasure progress ecosystem wide .\nDEMONSTRATING THIS PRINCIPLE\nSoftware manufacturers and online services should find ways to demonstrate successes in \nimplementing this principle . They should seek to provide evidence in the form of artifacts \nfor outsiders to examine . No single artifact by itself will prove that a manufacturer is \nimplementing a robust secure by design program, but by providing various artifacts they \nwill build a case of the manufacturers commitment to developing secure products . This \napproach is in the spirit of show, rather than tell . \nTo demonstrate this principle, software manufacturers should consider steps such \nas those in the following list . The authoring organizations recognize that few software \nmanufacturers will be able to immediately implement these practices and produce \ncorresponding artifacts at the start of their secure by design journey  . Further, software \nmanufacturers will need to prioritize this list depending on how the customers deploy the \nproduct in the field to achieve the largest security benefits .\n\n15\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nSECURE BY DEFAULT PRACTICES\n1. Eliminate default passwords. Default \npasswords continue to be implicated as \nthe cause of many attacks every year  . \nMaking a commitment to eliminate this \nchronic problem will deny easy access \nto attackers . Similarly, manufacturers \nshould consider what password practices \nshould be implemented, such as minimum \npassword length and disallowing known \nbreached passwords . \n2. Conduct field tests. As technology \ncontinues to evolve and become more \ncomplex, it is increasingly important \nfor software manufacturers to conduct \nsecurity-centric user testing to \nunderstand their products security \nposture in the field . Similar to how user \nresearch informs software development \nrequirements, software manufacturers \nshould also conduct security-focused \nuser research to understand where the \nsecurity user experience (UX) falls short . \nBy observing how customers deploy \nand use their products in real-world \nenvironments, software manufacturers \ncan gain valuable insights into the usability \nand effectiveness of their security \nfeatures and controls . These insights can \nhelp identify areas for improvement and \nrefine their products to better meet the \nsecurity needs of customers . For example, \nfield tests might suggest changes in UX \nflow, defaults, alerting, and monitoring  . \nField tests may also show where past \nimprovements in the products design \nreduce the velocity of security patches, \nreduce configuration errors, and minimize \nattack surface .  \nManufacturers should consider \nthe following: \n Do customers correctly implement the \nhardening guide?  Do the products existing security features \nperform as expected in the field? \n Do those features actually resist real-world \nattacks? \n Which features would better reduce the likelihood \nof compromise? \nNote: To gain deeper insights into these \nelements, software manufacturers may wish \nto partner with customers to conduct red \nteam exercises to see how the product resists \nattacks. These field tests might take place at the \ncustomers physical site, virtually, or via telemetry \nfrom the application in a privacy-preserving \nmanner.\n3. Reduce hardening guide size. Manufacturers \ncan improve customers security postures \nby streamlining or even eliminating product \nhardening guides and focusing on the most \ncritical security measures that customers \nshould prioritize when deploying their products . \nRather than overwhelming customers with a \nlaundry list of security measures, manufacturers \nshould identify the top security risks that their \nproducts are susceptible to and provide clear \nand concise guidance on how to mitigate these \nrisks . In addition, manufacturers should provide \ncustomers with tools and automation that simplify \nthe process of implementing security controls, \nsuch as scripts that can easily be deployed in \ntheir environment . These tools should additionally \nbe able to verify and clearly show the changes \nmade from the original baseline . By streamlining \nhardening guides and providing customers with \neasy-to-use tools and automation, manufacturers \ncan reduce the burden on their customers and \nhelp ensure that their products are deployed in a \nsecure manner  . One tactic would be to consider \nimplementing the Pareto principle to reduce the \nnumber of steps for the common use cases (the \n80%), and then providing contextual guidance and \ntooling for less common scenarios (the 20%) . In \nthis way, software manufacturers will be making \n\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS\nthe simple things simple, and the hard things possible . \nField testing will be a powerful tool in measuring how long \nit takes customers to discover, understand, and implement \nhardening guides . Manufacturers should consider how the \nproduct could nudge administrators to take action within \nthe product itself rather than relying on them to implement \ntasks from a hardening guide .\n4. Actively discourage use of unsafe legacy features. \nPrioritize security through clear upgrade paths over \nbackwards compatibility  . Publish blog posts showing the \nadoption of safer features and protocols, and deprecate \nunsafe features by announcement, possibly from within \nthe product itself  . A significant number of customers \nhave demonstrated that they will not keep their systems \ncurrent with modern network, identity, and other critical \nsecurity features . In some cases, customers fear existing \nfunctionality will break with an upgrade . By making \nupgrades as seamless as possible, customers will likely \nupgrade and get security fixes more often and quickly  . \nSoftware manufacturers should aggressively nudge \ncustomers along upgrade paths that reduce customer risk .\n5. Implement attention grabbing alerts.  \nSimilar to seat belt chimes in cars that continuously make \nnoise when seat belts are not fastened, manufacturers \nshould implement timely and repeated alerts when \nusers or admins are in truly unsafe states, warning \nadministrators that they are using deprecated protocols in \ntheir environments and suggest upgrade paths . Implement \ntimely and repeated alerting when users or admins, or the \napplication configuration, are in an unsafe state . Make the \nunsafe mode clear to the administrators on a regular basis . \nAn additional feature could require a super administrator \nto acknowledge the lack of MFA on their account upon \neach login, or even disable certain key features until they \nenable MFA . There is room to innovate to achieve these \ngoals while not creating alert fatigue .\n6. Create secure configuration templates.  \nThese templates can pre-set certain configurations to \nsafe settings based on an organizations risk appetite . \nWhile it might be overly simplistic to have low/medium/\nhigh security templates, that example illustrates how \nmany settings could be updated to manage risk for the \norganization . Templates can be supported by hardening \nguides on the risks the manufacturer has identified .TLP:CLEAR\nTLP:CLEAR16\n\n17\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nSECURE PRODUCT \nDEVELOPMENT PRACTICES\n3  NIST SSDF, PO 1.2, Example 2: Define policies that specify the security requirements for the organizations software, and verify compliance \nat key points in the SDLC (e.g., classes of software flaws verified by gates, responses to vulnerabilities discovered in released software).\n1. Document conformance to a \nsecure SDLC framework. Secure \nSDLC frameworks provide objectives \nand examples across people, processes, \nand technologies . Consider publishing a \ndetailed description of which secure SDLC \nframework controls have been implemented \nand describe any alternate controls \nwhich have been used . Within the US, \nconsider using the NIST Secure Software \nDevelopment Framework (SSDF) . While \nnot a checklist, the SSDF describes a set \nof fundamental, sound practices for secure \nsoftware development . \n2. Document Cybersecurity Performance \nGoals (CPG) or equivalent \nconformance. When an organization \nattests that they conform to the NIST SSDF \nstandard, they are asserting that their \nSDLC is informed by well-understood best \npractices . However, it is not sufficient for \nthem to only have a robust SDLC  . They also \nneed to protect their own enterprise and \ndevelopment environments from malicious \nactors who would seek to manipulate the \nsecurity properties of the product while \nit is still in development . This is not a \ntheoretical class of attack, but one that \nhas been carried out with adverse effects \nto customers, and by extension national \nsecurity  . Organizations should consider \npublishing details on the organizations \nconformance to the CISA CPGs, the NIST \nCybersecurity Framework (CSF), or other \ncybersecurity program frameworks .\n3. Vulnerability management. Some \nmanufacturers have a vulnerability \nmanagement program that focuses on \npatching vulnerabilities discovered internally \nor externally, and little more . More mature \nprograms incorporate extensive data-\ndriven analysis of vulnerabilities and their \nroot causes, taking steps to systemically \neliminate entire classes of vulnerability3 . They \nimplement formal programs around setting quality \nplanning, quality control, quality improvement, \nand quality measurement . They view defect \nmanagement as a business matter, not merely a \nsecurity matter  . These programs are not dissimilar \nin some ways to quality and safety programs in \nother industries .\n4. Responsibly use open source software.  \nWhen open source software is used, \nbe responsible by vetting open source \npackages, fostering code contributions back \nto dependencies, and helping sustain the \ndevelopment and maintenance of critical \ncomponents . For reference, Japans Ministry \nof Economy, Trade, and Industry (METI) has \npublished \"Collection of Use Case Examples \nRegarding Management Methods for Utilizing \nOSS and Ensuring Its Security  .\"\n5. Provide secure defaults for developers.  \nMake the default route during software \ndevelopment the secure one by providing safe \nbuilding blocks for developers . For example, given \nthe prevalence of SQL injection vulnerabilities \ncausing real-world harm, ensure that developers \nuse a well-maintained library to prevent that class \nof vulnerability  . Also known as paved roads or \nwell-lit paths,  this practice ensures both speed \nand security, and reduces human error  .\n6. Foster a software developer workforce that \nunderstands security. Ensure that your software \ndevelopers understand security by training them \non secure coding best practices . Further, help \ntransform the broader workforce by updating \nhiring practices to evaluate security knowledge \nand working with universities, community \ncolleges, bootcamps, and other educators \nto weave security into computer science and \nsoftware development curriculums .\n\nTLP:CLEAR\n7. Test security incident event management (SIEM) and security orchestration, automation, \nand response (SOAR) integration. In addition to conducting field tests, work jointly with \npopular SIEM and SOAR providers in conjunction with select customers to understand how \nincident response teams use logs to investigate suspected or actual security incidents . Few \nsoftware developers have experience responding to an incident and may create log entries that \ndont help responders as much as they would expect . By working both with SIEM and SOAR \ntechnologies and real incident response professionals, the development team can create \nlogs that tell the correct and complete story, saving time and reducing uncertainty during an \nincident . \n8. Align with Zero Trust Architecture (ZTA). Align product deployment guides with, for example, \nthe NIST ZTA models and the CISA Zero Trust Maturity Model . Encourage customers to \nincorporate these principles in their environments .\nTLP:CLEARCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS 18\n\n19\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nPRO-SECURITY BUSINESS PRACTICES\n1. Provide logging at no additional charge. \nCloud services should commit to generating \nand storing security-related logs at no \nadditional charge . On-premises products \nshould likewise generate security-related \nlogs at no additional charge . Further, \nthe product should log security events \nby default since many customers may \nnot understand their value until after an \nincident . These tactics may require a \nthorough review of what security events \nshould be logged to provide cybersecurity \nstate awareness, how a customer may \nconfigure logging, for what time period \nlogs are retained, how log integrity and \nstorage are protected, and how logs can be \nanalyzed . In some cases, the review may \nsuggest the need for a refactoring of the \napplications log management architecture \nto help make them actionable and at a cost \nthat works for the manufacturer  . Working \nwith incident response (IR) experts can \nincrease the chances that the logs will be \nuseful to investigators in the field . See the \nsection on SIEMs .\n2. Eliminate hidden taxes. Publish a \ncommitment to never charge for security \nor privacy features or integrations . For \nexample, within the larger scope of identity \nand access management (IAM), there \nare services called single sign-on (SSO) \nservices . Some manufacturers charge more \nto connect their system to a SSO service \n(sometimes referred to as an identity \nprovider) . This SSO tax means that good \nidentity and access management is out of \nreach for many SMOs, preventing them \nfrom achieving a strong security posture . \nSome services charge more to enable MFA \nfor users . Security should not be priced as \na luxury good but considered a customer \nright. Some manufacturers have argued \nthat few customers request these features, \nand they cost more to maintain . These \narguments ignore the fact that few customers \nwill call to complain or bargain, not all customers \nactually understand what the benefits of these \nfeatures are, and that all features cost something \nto maintain . Yet we dont see many manufacturers \ncharging extra for availability or data integrity  . The \ncosts to support those key attributes are built into \nthe price all customers pay, much like the costs to \ninclude seatbelts, collapsible steering columns, \nand airbags that save lives in accidents .\n3. Embrace open standards. Implement open \nstandards, especially around common network \nand identity protocols . Avoid proprietary protocols \nwhen open standards are available . \n4. Provide upgrade tooling. Many customers \nare reluctant to adopt the latest version of the \nproduct, including deploying newer and more \nsecure features like secure network connections . \nSoftware manufacturers can increase customer \nadoption of new upgrades by providing tooling \nto help reduce uncertainty and risk . Offer \nfree licenses for customers to test upgrades \nand patches in a test environment as a way to \nmotivate customers .\n\n20\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nPRINCIPLE 2: Embrace Radical \nTransparency and Accountability\nEXPLANATION\nSoftware manufacturers should pride themselves in delivering safe and secure \nproducts, as well as differentiating themselves from the rest of the manufacturer \ncommunity based on their ability to do so  .\nLets address a common concern about transparency  . When practitioners discuss \nradical transparency, there is a tendency for the conversation to get bogged down \nin a concern that they are providing a roadmap for attackers .  However, the \noverwhelming evidence is that attackers are doing just fine without such roadmaps, \nand such concerns should take a back seat to transparency that benefits direct \ncustomers, indirect customers, supply chains, and the entire software industry  .\nTransparency helps the industry establish conventionsin other words, what good \nlooks like . It helps those conventions change over time in response to customer \nneeds, changes in threat actor tactics or economics, or technology evolution . \nTransparency helps manufacturers with fewer resources learn from those with more \nmature and capable resources . Conversations about information sharing should \nexpand beyond real-time threat indicators, to include the elements below  .\nTransparency forces decisions around security to be made early in the development \nprocess, and to be a continuous activity of business leaders as well as engineers and TLP:CLEAR\n\n21\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nsecurity professionals . Transparency builds accountability into the product .\nA note on the choice of the adjective radical in front of transparency  . Today, it \nis uncommon for software manufacturers to publish detailed information about \nhow they develop and maintain software and how they mature their programs \nusing data over time . In the software industry, few manufacturers offer guided \ntours of how they design their software . There are few opportunities for software \nmanufacturers to see how peer organizations structure their SDLC programs, and \nhow those programs hold up in the customer environments against real attackers . \nThe collective industry would benefit from more information sharing on topics such \nas strategies to measure the cost of security defects and to eliminate classes of \nvulnerability  . As a result of these common practices, every software manufacturer \nmust learn how to deal with product security on their own . Perhaps by not placing a \nluxury tax on security features, safety and security therefore become a cost center \nrather than a profit center, and companies would benefit by lightening the load \nthrough collaboration and transparency  .\nWe want to focus on the tactics that will materially accelerate the evolution of the \nsoftware industry  . We can no longer afford to make opportunistic, incremental \nimprovements . If we are to collectively overcome the threats posed by intelligent \nand adaptive adversaries, we must embrace levels of transparency that will \nfeel uncomfortable today, but that will drive the industry forward . There are \nmanufacturers today who embody some of these secure by design principles . \nAs William Gibson said, the future is already here, its just not very evenly \ndistributed .  Radical transparency will help distribute that information and \nbenefit the defenders more than our adversaries.\nTransparency can do more than help peer organizations mature their SDLCs . \nProspective customers and investors can learn more about the investments and \ntradeoffs manufacturers have made, and the security posture those investments \nhave created for customers . Manufacturers who embrace radical transparency will \ngive customers information to help them make purchasing decisions not just on \nprice and features, but on security as well .\nAs hard as organizations work to secure their supply chain and their SDLC, \ncompanies have had their builds processes compromised in the recent past . \nEmbracing radical transparency should lead to public disclosure of the attack as \nwell as the improvements the company made to prevent and detect future attacks . \nThat form of information sharing will help other organizations learn without having \nto suffer the same fate .\nDEMONSTRATING THIS PRINCIPLE\nTo demonstrate this principle, software manufacturers should take steps including \nthe following:\n\n1. Publish aggregate security relevant statistics and trends. Example topics include \nMFA adoption by customers and administrators and use of unsafe legacy protocols .\n2. Publish patching statistics. Detail what percent of customers are on the latest version \nof the product, and what you are doing to make updates easier and more reliable .\n3. Publish data on unused privileges. Publish aggregate information on excessive \npermissions across your customer base as well as the nudges and other changes to \nthe product you are making to reduce the customers attack surfaces . These unused \nprivileges are likely to be good candidates for administrator alerts, like seatbelt chimes .SECURE BY DEFAULT PRACTICESTLP:CLEAR\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS 22TLP:CLEAR\n\n23\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nSECURE PRODUCT \nDEVELOPMENT PRACTICES\n1. Establish internal security controls. \nMany companies have seen the benefits of \nmoving their data to cloud providers . Now \nthose cloud providers become the target \nof attackers . Software as a Service (SaaS) \nproviders should publish statistics of \ntheir internal controls . For example, SaaS \nproviders should publish statistics on their \ninternal deployment of phishing-resistant \nMFA,  like Fast Identity Online (FIDO) \nauthentication . Ideally, they should be able \nto say that no staff member can access \ncustomer or other sensitive data without \nauthenticating via phishing-resistant MFA .\n2. Publish high-level threat models. \nSecure by design products start with \nwritten threat models that describe \nwhat the creators are trying to protect \nand from whom . Effective threat models \nare informed by the way intrusions \nhappen in the wild, and should cover \nboth the enterprise and development \nenvironments, as well as the way the \nsoftware manufacturers intend for it to be \nused in customer environments .\n3. Publish detailed secure SDLC self-\nattestations. Manufacturers following \nNIST SSDF, or other similar frameworks \nare actively working towards a mature \nsoftware development lifecycle . Publishing \na self-attestation of which controls the \nmanufacturer has enacted, and for \nwhich products, would demonstrate a \ncommitment to adhering to these best \npractices and provide an increased level \nof confidence to their customers . Other \ncertification schemes include the Israel \nCyber Supply Chain Methodology, for \ninstance .\n4. Embrace vulnerability transparency. \nPublish a commitment that will ensure \nthat identified product vulnerabilities will be published as CVE entries that are \ncorrect and complete . Thats especially true \nfor the common weakness enumeration \nfield that identifies the root cause of the \nvulnerabilities . The more correct and \ncomplete the public CVE database is, the \nmore the industry can track how products \nare becoming more secure, and which \nclasses of vulnerabilities are most prevalent . \nHowever, beware of the temptation to \ncount CVEs as a negative metric, since \nsuch numbers are also a sign of a healthy \ncode analysis and testing community  . As \nmanufacturers implement a secure by \ndesign philosophy, its possible that at \nfirst their raw CVE count will go up due \nto more comprehensive discovery and \nremediation of vulnerabilities in existing \ncode . Manufacturers should publish \nanalysis of past vulnerabilities, including any \npatterns and measures that were taken to \naddress the entire class of vulnerabilities . \nFor example, if a large percentage of a \ncompanys CVEs were related to cross-\nsite scripting (XSS), documenting the root \ncause analysis, response (such as shifting \nto web template frameworks that prevent \nXSS), and results would signal to customers \nthat they will not be victimized by a class of \nvulnerability for which mitigations have been \nunderstood for decades .\n5. Publish Software Bills of Materials \n(SBOMs). Manufacturers should \nhave command of their supply chains . \nOrganizations should build and maintain \nSBOMs [2] for each product, request data \nfrom their suppliers, and make SBOMs \navailable for downstream customers and \nusers . This will help demonstrate their \ndiligence in understanding the components \nthey use in the creation of their products, \ntheir ability to respond to newly identified \nrisks, and can help customers understand \nhow to respond if one of the modules in the \nsupply chain has a newly found vulnerability  . \n\nTLP:CLEAR\nFor reference, Japans Ministry of Economy, Trade, and Industry (METI) has published \nGuide of Introduction of Software Bill of Materials (SBOM) for Software Management .  \nTransparency should extend to firmware in embedded devices and the data and models \nused in AI/machine learning (ML) . Beyond assisting in purchasing decisions and \noperational capabilities, SBOMs play an important role in the infrastructure to detect \nand respond to malicious supply chain attacks .\n6. Publish a vulnerability disclosure policy. Publish a vulnerability disclosure policy that \n(1) authorizes testing against all products offered by the manufacturer and conditions \nfor those tests, (2) provides legal safe harbor for actions performed consistent with \nthe policy, and (3) allows public disclosure of vulnerabilities after a set timeline . \nManufacturers should perform root-cause analysis of discovered vulnerabilities and, to \nthe greatest extent feasible, take actions to eliminate entire vulnerability classes . See \nCISAs Vulnerability Disclosure Policy Template for reference language .\nTLP:CLEARCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS 24\n\nTLP:CLEAR\nPRO-SECURITY BUSINESS \nPRACTICES\n1. Publicly name a secure by design senior \nexecutive sponsor. In many organizations, \nsecurity (like quality) is delegated to \ntechnical teams who have limited ability to \nmake structural changes to dramatically \nimprove the security of the products . \nPublicly naming a top business executive to \noversee the secure by design program will \ntransform the security of products into a \ntop-level business concern .\n2. Publish a secure by design roadmap. \nManufacturers should document changes \nmade to their SDLC to improve customer \nsecurity, including details about field-\ntest reports, actions taken to eliminate \nentire classes of vulnerability, and other \nitems listed in the other principles . As in \nthe case of quality improvement efforts, \nsecurity improvement programs have \ndistinct phases of planning, control, and \nimprovement . In the spirit of showing rather \nthan telling, publishing the roadmap and \nthe details behind these phases will build \nconfidence that the products are secure \nby design . After achieving meaningful \nprogress, manufacturers can detail them \nin transparency reports . Doing so not only \ndemonstrates a commitment to secure by \ndesign principles but can inspire others \nto adopt similar programs by showing an \nexistence proof  .3. Publish a memory-safety roadmap. \nManufacturers can take steps to eliminate \none of the largest classes of vulnerability \nby migrating existing products and \nbuilding new products using memory safe \nlanguages . While this may not be possible \nin all cases, manufacturers can consider \ndeveloping application wrappers in memory \nsafe languages instead of re-writing entire \napplications . This can also include how \nmanufacturers are updating hiring, training, \ncode review, and other internal processes, \nas well as ways they are helping the open \nsource community do the same .\n4. Publish results. While updating their \nSDLC to embody a secure by design \nphilosophy, organizations will find quick \nwins, more resource intensive wins, and \nsome unexpected setbacks . By presenting \ntheir internal successes and roadblocks, the \nentire industry can learn from the results .\nTLP:CLEARCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS 25\n\n26\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nPRINCIPLE 3: Lead from the Top\nEXPLANATION\nWhile the overall philosophy is called secure by design,  the incentives \nfor customer safety begin well before the product design phase . They \nbegin with business goals and implicit and explicit objectives and desired \noutcomes . Only when senior leaders make security a business priority, \ncreating internal incentives, and fostering an across-the-board culture to \nmake security a design requirement will they achieve the best results .\nWhile technical subject matter expertise is critical to product security, it is \nnot a matter that can be solely left to technical staff  . It is a business priority \nthat must start at the top  .\nSome people have wondered if a software manufacturer is embracing the \nfirst two principles and producing meaningful artifacts, is the third principle \nnecessary? How a company establishes its vision, mission, values, and \nculture will affect the product, and those elements have a heavy component \nat the top  . We see this in other industries that have made dramatic \nimprovements in safety and quality  . Noted quality expert J  .M . Juran wrote:\nWe believe that security is a sub-category of product quality. When \nsecurity and quality become business imperatives rather than technical \nfunctions left solely to technical staff, organizations will be able to respond \nto the security needs of their customers more quickly and efficiently  . \nMoreover, investing the necessary resources to ensure that software \nsecurity is a core business priority from the beginning will reduce the long-\nterm costs of addressing software defectsand in turn, lower the national \nsecurity risks .\nIn the same way that leadership teams have implemented corporate social \nresponsibility (CSR) programs, there is growing awareness that corporate \nboards, including those of software manufacturers, should take a more \nactive role in guiding cybersecurity programs . The term corporate cyber \nresponsibility (CCR) is sometimes used to describe this emerging idea .Attainment of quality leadership requires that the \nupper managers personally take charge of managing \nfor quality. In companies that did attain quality \nleadership, the upper managers personally guided \nthe initiative. I am not aware of any exceptions. [3]\n\n27\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nDEMONSTRATING THIS PRINCIPLE\nTo demonstrate this principle, software manufacturers should take steps including the \nfollowing:\n1. Include details of a secure by design \nprogram in corporate financial reports. \nIf the manufacturer is a publicly traded \ncompany, add a section in each annual \nreport devoted to secure by design efforts . \nIt is common for automobile annual financial \nreports to include sections on driver and \npassenger safety, including information \nabout centralized and distributed quality \nand safety committees . Detailing the secure \nby design program in a financial report will \ndemonstrate that the organization is linking \ncustomer security and corporate financial \noutcomes and not simply adopting a term in \nmarketing materials because it is in vogue . \n2. Provide regular reports to your board \nof directors. Chief information security \nofficer (CISO) reports to corporate boards \nusually include information about current \nand planned security programs, threats, \nsuspected and confirmed security incidents, \nand other updates centered on the security \nposture and health of the company  . In \naddition to receiving information about the \nsecurity posture of the enterprise, boards \nshould request information about product \nsecurity and the impact it has on customer \nsecurity  . Boards should not look solely to \nthe CISO, but primarily to other members \nof company management to drive customer \nrisk down .\n3. Empower the secure by design executive. \nThere is a significant difference between an \norganization where the technical teams have \nexecutive buy-in,  and those where business \nleaders personally manage the customer \nsecurity improvement process using \nstandard business processes . The term \nexecutive buy-in implies that someone had \nto sell the idea of a customer safety program \nrather than it being a top-level business \ngoal . This executive must be empowered to \ninfluence product investments to achieve \ncustomer security outcomes .4. Create meaningful internal incentives. While \nbeing mindful to not create perverse incentives, \nalign reward systems to improve customer \nsecurity to match other valued behaviors and \noutcomes . From the secure by design executive \nto product management, software development, \nsupport, sales, legal, and other organizations, \nweave customer security incentives into hiring, \npromotions, salaries, bonuses, stock options, and \nother common processes in the running of the \nbusiness . For example, when establishing criteria \nfor promoting software developers, include \nconsiderations for improving the security of the \nproduct along with other criteria like uptime, \nperformance, and feature improvements .\n5. Create a secure by design council. In some \nindustries, its common for organizations to create \na central quality council, and to embed quality \nrepresentatives in key divisions or business units . \nBy including both centralized and distributed \nmembers, these groups work to improve quality \nagainst top level goals while receiving telemetry \nfrom deep in the organization . Similarly, a \nsecure by design council would improve security \nagainst secure by design goals throughout the \norganization .\n6. Create and evolve customer councils. Many \nsoftware manufacturers have customer councils \ncomprised of customers from different regions, \nindustries, and sizes . These councils can provide \na great deal of information about customer \nsuccesses and challenges in deploying the \ncompanys products . Structure the council agenda \nwith dedicated topics addressing customer \nsafety, even if its not currently top of mind for \nthe participants . Consider where the customer \ncouncil reports and how to tap participants for \ninsights into the products security as deployed . \nFor example, does the council have a bias towards \nmarketing and sales purposes, or product \nmanagement? The secure by design executive \nshould help steer these customer interactions and \nshould link them with other elements in this paper, \nsuch as field studies .\n\n28\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\nThe Secure Software Development Framework (SSDF), also known as the National \nInstitute of Standards and Technologys (NISTs) SP 800-218, is a core set of high-level \nsecure software development practices that can be integrated into each stage of the \nsoftware development lifecycle (SDLC) . Following these practices can help software \nproducers become more effective at finding and removing vulnerabilities in released \nsoftware, mitigate the potential impact of the exploitation of vulnerabilities, and address \nthe root causes of vulnerabilities to prevent future recurrences .\nThe authoring organizations encourage the use of secure by design tactics, including \nprinciples that reference SSDF practices . Software manufacturers should develop a \nwritten roadmap to adopt more secure by design software development practices across \ntheir portfolio  . The following is a non-exhaustive illustrative list of roadmap best practices:\n Memory safe programming languages (SSDF PW.6.1). Prioritize the use of memory \nsafe languages wherever possible . The authoring organizations acknowledge \nthat memory specific mitigations may be helpful shorter-term tactics for legacy \ncodebases . Examples include C/C++ language improvements, hardware mitigations, \naddress space layout randomization (ASLR), control-flow integrity (CFI), and \nfuzzing  .  Nevertheless, there is a growing consensus that adoption of memory \nsafe programming languages can eliminate this class of defect, and software \nmanufacturers should explore ways to adopt them . Some examples of modern \nmemory safe languages include C#, Rust, Ruby, Java, Go, and Swift . Read NSAs \nmemory safety information sheet for more .\n Secure Hardware Foundation. Incorporate architectural features that enable \nfine- grained memory protection, such as those described by Capability Hardware \nEnhanced RISC Instructions (CHERI) that can extend conventional hardware \nInstruction-Set Architectures (ISAs), as well as other features like Trusted Platform \nModules and Hardware Security Modules . For more information visit, University of \nCambridges CHERI webpage .\n Secure Software Components (SSDF PW 4.1). Acquire and maintain well-secured \nsoftware components (e .g  ., software libraries, modules, middleware, frameworks) \nfrom verified commercial, open source, and other third-party developers to ensure \nrobust security in consumer software products .\n Web template frameworks (SSDF PW.5.1). Use web template frameworks that \nimplement automatic escaping of user input to avoid web attacks such as cross-site \nscripting  .\n Parameterized queries (SSDF PW 5.1). Use parameterized queries rather than \nincluding user input in queries, to avoid SQL injection attacks .\n Static and dynamic application security testing (SAST/DAST) (SSDF PW  .7 .2, \nPW .8 .2) . Use these tools to analyze product source code and application behavior \nto detect error-prone practices . These tools cover issues ranging from improper \nmanagement of memory to error prone database query construction (e .g  ., \nunescaped user input leading to SQL injection) . SAST and DAST tools can be \nincorporated into development processes and run automatically as part of software \ndevelopment . SAST and DAST should complement other types of testing, such \nas unit testing and integration testing, to ensure products comply with expected \nsecurity requirements . When issues are identified, manufacturers should perform \nroot-cause analysis to systemically address vulnerabilities .SECURE BY DESIGN TACTICS\n\n29\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICASTLP:CLEAR\nTLP:CLEAR\n Code review (SSDF PW  .7 .1, PW  .7 .2) . Strive to ensure that code submitted into \nproducts goes through quality control techniques such as peer review by other \ndevelopers or error seeding  . \n Software Bill of Materials (SBOM) (SSDF PS .3 .2, PW  .4 .1) . Incorporate the creation \nof SBOM4  to provide visibility into the set of software that goes into products . \n Vulnerability disclosure programs (SSDF RV  .1 .3) . Establish vulnerability disclosure \nprograms that allow security researchers to report vulnerabilities and receive \nlegal safe harbor in doing so  . As part of this, suppliers should establish processes \nto determine root causes of discovered vulnerabilities . Such processes should \ninclude determining whether adopting any of the secure by design practices in this \ndocument (or other similar practices) would have prevented the introduction of the \nvulnerability  .\n CVE completeness. Ensure that published CVEs include root cause or common \nweakness enumeration (CWE) to enable industry-wide analysis of software \nsecurity design flaws . While ensuring that every CVE is correct and complete can \ntake extra time, it allows disparate entities to spot industry trends that benefit all \nmanufacturers and customers . For more information on managing vulnerabilities, \nsee CISAs Stakeholder-Specific Vulnerability Categorization (SSVC) guidance .\n Defense-in-Depth. Design infrastructure so that the compromise of a single \nsecurity control does not result in compromise of the entire system . For example, \nensuring that user privileges are narrowly provisioned, and access control lists \nare employed can reduce the impact of a compromised account . Also, software \nsandboxing techniques can quarantine a vulnerability to limit compromise of an \nentire application .\n Satisfy Cybersecurity Performance Goals (CPGs). Design products that meet basic \nsecurity practices . CISAs Cybersecurity Performance Goals outline fundamental, \nbaseline cybersecurity measures organizations should implement . Additionally, \nfor more ways to strengthen your organizations posture, see the UKs Cyber \nAssessment Framework  which shares similarities to CISAs CPGs . If a manufacturer \nfails to meet the CPGs such as not requiring phishing-resistant MFA for all \nemployees then they cannot be seen as delivering secure by design products .\nThe authoring organizations recognize that these changes are significant shifts in \nan organizations posture . As such, their introduction should be prioritized based on \ntailored threat modeling, criticality, complexity, and business impact . These practices \ncan be introduced for new software and incrementally expanded to cover additional use \ncases and products . In some cases, the criticality and risk posture of a certain product \nmay merit an accelerated schedule to adopt these practices . In others, practices can be \nintroduced into a legacy codebase and remediated over time .\n4  Some of the authoring organizations are exploring alternate approaches to gaining security assurances around the software \nsupply chain.\n\nIn addition to adopting secure by design development practices, the authoring \norganizations recommend software manufacturers prioritize secure by default \nconfigurations in their products . These should strive to update products to conform to \nthese practices as they are refreshed . For example:\n Eliminate default passwords. Products should not come with default passwords that \nare universally shared . To eliminate default passwords, the authoring organizations \nrecommend products require administrators to set a strong password during \ninstallation and configuration or for the product to ship with a unique, strong password \nfor each device .\n Mandate multifactor authentication (MFA ) for privileged users. We observe that \nmany enterprise deployments are managed by administrators who have not protected \ntheir accounts with MFA . Given that administrators are high value targets, products \nshould make MFA opt-out rather than opt-in . Further, the system should regularly \nprompt the administrator to enroll in MFA until they have successfully enabled it on \ntheir account . Netherlands NCSC has guidance that parallels CISAs, visit their Mature \nAuthentication Factsheet for more information .\n Single sign-on (SSO). IT applications should implement single sign on support via \nmodern open standards . Examples include Security Assertion Markup Language \n(SAML) or OpenID Connect (OIDC  .) This capability should be made available by default \nat no additional cost .\n Secure Logging. Provide high-quality audit logs to customers at no extra charge or \nadditional configuration . Audit logs are crucial for detecting and escalating potential \nsecurity incidents . They are also crucial during an investigation of a suspected or \nconfirmed security incident . Consider best practices such as providing easy integration \nwith security information and event management (SIEM) systems with application \nprogramming interface (API) access that uses coordinated universal time (UTC), \nstandard time zone formatting, and robust documentation techniques .\n Software Authorization Profile. Software suppliers should provide recommendations \non authorized profile roles and their designated use case . Manufacturers should \ninclude a visible warning that notifies customers of an increased risk if they deviate \nfrom the recommended profile authorization . For example, medical doctors can view all \npatient records, but a medical scheduler has limited access to certain information that \nis required for scheduling appointments .\n Forward-looking security over backwards compatibility. Too often, backwards- \ncompatible legacy features are included, and often enabled, in products despite \ncausing risks to product security  . Prioritize security over backwards compatibility, \nempowering security teams to remove insecure features even if it means causing \nbreaking changes .\n Track and reduce hardening guide size. Reduce the size of hardening guides \nthat are included with products and strive to ensure that the size shrinks over time as \nnew versions of the software are released . Integrate components of the hardening \nguide as the default configuration of the product . The authoring organizations SECURE BY DEFAULT TACTICSTLP:CLEAR\nTLP:CLEAR30CISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS\n\nrecognize that shortened hardening guides result from ongoing partnership with \nexisting customers and include efforts by many product teams, including user \nexperience (UX) .\n Consider the user experience consequences of security settings. Each new setting \nincreases the cognitive burden on end users and should be assessed in conjunction \nwith the business benefit it derives . Ideally, a setting should not exist; instead, the most \nsecure setting should be integrated into the product by default . When configuration is \nnecessary, the default option should be broadly secure against common threats .\nThe authoring organizations acknowledge these changes may have operational effects \non how the software is employed . Thus, customer input is critical in balancing operational \nand security considerations . We believe that developing written roadmaps and executive \nsupport that prioritize these ideas into an organizations most critical products is the first \nstep to shifting towards secure software development practices . While customer input \nis important, we have observed important cases where customers have been unwilling \nor unable to adopt improved standards, often network protocols . It is important for the \nmanufacturers to create meaningful incentives for customers to stay current and not \nallow them to remain vulnerable indefinitely  .TLP:CLEAR\nTLP:CLEAR31CISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS\n\nHARDENING VS LOOSENING GUIDES\nHardening guides may result from the lack of product security controls being \nembedded into a products architecture from the start of development . Consequently, \nhardening guides can also be a roadmap for adversaries to pinpoint and exploit \ninsecure features . It is common for many organizations to be unaware of hardening \nguides, thus they leave their device configuration settings in an insecure posture . An \ninverted model known as a loosening guide should replace such hardening guides \nand explain which changes users should make while also listing the resulting security \nrisks . These guides should be written by security practitioners who can explain the \ntradeoffs in clear language to increase the chances of them being applied correctly  .\nRather than developing hardening guides that list methods for securing products, \nthe authoring organizations recommend software manufacturers shift to a secure by \ndefault approach and providing \"loosening guides . \" These guides explain the business \nrisk of decisions in plain, understandable language, and can raise organizational \nawareness of risks to malicious cyber intrusions . Security tradeoffs should be \ndetermined by the customers senior executives, balancing security with other \nbusiness requirements .TLP:CLEAR\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS 32TLP:CLEAR\n\nRECOMMENDATIONS \nFOR CUSTOMERS\nThe authoring organizations recommend organizations hold \ntheir supplying software manufacturers accountable for the \nsecurity outcomes of their products . As part of this, the authoring \norganizations recommend that executives prioritize the importance \nof purchasing secure by design and secure by default products . \nThis can manifest through establishing policies requiring that IT \ndepartments assess the security of software before it is purchased, \nas well as empowering IT departments to push back if necessary  . IT \ndepartments should be empowered to develop purchasing criteria \nthat emphasize the importance of secure by design and secure by \ndefault practices (both those outlined in this document and others \ndeveloped by the organization) . Furthermore, IT departments \nshould be supported by executive management when enforcing \nthese criteria in purchasing decisions . Organizational decisions \nto accept the risks associated with specific technology products \nshould be formally documented, approved by a senior business \nexecutive, and regularly presented to the board of directors .\nKey enterprise IT services that support the organizations security \nposture, such as the enterprise network, enterprise identity and \naccess management, and security operations and response \ncapabilities, should be seen as critical business functions that are \nfunded to align with their importance to the organizations mission \nsuccess . Organizations should develop a plan to upgrade these \ncapabilities to leverage manufacturers that embrace secure by \ndesign and secure by default practices .\nWhere possible, organizations should strive to forge strategic \nrelationships with their key IT suppliers . Such relationships include \ntrust at multiple levels of the organization and provide vehicles \nto resolve issues and identify shared priorities . Security should \nbe a critical element of such relationships and organizations \nshould strive to reinforce the importance of secure by design and \nsecure by default practices in both the formal (e .g  ., contracts or \nvendor agreements) and informal dimensions of the relationship  . \nOrganizations should expect transparency from their technology \nsuppliers about their internal control posture as well as their \nroadmap towards adopting secure by design and secure by default \npractices .TLP:CLEAR\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS 33TLP:CLEAR\n\nIn addition to making secure by default a priority within an organization, IT leaders \nshould collaborate with their industry peers to understand which products and \nservices best embody these design principles . These leaders should coordinate \ntheir requests to help manufacturers prioritize their upcoming security \ninitiatives . By working together, customers can help provide meaningful input to \nmanufacturers and create incentives for them to prioritize security  .\nWhen leveraging cloud systems, organizations should ensure they understand the \nshared responsibility model with their technology supplier  . That is, organizations \nshould have clarity on the supplier's security responsibilities rather than just the \ncustomers responsibilities .\nOrganizations should prioritize cloud providers that are transparent about their \nsecurity posture, internal controls, and ability to live up to their obligations under \nthe shared responsibility model .\nDISCLAIMER\nThe information in this report is being provided as is for informational purposes only. \nCISA and the authoring organizations do not endorse any commercial product or service, \nincluding any subjects of analysis. Any reference to specific commercial entities or \ncommercial products, processes, or services by service mark, trademark, manufacturer, \nor otherwise does not constitute or imply endorsement, recommendation, or favoritism by \nCISA and the authoring organizations. This document is a joint initiative by CISA that does \nnot automatically serve as a regulatory document.TLP:CLEAR\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS 34TLP:CLEAR\n\nCISA\n  CISAs SBOM Guidance\n  CISAs Cross-Sector Cybersecurity Performance Goals\n  Guidelines on Technology Interoperability\n  CISA and NISTs Defending Against Software Supply Chain Attacks\n  The Cost of Unsafe Technology and What We Can Do About It | CISA\n  Stop Passing the Buck on Cybersecurity: Why Companies Must Build \nSafety Into Tech Products (foreignaffairs.com)\n  CISAs Stakeholder-Specific Vulnerability Categorization (SSVC) Guidance\n  CISAs Phishing Resistant MFA Fact Sheets\n  Cyber Guidance for Small Businesses | CISA\nNSA\n  NSAs Cybersecurity Information Sheet on Memory Safety\n  NSAs ESF Securing the Software Supply Chain: Best Practices for \nSuppliers\nFBI\n  Understanding and Responding to the SolarWinds Supply Chain Attack: \nThe Federal Perspective\n  The Cyber Threat - Response and Reporting\n  FBIs Cyber Strategy\nNational Institute of Standards and Technology (NIST)\n  NISTs Digital Identity Guidelines\n  NISTs Cyber Security Framework\n  NISTs Secure Software Development Framework (SSDF)\nAustralian Cyber Security Centre (ACSC)\n  ACSCs IoT Code of Practice Guidance for Manufacturers\nThe United Kingdoms National Cyber Security Centre (UK)\n  The UKs Cyber Assessment Framework\n  The UK NCSCs Secure Development and Deployment guidance\n  The UK NCSCs Vulnerability Management guidance\n  The UK NCSCs Vulnerability Disclosure Toolkit\n  University of Cambridges CHERI\n  So long and thanks for all the bits - NCSC.GOV.UK \nCanadian Centre for Cyber Security (CCCS)\n  CCCSs Guidance on Protecting Against Software Supply Chain Attacks\n  Cyber supply chain: An approach to assessing risks\n  Canadian Centre for Cyber Securitys CONTI ransomware guidanceResources\nTLP:CLEAR\nTLP:CLEARCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS 35\n\nGermanys Federal Office for Information Security (BSI)\n  The BSI Grundschutz compendium (module CON.8)\n  The international standard IEC 62443, part 4-1\n  State of IT-security in Germany report, 2022\n  BSI practices of web application security\nNetherlands National Cyber Security Centre\n  NCSC-NLs Mature Authentication Factsheet\nJapans National Center of Incident Readiness and Strategy \nfor Cybersecurity (NISC)\n  Japans National Cybersecurity Strategy\nJapans Ministry of Economy, Trade and Industry (METI)\n  Guide of Introduction of Software Bill of Materials (SBOM) for Software \nManagement\n  Collection of Use Case Examples Regarding Management Methods for \nUtilizing OSS and Ensuring Its Security\nCyber Security Agency of Singapore\n  Technical Advisory on Secure API Development\n  CSA SingCERT Vulnerability Disclosure Policy\n  CSA SingCERT Incident Response Checklist\n  CSA SingCERT Incident Response Playbooks\n  CSA Security by Design Framework\n  CSA Security by Design Framework Checklist\n  CSA Guide to Cyber Threat Modelling\n  CSA Cybersecurity Labelling Scheme\nOther\n  How Complex Systems Fail\n  The New Look in complex system failure\nREFERENCES\n[1] https://csrc.nist.rip/publications/history/ande72.pdf\n[2] https://www.cisa.gov/sbom and SBOMs references in TR 03183-2 https://www.bsi.bund.de/dok/TR-03183\n[3] Juran on Quality by Design by J.M. Juran, 1992.\nTLP:CLEAR\nCISA | NSA | FBI | ACSC | CCCS | CERT NZ | NCSC-NZ | NCSC-UK | BSI | NCSC-NL\nNCSC-NO | NKIB | INCD | KISA | NISC-JP | JPCERT/CC | CSA | CSIRTAMERICAS 36TLP:CLEAR\n\n",
  "cves": [],
  "techniques": [],
  "advisory": "cybersecurity-alerts",
  "title": "shifting-the-balance-of-cybersecurity-risk-principles-and-approaches-for-secure-by-design-software",
  "source": "nsa",
  "id": "0079e8221d07140f6d2360e4ee22b9eb6c4de0cf610ca977aca87e5ccdf6a28b"
}