{
  "markdown": " \n \n \n \nNational Security Agency  \nCybersecurity  Technical Report  \n \n \n \n \n \nDoD Microelectronics:  \nField  Programmable Gate Array  \nBest Practices  Threat Catalog  \n \n \n \n \n \nMay 2024 \n \nU/OO/ 156779 -24 \nPP-24-1961  \nVersion 1.1 \n \n \n  \n\n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  ii \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \n \n This document was created through collaboration with each of the \nJFAC labs: National Security Agency (NSA), Air Force Research \nLab (AFRL) RYDT, Naval Surface Warfare Center (NSWC) Crane, \nand Army Development Command (DEVCOM)/AVMC.  \nFor additional information, guidance, or assistance with this \ndocument, please contact the Joint Federated Assurance Center \n(JFAC) at JFAC_HWA@radium.ncsc.mil . \n  \n \n\n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  iii \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nNotices and history   \nDocument change history  \nDate  Version  Description  \nDecember  2022  1.0 Initial Publication  \nMay 2024  1.1 Updated descriptions. Merged TD 10 into TD 2.  \nDisclaimer of warranties and endorsement  \nThe information and opinions contained in this document are provided \"as is\" and without any warranties \nor guarantees. Reference herein to any specific commercial products, process, or service by trade name, \ntrademark, manufacturer, or otherwise, does not constitute or imply its endorsement, recommendation, or \nfavoring by the United States Government, and this guidance shall not be used for advertising or product \nendorsement purposes.  \nPublication information  \nAuthor(s)  \nNational Security Agency  \nCybersecurity Directorate  \nJoint Federated Assurance Center  \nContact information  \nJoint Federated Assurance Center : JFAC_HWA@radium.ncsc.mil  \nGeneral Cybersecurity Report Inquiries: CybersecurityReports@nsa.gov  \nDefense Industrial Base Inquiries and Cybersecurity Services: DIB_Defense@cyber.nsa.gov  \nMedia inquiries / Press Desk: Media Relations, 443 -634-0721, MediaRelations@nsa.gov  \nPurpose  \nThis document was developed in furtherance of NSAs cybersecurity missions. This includes its \nresponsibilities to identify and disseminate threats to National Security Systems, Departmen t of Defense \ninformation systems, and the Defense Industrial Base, and to develop and issue cybersecurity \nspecifications and mitigations. This information may be shared broadly to reach all appropriate \nstakeholders.   \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  iv \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nExecutive summary  \nThis report categorizes hardware assurance threats that apply to field programmable \ngate arrays  (FPGA s) as described in the Joint Federated Ass urance Center (JFAC) \nFPGA Level  of Assurance (LoA) document s. This report  does not list all technical \nmethods an attacker mig ht employ, but rather it identifies  common threat categories \nrequiring  mitigation strategies . These threats originate from an adversary, are malicious, \nand compromise the operation of an FPGA -based system by:  \n Modifying intended behavior  \n Adding extraneous n ew behaviors  \n Impeding or preventing operation  \n Degrading operation or reliability  \n Making use of known vulnerabilities in specific FPGA devices  \nThis report provides readers with a clear  understand ing of  JFAC identified  FPGA \nthreats .  \n  \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  v \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nContents  \nExecutive summary  ................................ ................................ ................................ ......................  iv \n1. FPGA threat catalog overview  ................................ ................................ ................................  1 \n2. Threat descriptions  ................................ ................................ ................................ ..................  4 \n2.1. TD 1: Adversary uses a known FPGA platform vulnerability  ................................ ...........................  4 \n2.2. TD 2: Adversary inserts malicious counterfeit  ................................ ................................ .......................  5 \n2.3. TD 3: Adversary compromises application design cycle  ................................ ................................ ... 6 \n2.4. TD 4: Adversary compromises system assembly , keying, or provisioning  ................................  7 \n2.5. TD 5: Adversary compromises third -party soft IP  ................................ ................................ ................  8 \n2.6. TD 6: Adversary swaps configuration file on target  ................................ ................................ .............  9 \n2.7. TD 7: Adversary substitutes modified FPGA software design suite  ................................ ...........  10 \n2.8. TD 8: Adversary modifies FPGA platform family at design  ................................ ............................  10 \n2.9. TD 9: Adversary compr omises single -board computing system (SBCS)  ................................ . 11 \n2.10. TD 10 Adversary modifies FPGA software design suite  ................................ ...............................  12 \n3. Summary  ................................ ................................ ................................ ................................ .. 12 \nAppendix A: Standardized terminology  ................................ ................................ ...................  13 \n \nTables  \nTable 1: Level of Assurance threats  ................................ ................................ ................................ .......................  2 \nTable 2: Attack cost and attack value  ................................ ................................ ................................ .....................  3 \nTable 3: Threat descriptions and LoA matrix  ................................ ................................ ................................ ....... 4 \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  1 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \n1. FPGA  threat catalog overview  \nThis field programmable gate array (FPGA)  threat catalog was created using potential \nthreats  identified  in the 2014 Trust in FPGA Study (classified) and its 2020 update ; U.S. \nGovernment research ; JFAC and subject matter expert input ; academic papers ; and \nFPGA vendor  publications . Collectively, the threats are categorized under the following \nhigh level groupings based upon their commonality of characteristics and mitigations:  \n Adversary uses  a known FPGA platform vulnerability  \n Adversary inserts malicious counterfeit  \n Adversary compromises application design cycle \n Adversary compromises system assembly , keying , or provisioning  \n Adversary compromises third-party soft intellectual property (IP)  \n Adversary swaps configuration file on target  \n Adversary substitutes modified FPGA software design suite \n Adversary modifies FPGA platform family at design  \n Adversary compromises single -board computing system (SBCS)  \n Adversary inserts a compromise during the FPGA fabrication process  \n Adversary modifies FPGA software design suite \nThis document discusses the list of  threats and their relvancy at  applicable L evels of \nAssurance (L oAs) using the criteria defined in the CTR: DoD Microelectronics Levels of \nAssurance Definitions and Application s document .  \nIn accordance with the CTR: DoD Microelectronics Levels of Assurance Definitions and \nApplication s document , LoAs are characterized by the likelihood of an attack . The \nlikelihood of an attack is based on the cost to an adversary to carry out the attack  and \nthe utility  of the outcome to the adversary. As the  level of assuranc e rises, the cost \nincreas es and the utilty decreas es. The definition of each LoA is defined in Table 1:  \nLevel of Assurance Threats . \n  \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  2 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nTable 1: Level of Assurance threats   \nLevel  Threats  \n \n \n \n \n Threats that have a low cost to implement and with high utility \nto the adversary.  (High likelihood  threats ) \n Threats with moderate costs to implement and that achieve \nmoderate levels of utility to the adversary. Additionally, this is \ninclusive of all LoA1 threats.  (High and moderate likelihood  \nthreats ) \n Threats with a high cost to implement and/or low utility to the \nadversary, in addition to all LoA1 and LoA2 threats.  (High, \nmoderate, and  low likelihood  threats ) \n \nIn Table 1, cost is defined by the level of access, the sophistication of the technology  \nneeded to implement the attack,  and the investment the adversary would require to \nexecute the thr eat. Utility is defined as the value the adversary obtains b y succes sful \nimplementation, along with the advesarys ability  to affect a specific target or set of \ntargets . \nTable 2 define s the cost an d utility criteria at each LoA.  \n  \nLoA2  \nLoA3  \nLoA1  \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  3 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nTable 2: Attack cost and attack value  \n Criteria  LoA1 LoA2  LoA3  Attack cost  Access  \nA single available point of access     \nA difficult point of access or multiple available points of access     \nMultiple points of difficult access     \nTechnology  \nExisting public technology     \nLow implementation risk technology     \nTechnologically feasible     \nInvestment  \nMinimal investment of resources     \nA large multidisciplinary team     \nA nation scale directed priority     Attack utility  Value of e ffect  \nDisable or subvert a system     \nEstablish vulnerabilities (for future exploitation)     \nDegrade system performance     \nTargetability  \nInherently targetable and controllable     \nAffects only a subset of systems     \nBlind attacks ( Difficult to precisely target  or control the \noutcome)     \nIndividual t hreats were analyzed for their cost and utility characteristics and then \ncombined into higher level categories based upon any commo n goals  or common  \nmitigations . This process resulted  in the final top -level group ings of common threats  \nidentified  in Table 3. Most have relevancy  at multiple  LoAs based upon how the attack \nis implemented. In this document, each threat is discussed at each level of applicability.  \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  4 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nTable  3: Threat description s and LoA matrix  \n# Threat description (TD)  LoA1 LoA2  LoA3  \nTD 1  Adversary uses  a known FPGA platform vulnerability     \nTD 2  Adversary inserts malicious counterfeit     \nTD 3  Adversary compromises application design cycle     \nTD 4  Adversary compromises system assembly , keying , or \nprovisioning     \nTD 5  Adversary compromises third -party soft IP     \nTD 6  Adversary swaps configuration file on target     \nTD 7  Adversary substitutes modified FPGA software design suite     \nTD 8  Adversary modifies FPGA platform family at design  *   \nTD 9  Adversary compromises single -board computing system \n(SBCS)     \nTD 1 0 Adversary modifies FPGA software design suite     \n* TD 8 is not a threat at LoA 1; however, JFAC request s that DoD programs even at LoA1 provide \ninformation about FPGA device use as described in DoD Microelectronics : FPGA LoA 1 Best Practices  - \n5. JFAC Survey Request . This information relates to TD 8 mitigations.  \n2. Threat descriptions  \n2.1. TD 1: Adversary uses  a known FPGA platform vulnerability  \nIn this threat , an adversary uses  a vulnerability in an FPGA platform to carry out an \nattack. A vulnerability is a weakness in the design of a n FPGA platform that allow s an \nadversary  to use it for malicious purposes. This t hreat does not focus on a particular \nvulnerability, but could be any weakness in the FPGA device. Known  vulnerabilities are \npublished in public databases such as  Common Vulnerabilities and Exposures (CVE) \nand the National Vulnerabilities Database (NVD) . Such vulnerabilities could allow for \nleakage of sensitive information or keys; compromise of security or tamper detection \nfunctions; or  unauthorized reconfiguration of the product.   \nAs the LoA of a program rises, the access and technology required to impl ement a  \nthreat become increasingly difficult. The use of insiders  may provide  better opportunities \nto access and take advantage of a weakness . Additionally, at higher LoAs there is a n \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  5 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nincrease d burden on  the adversar y to uncover  and utilize  unknown vulnera bilities  (also \nknown as zero -day vulnerabilities) , typically involving  nation state resources.   \nThe following examples illustrate how the threats become increasingly complex in their \nimplementation as the LoA increases:  \n LoA1  \no An adversary exploits a  publis hed vulnerability to attack a system.  \no A compromised  insider compromises research to hide a vulnerability.  \n LoA2  \no A compromised cleared insider hides or covers up a vulnerability.  \no A compromised cleared insider inserts malicious code to exploit a \nvulnerability.  \no An adversary exploits a vulnerability proven  in academic research.  \n LoA3  \no Multiple compromised cleared people exploit  a vulnerability  that is known by \nonly a subset of people . \no Nation state resources are leveraged  to take advantage of a vulnera bility. \no An adversary exploits a theoretical vulnerability suggested  in academic \nresearch.   \no Collaboration of cleared and uncleared persons  to exploit a vulnerability . \n2.2. TD 2 : Adversary inserts malicious counterfeit  \nIn this threat , an adversary inserts a  counterfeit part into the supply chain of a DoD \nprogram. A counterfeit part is one put forth as a genuine device, but that differs from the \noriginal in function or reliability. These counterfeit devices can include any of the \nfollowing:  \n A device manufactu red in an  unauthorized fabrication facility with functional or \nreliability differences.  Differences reside on the die or in the packaging.  \n A device manufactured in an authorized fabrication facility with functional or \nreliability differences.  Differences r eside on the die or in the packaging.  \n Genuine devices re presented as a different par t with functional or reliability \ndifferences . An example is a commercial device represented as a military grade \nproduct.  Differences reside in the package markings or the die and package \ncombination .  \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  6 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nIn general, modifications to an FPGA platform at the fabrication stage are considered to \nrequire a high level of effort  with low utility and low targetability . However, in cases \nwhere an adversary nation  has already successful ly designed a compatible device, \nalbeit a counterfeit, that work has already been performed  and the adversarys overall \ninvestment in the effort is reduced.  \nThe following examples illustrate  how the threats become increasingly complex in their \nimplementat ion as the LoA increases:  \n LoA1  \no Counterfeit parts built in an existing unauthorized fab are inserted in the \nsupply chain.  \n LoA2  \no Modifications are made to the package contents during shipping . \no Modifications are made to the die in an authorized fab and inserte d into the \nprograms supply chain.  \n LoA3  \no The FPGA design is compromised during design development . \no The FPGA is compromised during manufacturing . \no Package changes are made that are sent to  the entire supply chain.  \n2.3. TD 3: Adversary compromises application design cycle \nIn this threat, an adversary has access to the design process and data related to the \napplication design effort that incorporates an FPGA , a classic example of an  insider \nthrea t or long-term compromise of an insiders account . The bad actor ta kes advantage \nof access to modify design code, change FPGA configuration settings, or substitute a \nmodified configuration file that was authenticated and built with the same tools and keys \nthat the design team used. Such an attacker is in a particularly ad vantageous position \nbecause they can monitor the design process and modify the product during any phase \nof the design.   \nThe following list illustrates  how the threats become increasingly complex in their \nimplementation as the LoA increases.  The threats ass ociated with this category are \ngenerally the same at each LoA. The primary differences between the LoAs are the \npeople  who participate in the compromise and the level of technology required for a \nsuccessful attack.  Examples include:  \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  7 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \n LoA1  \no An adversary chang es hardware description language (HDL) code via \nnetwork access  (remote or in person) . \no A compromised insider introduces a malicious function that executes at an \nopportune time for the adversary . \no Compromised tooling or software  is incorporated  into the design environment  \nto introduce malicious code or functionality that executes at an opportune \ntime for the adversary . \no The d esign and test phases of development  are compromised to hide \nmalicious code or functionality insertion . \no An insider modifies configura tion data after generation . \n LoA2  \no A compromised cleared insider works with an external  party to modify HDL \ncode . \no A compromised cleared insider modifies tooling  or software in  the \nenvironment.  \no A group of uncleared U .S. persons compromise the design and test phases of \ndevelopment . \no A compromised cleared insider modifies configuration data after generation  \n LoA3  \no Multiple  compromised cleared people  compromise  the final bitstream . \no Multiple cleared insiders compromise key generation and storage.  \no A collaboration of c leared and uncleared persons  compromise the design and \ntest phases of development.  \n2.4. TD 4: Adversary compromises system assembly , keying , or \nprovisioning  \nIn this threat, an adversary carrie s out an attack on the product during printed circuit \nboard asse mbly, key injection, or device configuration. This attack could include the \nassembly house replacing authentic FPGA parts with counterfeit ones, compr omising \nconfiguration files, stealing or modifying encryption keys , or modifying the printed circuit \nboard  (PCB) traces to the FPGA device . Collectively, t hese threats will be refer red to as \nassembly process  threats . While assembly processes are often performed during a \nsingle manufacturing phase, they can be conducted  sepa rately at different locations. \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  8 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nKey injection and provisioning can even occur af ter the manufacturing process. In some \nDoD applications, keys and configuration files are not loade d until the system is fielded.  \nThe following examples illustrate  how the threats become increasingly complex in their \nimplementation as the LoA increases:  \n LoA1  \no An adversary replaces an authentic bitstream with an altered one through \nremote network access . \no A compromised uncleared insider steals  or compromises  keys during \nprovisioning . \n LoA2  \no A compromised cleared insider steals or alters keys during provisioning . \no A group of uncleared U .S. persons compromise the PCB traces during \nassembly . \no An adversary gives a compromised cleared insider security keys  to use to \nalter the program . \n LoA3  \no Multiple com promised cleared people  compromise  the provisioning  and \ntesting phases of assembly . \no An adversary supplies counterfeit parts to an insider to swap in for genuine \nparts . \n2.5. TD 5: Adversary compromises third -party s oft IP  \nIn this threat, an adversary compromises a vendor who sells third -party soft IP intended \nfor integration  into the application design. This IP can be provided through the FPGA \nvendors software IP libraries or directly to the end user by a third-party IP (3PIP) \nvendor. Compromise of the 3PIP vendor can occur during the IP design phase , by a \nprogram insider after acquisition , or via an adversary -in-the-middle attack during the \ndistribution of the IP to the application design team.  \nThe following examples illustrate  how the threats become  increasingly  complex in their \nimplementation as the LoA increases : \n LoA1  \no An adversary includes malicious code during 3PIP development.  \no An adversary uses r emote network access  to swap 3PIP in the design \nenvironment . \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  9 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \no A compromised uncleared insider on the pr ogram design team modifies the \n3PIP .  \n LoA2  \no A compromised c leared insider  assist s the adversary in adding  compromised \n3PIP into the design environment.  \no An adversary insert s compromised 3PIP  into the supply chain , with limited \ndistribution.   \n LoA3  \no Multiple  compromised cleared  persons  insert compromised 3PIP into the \ndevelopment environment.  \no Collaboration of cleared and uncleared persons  insert compromised 3PIP  into \nthe development environment.  \no An adversary insert s compromised 3PIP into the supply chain  without insight \ninto who will use it . \n2.6. TD 6: Adversary swaps c onfiguration file on t arget  \nIn this threat, an adversary obtains access to the system during or after assembly and \ncan modify the behavior of the device via the configuration file . In most cases , the \nconfiguration information is stored on a flash  drive that is par t of the same PCB as the \nFPGA. In other cases, the  configuration information is stored on a system hard drive \nand loaded via a high -speed protocol such as PCI  Express . Some FPGA devices store \nthe configuration informat ion on the FPGA device itself. Since the data is at rest in a \nstorage element, it is susceptible to b eing read and modified by  an adversary wit h \nsufficient technical skills. The modification  could include anything from a complete \nchange  of the bitstream instructions to the introduction  of a subtle and simple \nvulnerability.  \nThe following examples illustrate  how the threats become increasingly complex in their \nimplementation as the LoA increases : \n LoA1  \no An adversary use r emot e network access to update  the configuration file . \no An adversary swaps  the configuration file  in the field . \no An adversary changes  the configuration file prior to loading.  \n LoA2  \no A compromised cleared insider  swaps the configuration file in storage . \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  10 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \no An adversar y loads  a new configuration file  in flash  in the field . \n LoA3  \no A compromised cleared insider provides an alternate configuration file to the \ncleared assembly house for provisioning.  \n2.7. TD 7: Adversary substitutes modified FPGA software design suite \nIn this  threat, an adversary replaces the design suite used by the application designers \nwith one modified to subvert the design at synthesis, implementation, or configuration \nfile generation. Such an adversary would need both the means to modify the vendor tool \nand to insert it into the supply chain.   \nThe following examples illustrate  how the threats become increasingly complex in their \nimplementation as the LoA increases : \n LoA1  \no An adversary modified executable is swapped for authorized software via a \nremote attac k or compromised insider . \n LoA2  \no A compromised cleared insider swaps a modified executable for authorized \nsoftware.  \no A compromised insider  uses a distributor to introduce a modified version . \n LoA3  \no An adversary compromises software at the vendor or at the distr ibution \ncenter. Targeting is not possible.  \n2.8. TD 8: Adversary modifies FPGA platform family at design  \nIn this threat, an adversary compromises the FPGA platform during the design stage  \nsuch that it will compromise the security of devices when in use. This also includes \nthreats in which an adversa ry compromises a piece of third -party hard IP that is used by \nthe platform design team. While the access required to do this is comparable to t he \naccess required for compromising the application design, the targetability is significantly \nmore difficult.   \nThe following examples illustrate  how the threats become increasingly complex in their \nimplementation as the LoA increases : \n LoA1  - Not Applicabl e \n \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  11 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \n LoA2  \no A compromised uncleared insider on the vendo r design team introduces a \nback door into the device design  for later use.  \n LoA3  \no A compromised insider on the vendor design team introduces a reliability \nissue or a means to degrade the performance under limited circumstances.  \n2.9. TD 9: Adversary compromises single -board computing system \n(SBCS)  \nIn this threat, an adversary compromises a single -board computing system (SBCS) \npurchased by a program for use in a system.  An SBCS is a commercial off -the-shelf \n(COTS ) product consisting of a printed circuit board ( PCB) with FPGAs and computer \nprocessing resources.  These boards are readily available in the marketplace  and used  \nin many  DoD systems . Additionally, their relative technical simplicity and low expense \ndo not justify the fabrication of custom solutions by programs. Under this threat, the \nprogram does not have control of the manufacturing process of the SBCS , forcing the \nprogram to rely upon a verification -heavy approach to mitigating threats.  Of primary \nconcern in this scenario are threats to the : \n Authenticity of the FPGA devices themselves , \n Configuration methodology , \n PCB connections , and  \n Test interfaces . \nPCB concerns are left to the program to resolve with the assistance of the JFAC PCB \nExecutive Agent.  \nThe following examples illustrate how the threats become increasingly complex in their \nimplementation as the LoA increases:  \n LoA1:  \no A compromised  SBCS vendor builds a kill switch onto the SBCS board.  \no A compromised  SBCS vendor builds the board using maliciousl y modified \nFPGA devices . \n LoA2:  \no A compromised  SBCS vendor uses  counterfeit FPGAs without configuration \nfile protections or tamper detect ion functions.  \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  12 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \no A compromised cleared program insider provides design information to the \nSBCS for the creation of a custom  malicious change.  \n LoA3:  \no A compromised insider at the SBCS vendor  incorporates a reliability issue \ninto the design of the board.  \n2.10. TD 1 0 Adversary modifies FPGA software design suite \nIn this threat, an adversary has compromised the development of the vendor production \nFPGA synthesis and configuration file  generation software . The subverted tool is the  \nauthorized version delivered by the vendor and its distributors.  While the access to \nexecute this threat may not be difficult , the targeting is significa ntly more difficult.  \nThe following example illustrates this threat:  \n LoA 1  - Not Applicable  \n LoA 2 - Not Applicable  \n LoA 3 \no An adversary compromises an FPGA vendor employee to introduce a \nmalicious function into the configuration file generation tools. The result \ncompromises the security features across an entire family of devices.  \n3. Summary  \nAll of these threat  categories focus specifically on assurance -related threats. They are \nnot inclusive of confi dentiality, security, or tamper -related attacks except in  areas where \nthey overlap assurance concerns. As a program using  FPGAs seeks to apply \nappropriate mitigations for a given LoA, that program would  be expected to provide \nmitigations against the threat categories listed under the corresponding threat level. The \nmitigations suggested by the JFAC Best Practices documents  have been evaluated to \nmitigate those threats to the appropriate level. As expected, for higher LoAs, the \nprogram would  need to address the same threats with higher LoA mitigations.  JFAC is \navailable to guide programs through this process. Additional information for JFAC may \nbe obtained by contacting JFAC_HWA@radium.ncsc.mil .   \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  13 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nAppendix  A: Standardized t erminology  \nThe following terms are used in th e Joint Federated Assurance Center Field \nProgrammable Gate Array Best Practices documents. These terms are modified from \nDefense Acquisition University definitions to support common understanding.  \nApplication design   The collection of schematics, constraints, hardware description \nlanguage (HDL), and other implementation files developed to generate an FPGA \nconfiguration file for use on one or many FPGA platforms.  \nApplication domain   This is the area of technology of  the system itself, or a directly \nassociated area of technology. For instance, the system technology domain of a radar \nsystem implemented using FPGAs would be \"radar\" or \"electronic warfare.\"  \nConfiguration file   The set of all data produced by the applica tion design team and \nloaded into an FPGA to personalize it. Referred to by some designers as a bitstream, \nthe configuration file includes that information, as well as additional configuration \nsettings and firmware, which some designers may not consider p art of their bitstream.  \nControllable effect   Program -specific, triggerable function allowing the adversary to \nattack a specific target.  \nDevice/FPGA device   A specific physical instantiation of an FPGA.  \nExternal facility   An unclassified facility that is out of the control of the program or \ncontractor.  \nField programmable gate array (FPGA)   In this context FPGA includes the full range \nof devices containing substantial reprogrammable digital logic. This includes devices \nmarketed as FPGAs, complex program mable logic devices (CPLD), system -on-a-chip \n(SoC) FPGAs, as well as devices marketed as SoCs and containing reprogrammable \ndigital logic capable of representing arbitrary functions. In addition, some FPGAs \nincorporate analog/mixed signal elements alongsid e substantial amounts of \nreprogrammable logic.  \nFPGA platform   An FPGA platform refers to a specific device type or family of devices \nfrom a vendor.  \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  14 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nHard IP   Hard IP is a hardware design captured as a physical layout, intended to be \nintegrated into a hardware design in the layout process. Hard IP is most typically \ndistributed as Graphic Design System II (GDSII). In some cases, Hard IP is provided by \na fabric ation company and the user of the IP does not have access to the full layout, but \nsimply a size and the information needed to connect to it. Hard IP may be distributed \nwith simulation hardware description language (HDL) and other soft components, but is \ndefined by the fact that the portion that ends up in the final hardware was defined by a \nphysical layout by the IP vendor.  \nLevel of assurance (LoA)   A Level of Assurance is an established guideline that \ndetails the appropriate mitigations necessary for the implementation given the impact to \nnational security associated with subversion of a specific system, without the need for \nsystem -by-system custom evaluation.  \nPhysical unclonable function (PUF)   This function provides a random string of bits of \na predeter mined length. In the context of FPGAs, the randomness of the bitstring is \nbased upon  variations in the silicon of the device due to manufacturing. These bitstrings \ncan be used for device IDs or keys.   \nPlatform design   The platform design is the set of des ign information that specifies \nthe FPGA platform, including physical layouts, code, etc.  \nSoft IP   Soft IP is a hardware design captured in hardware description language \n(HDL), intended to be integrated into a complete hardware design through a synthesis \nprocess. Soft IP can be distributed in a number of ways, as functional HDL or a netlist \nspecified in HDL, encrypted or unencrypted.  \nSystem   An aggregation of system elements and enabling system elements to achieve \na given purpose or provide a needed capabi lity. \nSystem design  System design is the set of information that defines the \nmanufacturing, behavior, and programming of a system. It may include board designs, \nfirmware, software, FPGA configuration files, etc.  \nTarget  A target refers to a specific dep loyed instance of a given system, or a specific \nset of systems with a common design and function.  \n\n \n \nU/OO/ 156779 -24 | PP-24-1961 | May 2024 Ver. 1.1  15 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: FPGA Best Practices  Threat Catalog  \nTargetability  The degree to which an attack may have an effect that only shows up in \ncircumstances the adversary chooses. An attack that is poorly targetabl e would be more \nlikely to be discovered accidentally, have unintended consequences, or be found in \nstandard testing.  \nThird -party intellectual property (3PIP)   Functions whose development are not \nunder the control of the designer. Use of the phrase intell ectual property, IP, or 3PIP in \noutlining this methodology of design review does not refer to property rights, such as, \nfor example, copyrights, patents, or trade secrets. It is the responsibility of the party \nseeking review and/or the reviewer to ensure that any rights needed to perform the \nreview in accordance with the methodology outlined are obtained.  \nThreat category  A threat category refers to a part of the supply chain with a specific \nattack surface and set of common vulnerabilities against which m any specific attacks \nmay be possible.  \nUtility  The utility of an attack is the degree to which an effect has value to an \nadversarial operation. Higher utility effects may subvert a system or provide major \ndenial of service effects. Lower utility attacks m ight degrade a capability to a limited \nextent.  \nVulnerability  A flaw in a software, firmware, hardware, or service component \nresulting from a weakness that can be exploited, causing a negative impact to the \nconfidentiality, integrity, or availability of an impacted component or components.  \n\n",
  "cves": [],
  "techniques": [],
  "advisory": "cybersecurity-alerts",
  "title": "ctr_dod_microelectronics-fpga_best_practices_threat_catalog",
  "source": "nsa",
  "id": "c5fbe4cbc6fe16e13b8296580d17f3e3ef3143b057cce16458c1d8eed5f4e582"
}