{
  "markdown": " \n \n \n \nNational Security Agency  \nCybersecurity  Technical Report  \n \n \n \n \n \nDoD Microelectronics :  \nLevels of Assurance Definitions and \nApplication s \n \n \n \n \n \nJULY 2022 \n \nU/OO/ 173659 -22 \nPP-22-1079  \nVersion 1.0 \n \n  \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  ii \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \n \n \nFor additional information, guidance or assistance with this document, please contact \nthe Joint Federated Assurance Center (JFAC) at https://jfac.navy.mil . \n  \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  iii \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nNotices and history   \nDocument change history  \nDate  Version  Description  \nJULY   2022  1.0 Initial Publication  \n   \nDisclaimer of warranties and endorsement  \nThe information and opinions containe d in this document are provided \"as is\" and without any warranties \nor guarantees. Reference herein to any specific commercial products, process, or service by trade name, \ntrademark, manufacturer, or otherwise, does not necessarily constitute or imply its endorsement, \nrecommendation, or favoring by the United States Government, and this guidance shall not be used for \nadvertising or product endorsement purposes.  \nPublication information  \nAuthor(s)   \nNational Security Agency  \nCybersecurity Directorate  \nJoint Federated Assurance Center  \nContact information  \nJoint Federated Assurance Center: https://jfac.navy.mil   \n \nDefense Industrial Base Inquiries and Cybersecurity Services: DIB_Defense@cyber.nsa.gov   \n \nMedia Inquiries / Press Desk: Media Relations, 443-634-0721, MediaRelations@nsa.gov   \nPurpose  \nThis document was developed in furtherance of NSAs cybersecurity missions . This  includ es its \nresponsibilities to identify and disseminate threats to National Security Systems, Department of Defense \ninformation systems, and the Defense Industrial Base, and to develop and issue cybersecurity \nspecifications and mitigations. This information may be shared broadly to reach all appropriate \nstakeholders.   \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  iv \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nExecutive summary  \nThis document describes a consistent and measurable approach to addressing \nassurance risks in the fabrication of custom microelectronic components (CMC), \ncomprised of A pplication Specific Integrated Circuits (ASIC) , Field Programmable Gate \nArrays (FPGA) , and other microelectronic devices whose function is custom or \nconfigurable. This document defines three levels of hardware assurance and the steps \nnecessary to apply them in the pro tection of custom microelectronic parts used in D oD \nsystems.  \nFor the purpose of this document the Defense Acquisition University (DAU) definition for \nhardware assurance (HwA) has been adapted to the following : \nAn evidence -supported level of confidence tha t a CMC device and its configuration do \nnot contain unexpected characteristics or exhibit unintended behaviors due to the \ninfluence of an adversary or known vulnerabilities that will enable an adversary to \ninfluence the systems behavior. These characteris tics or behaviors could range from \ndegraded reliability to denial of service or to complex functional changes.  \nConsistent with  this definition, the Joint Federated Assurance Center (JFAC)  has \nidentified  three levels of HwA to be applied by D oD programs to their top -level system \nand its critical components.  \nLevel of assurance  Typical criteria  \n \n If the system fails, U.S. Government (USG) capability will be reduced in a \nmeaningful way. If the system is subverted, it can cause harm to U.S. \npersonnel, property, or interests. However:  \n Essential operational capabilities for the DoD will remain available \neven during a system failure.  \n If the system fails, the consequences will be grave. If the system is \nsubverted, it can cause serious harm  to U.S. personnel, property, or \ninterests. However:  \n Essential operational capabilities for the DoD may be degraded \nduring a system failure, and  \n Redundant capabilities can be brought online as part of a continuity \nof operations plan, and  \n The failure of  the system will not cause cascade effects across \nmany DoD or allied systems.  \nLoA2  \nLoA1  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  v \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \n If the system fails, the consequences will be extremely grave. If the system \nis subverted, it can cause exceptionally grave harm  to U.S. personnel, \nproperty, or interests. A failure or subversion of this system:  \n May represent an existential risk to the USG, and  \n May cascade across many DoD systems in a way that impacts total \noperational readiness in an immediate way, and  \n Will inte rrupt essential operational capabilities of the DoD.  \nOnce the system is categorized at the appropriate level of assurance ( LoA), the \nrespective CMC is further analyzed to determine potential threats to the manufacturing \nprocess. The threats are defined by two characteristics at each level: cost and utility. \nThe following table documents the cost and utility characteristics at each LoA.  \n Criteria  LoA1 LoA2  LoA3  Attack cost  Access     \nA single available point of access     \nA difficult point of access or multiple available points of access     \nMultiple points of difficult access     \nTechnology     \nExisting public technology     \nLow implementation risk technology     \nTechnologically feasible     \nInvestment     \nMinimal investment of resources     \nA large multidisciplinary team     \nA nation scale directed priority     Attack utility  Value of e ffect     \nDisable or subvert a system     \nEstablish vulnerabilities (for future exploitation)     \nDegrade system performance     \nTargetability     \nLoA3  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  vi \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \n Criteria  LoA1 LoA2  LoA3  \nInherently targetable and controllable     \nAffects only a subset of systems     \nBlind attacks ( Difficult to precisely target  or control the \noutcome)1    \nAfter CMC  LoAs have been determined by the program, the program should utilize \nJFAC best practice guide s for the relevant assurance level to identify the threats \npresent at that level and effective techniques for mitigating each.  \nThese mitigations can be incorporated directly into  a Program Protection Plan (PPP ).  In \nthis document, CMC products are defined to include the full range of devices containing \nreprogrammable digital logic that can implement arbitrary digital functions and fully  \ncustom integrated circuits. This includes devices marketed as field  programmable gate \narrays (FPGAs), such as complex programmable logic devices (CPLD), and system -on-\na-chip (SoC) FPGAs.  \nThe f ollowing is a list of the available and anticipated best pract ice guides.  \nLevel of Assurance 1 FPGA Best Practices  \nLevel of Assurance 2 FPGA Best Practices  \nLevel of Assurance 3 FPGA Best Practices  \nLevel of Assurance 1 CIC Best Practices  \nLevel of Assurance 2 CIC Best Practices  \nLevel of Assurance 3 CIC Best Practices  \nLevel of Assurance 1 COTS Best Practices  \nLevel of Assurance 2 COTS Best Practices  \nLevel of Assurance 3 COTS Best Practices  \n  \n                                                \n1   As will be discussed later in this document, LoA3 systems are best approached with a full risk analysis to identify which bli nd attacks are of concern to a given \nsystem. Realistic risks in this space are often idiosyncratic, and the most concerning blind attacks are typically not the mo st expensive. LoA3 is the least one \nsize fits all of all the categories specifically because many such syst ems are judged to need to concern themselves with such unpredictable effects.  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  vii \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nContents  \nDoD Microelectronics:  Levels of Assurance Definitions and Applications  ......... i \nExecutive summary  ................................ ................................ ................................ ......................  iv \n1 Levels of assurance  ................................ ................................ ................................ ..................  1 \n1.1 Identification criteria for components  ................................ ................................ ................................ ..........  2 \n1.1.1 Final determination of LoA by DoD  ................................ ................................ ................................ ..... 3 \n1.1.2 LoA selection example  ................................ ................................ ................................ .............................  4 \n1.2 Component levels of assurance threat characteristics  ................................ ................................ ........ 6 \n1.2.1 Cost and utility of threats  ................................ ................................ ................................ ........................  6 \n1.2.2 Cost characteristics  ................................ ................................ ................................ ................................ ... 8 \n1.2.3 Relationship of cost and utility to LoA  ................................ ................................ ................................  9 \n2 Levels of assurance  ................................ ................................ ................................ ................  11 \n2.1 Lo A1 threats  ................................ ................................ ................................ ................................ .......................  11 \n2.2 LoA2 threats  ................................ ................................ ................................ ................................ .......................  13 \n2.3 LoA3 threats  ................................ ................................ ................................ ................................ .......................  15 \n3 Implementation strategy  ................................ ................................ ................................ .........  17 \n4 Summary  ................................ ................................ ................................ ................................ ... 19 \nAppendix A: JFAC F PGA Documents Overview  ................................ ................................ ..... 20 \nAppendix B: Standardized Terminology  ................................ ................................ ..................  22 \n \nFigures  \nFigure 1: Example LoA determination process for subcomponents  ................................ ..........................  5 \nTables  \nTable 1: System and component LoA criteria as determined by national impact ................................ . 3 \nTable 2: Mapping critical components to levels of assurance  ................................ ................................ ...... 5 \nTable 3: LoA threats defined by cost and utility  ................................ ................................ ................................ . 7 \nTable 4: Cost characteristics and descriptions  ................................ ................................ ................................ ... 8 \nTable 5: Utility characteristics and descriptions  ................................ ................................ ................................ . 9 \nTable 6: Threat criteria that an LoA must protect against  ................................ ................................ ............  10 \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  1 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \n1 Levels of assurance  \nFor the purpose of this  document the Defense Acquisition University (DAU) definition for  \nhardware assurance (HwA)  has been adapted to the following:   \nAn evidence -supported level of confidence that a CMC device and its configuration do \nnot contain unexpected characteristics or exhibit unintended behaviors due to the \ninfluence of an adversary or known vulnerabilities that will enable an adversary to \ninfluence the systems behavior. The se characteristics or behaviors could range from \ndegraded reliability to denial of service or to complex functional changes.  \nConsistent with this definition, the Joint Federated Assurance Center ( JFAC ) has set \nforth three levels of hardware assurance (HwA) that can be applied by D oD programs to \ntheir top -level system and its critical components. These are known as levels of \nassurance (LoA).  \nIn these documents, each level of assurance identifies three th ings:  \n \nThe seriousness of the \nconsequence  to national \nsecurity in the event that \nthe system and device fail \nor are subverted.   \nThe specific types and \ncharacteristics of the \nthreats  that must be \naddressed for the given \nlevel.  \nA list of JFAC approved \nmitigations  for protecting \nthe respective device from \nthe list of given threats . \n \nPrograms should first identify the appropriate LoA for the top -level system. Once th e \nsystem is categorized at the appropriate LoA, the program should analyze the \nrespective  CMC to determine potential threats to the manufacturing process. The \nthreats are defined by two characteristics at each level: cost and utility.  \nOnce the program determines the LoAs, it should  use a JFAC best practice guide for \nthe relevant assurance level and type of CMC to identify the threats present at that level \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  2 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nand effective techniques for mitigating each . These mitigations can be incorporated \ndirectly into a Program Protection Plan (PPP) . \nThe following are the  available and a nticipated best practice guides:  \n Level of Assurance 1 FPGA Best Practices  \n Level of Assurance 2 FPGA Best Practices  \n Level of Assurance 3 FPGA Best Practices  \n Level of Assurance 1 CIC Best Practices  \n Level of Assurance 2 CIC Best Practices  \n Level of Assurance 3 CIC Best Practices  \n Level of Assurance 1 COTS Best Practices  \n Level of Assurance 2 COTS Best Practices  \n Level of Assurance 3 COTS Best Practices  \nIn this report, CMC products include the full range of devices containing \nreprogrammable digital logic that can implement arbitrary digital functions and fully \ncustom integrated circuits. This includes devices marketed as field  programmable gate \narrays (FPGAs), such as complex programmable logic devices (CPLD), and system -on-\na-chip (SoC) FPGAs.  \n1.1 Identification criteria  for components  \nWithin this framework and as part of the development of a PPP, a program  must \ndetermine which LoA is appropriate for each CMC or for each subsystem containing a \nCMC. That determination is dependent on two elements:  \n National impact caused by the failure or subversion of the top-level system , and  \n Criticality of the component to that system .  \nThe larger contributor of the two in this determination is the national impact caused by \nthe failure of the system. That is, systems  where:  \n Failure can be mitigated  using alternative capabilities and options in real time \nbelong in LoA1.  \n The consequence of failure is dramatic , but which do not represent existential \nthreats, belong in LoA2.  \n Failure represent s an existential threat  to the United States belong in LoA3.  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  3 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nThis guidance is not applicable to s ystems  that do not minimally meet LoA1 cr iteria , but \nprograms should consider implementing the appropriate LoA1 mitigations depending on \nthe their needs.  \nThe f ollowing table summarizes the criteria for a program to determine the appropriate \nLoA for their top -level system.  \nTable 1: System and component  LoA criteria  as determined by national impact  \nLevel of assurance  Typical criteria  \n \n If the system fails, U.S. Government (USG) capability will be reduced in a \nmeaningful way. If the system is subverted , it can cause harm to U.S. \npersonnel, property, or interests. However:  \n Essential operational capabilities for the DoD will remain available \neven during a system failure.  \n If the system fails, the consequences will be grave. If the system is \nsubverted, it can cause serious harm to U.S. personnel, property, or \ninterests. However:  \n Essential operational capabilities for the DoD may be degraded \nduring a system failure, and  \n Redundant capabilities can be brought online as part of a continuity \nof operations plan, and  \n The failure of the system will not cause cascade effects across \nmany DoD or allied systems.  \n If the system fails, the consequences will be extremely grave. If the system \nis subverted, it can cause exceptionally grave harm to U.S. personnel, \nproperty, or interests. A failure or subversion of this system:  \n May represent an existential risk to the US G, and  \n May cascade across many DoD systems in a way that impacts total \noperational readiness in an immediate way, and  \n Will interrupt essential operational capabilities of the DoD.  \n1.1.1  Final d etermination  of LoA  by DoD  \nThe DoD program Milestone Decision  Authority (MDA) makes the final determination of \nthe appropriate LoA  for top -level systems  based on projected national impact. Once  that \ndetermination is made , the program can select the required LoA of each component by \nits criticality, as identified thr ough the PPPs Trusted Systems and Networks ( TSN) \nanalysis.  \nLoA2  \nLoA3  \nLoA1  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  4 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nThe programs TSN analysis  will result in the assignment of a level of criticality \ncommensurate with the consequence of the component s failure to the system. The \nTSN levels of criticality are:  \n Level 1 - Total Mission Failure  \n Level 2 - Significant/Unacceptable Degradation  \n Level 3 - Partial/Acceptable  \n Level 4 - Negligible  \nSome components may have their LoA lowered from the system LoA, because they are \ninsufficiently critical to the system itself. The program reduces the LoAs only  after a \nthorough criticality analysis, which takes into account all dependencies, including from \nthe perspective of all trusted rela tionships and connected devices2. Components within \na system are often implicitly trusted and relied upon by other components, albeit in \nsubtle ways that only reveal the mselves with thorough analysis.  \nIt is not sufficient to demonstrate that the role of a sub -system is less important. Instead, \nits compromise must not allow an adversary access o r influence over other, more \ncritical functions. For example, a component that manages power distribution through a \nsystem may be of low complexity and low sensitivity. However, at the same time, its \nsubversion might be catastrophic. For networked componen ts, no component should be \nassigned a n LoA lower than another component with which it shares a trusted \nrelationship or unfiltered connection.  \n1.1.2 LoA selection e xample  \nThe following figure illustrates the process of selecting the system -and-component -level \nLoAs . In the illustration, the program is creating an airplane and stepping through the \nassurance LoA decision points .  \n1. The MDA and the program decide that the top-level system will require LoA3 \nassurance protections.  \n2. The program identifies all the sys tems critical components and in itially assigns \nthem the system -level LoA; LoA3.  \n3. The program performs a TSN analysis on each of the critical components \nresulting in some being down graded to lower levels of assurance mitigations.  \n                                                \n2 Trusted relationships exist between devices whenever one device provides input to another device that is given privileges to cause changes and effects. Two \ndevices that share a  connected bus or network are a risk, even when they are not intended to communicate with one another in normal operation.  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  5 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \n4. Finally, the program applie s the mitigations to each component appropriate for its \nlevel of assurance.  \n \nFigure 1: Example LoA determination process for subcomponents  \nOnce this analysis is completed,  the analysts on the program can refer to the following \ntable to determine the appropriate LoA for a given component.  \nTable 2: Mapping critical components to levels of assurance  \nSystem LoA  Criticality of component to the system  \nNegligible  Partial / \nAcceptable  Significant / \nUnacceptable  Total Mission \nFailure  \nLoA1    LoA1  LoA1  \nLoA2  LoA1  LoA1  LoA2  LoA2  \nLoA3  LoA1  LoA2  LoA3  LoA3  \n \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  6 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \n1.2 Component  levels of assurance threat c haracteristics  \nOnce a component s LoA has been selected, the  program is encouraged to utilize the \nJFAC -authored  best practice guide s for threats at the relevant LoA.  For insta nce, a \nprogram building an FPGA -based system at LoA1 should consult  Level of Assurance 1 \nFPGA Best Practices Overview . Each  best practice  guide provides the attack and \nmitigations descriptions  designed to satisfy the TSN attack/mitigation analysis in HwA \nfor CMCs . \nThe following sections define the criteria for identifying what threats will be mitigated at \neach LoA. They detail the criteria used to measure  the likelihood of each threat and \nunder which LoA it should be mitigated. These definitions inform the evaluation of the \neffectiveness of relevant mitigation approaches  and do not represent the mitigations \nthemselves.  \n1.2.1 Cost and utility  of threats  \nTo define the criteria, a program must understand a threats  cost and utility to an \nadversary . The JFAC FPGA Assurance Best Practices  guides include the evaluation of \neach threat category in these two areas : \n The full cost to the adversary to im plement the attack and  \n The utility of the attack to the adversary.  \nIn the context of the JFAC Assurance Best Practices, cost refers to the entire spectrum \nof resources required to carry out the respective threat. These costs include investment \nin research and development, personnel requirements, tooling, processes, and funding. \nCost also includes opportunity costs associated with the attack. In particular, the \nopportunity costs include the accesses the adversary must gain and risk to carry out an \nattack.  \nUtility is evaluated on two aspects: the value of the effects for the adversary and the \ndegree to which the adversary is in control of the attack (referred to as targetability). \nThese two characteristics help programs  prioritize  mitigations where an adversary could \nachieve success with reliable high -value effects.  \nConsidered t ogether, cost and utility  measure the  likelihood value in a TSN analysis . \nThis likelihood refers to the potential of an adversary to carry out a specific attack . \nWhen graphed a gainst these two axes, FPGA assurance threats are binned into the \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  7 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nLoA at which they are first relevant . The following table lists and defines the type of \nthreats addressed at each LoA according to these two criteria:  \nTable 3: LoA threats defined by cost and utility  \nLevel  Definitions  \n \n \n \n \n \n \n Threats that have a low cost to the adversary and provide them with high \nutility. They represent the most likely CMC threats.  \n Threats that have high or moderate utility for an adversary. For example, \nintroducing a compromised element that is only effective when combined with \nother compromised components or security failures. LoA2 may include both \nlow- and moderate -cost threats. These represent threats that are likely:  \n High-utility effects with moderate costs,  \n Moderate -utility effects with low costs, and  \n Moderate -utility effects with moderate costs.  \nPlus:  \n Includes all threats from LoA1  \n Threats that have a high cost to implement or have low utility. Specifically, \nthis covers threats that are feasible but may require very high costs. It also \ncovers threats that have marginal or difficult -to-control effects. This LoA \nrepresents those threats that are of concern, but which are least likely to be \nenacted:  \n High-utility and m oderate -utility threats with high costs,  \n Low-utility threats with low or moderate costs, and  \n Low-utility threats with high costs (subject to a system -specific risk \nevaluation).  \nPlus:  \n Includes all threats form LoA1 and LoA2  \nThe three LoAs address the threat categories beginning with the low -cost and high -\nutility threats and continue across the spectrum.  \nThe mitigation requirements for each level include  the requirements of the previous \nlevels and provide cascading protections. That is, a system that r equires LoA2 will \nprovide mitigations to all threats that are relevant to LoA2 and LoA1. Accomplishing \nLoA3 mitigations requires a program to provide mitigations for the threats in LoA2 and \nLoA1.  \nLoA2  \nLoA3  \nLoA1  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  8 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nThe type of threats that would be addressed by each LoA have  specific areas of \nevaluation for the attack cost and attack utility.  \n1.2.2 Cost characteristics  \nFor H wA, JFAC defines attack cost characteristics in three specific areas  as captured in \nthe following table : \nTable 4: Cost characteristics and description s \nCost characteristic  Description  \nAccess  \n The level of access to a vendor, a network, a design center , or a fabrication \nfacility that an adversary requires to conduct an attack. This also includes \nshipment and storage in the supply chain; during assembly, integration, and \ntesting; and in the field. This includes the number of access points and the \namount o f time that access is required.  \nTechnology  \n The level and complexity of technology required by an adversary to conduct \nan attack. This includes the types of tools/software, techniques, and level of \nexpertise.  \nInvestment  \n The volume of resources necessary to carry out the attack. These resources \ninclude funding, labor, and time. All resource costs are specified as relative to \na nation state actor.  \nJFAC  defines  attack utility characteristics in two specific areas  as described in the \nfollowing table: \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  9 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nTable 5: Utility characteristics and description s \nUtility characteristic  Description  \nValue of Effect  \n The value of the effect of an attack measures the positive outcome of the \nattack for an adversary, given success. This measurement is relative to the \ncriticality of the particular system.  \nA high -value effect might disable or subvert a system in arbitrary ways. \nModerate -value effects might establish vulnerabilities that can be combined \nwith future operations in useful ways. The lowest value effects degrade \nperformance in a non -specific way, leaving the adversary to hope that the \noverall degradation establis hes an advantage.  \nTargetability  \n The measurement of the attacks ability to be directed to a specific target for \na specific effect at a speci fic time. This category includes evaluating  the \nreliability and predictability of the outcome. Attacks with high targetability can \nbe controlled by the adversary to occur on demand and to a specific device \nor system. Attacks with a lower targetability may be unreliable, happen at \ntimes that are hard to control, or even happen in cases where an adversary \ndoes not want  them to occur, leading to possible coincidental detection.  \n1.2.3 Relationship of cost and utility to LoA  \nAn important factor in categorizing the threat to the appropriate LoA is that the cost -\nrelated criteria increases as the cost to the adversary increases . Therefore,  \n LoA1 protects against the simplest and least costly threats . \n LoA3 protects against the most costly threats.  \nConversely, the criteria related to the utility of a given attack decreases as the LoA \nincreases, indicating that LoA3 must p rotect against threats that achieve lower utility for \nthe adversary. Less critical USG systems protect against attacks with low cost and high \nutility to the adversary. The most critical USG systems must concern themselves with all \nthreats including those with high costs and/or attacks that have lower utility effects.  \nEach LoA must defend against attac ks re levant to lower LoAs  (i.e., LoA2 must defend \nagainst all relevant LoA1 and LoA2 threats ). This overlapping coverage relationship is \ncaptured in the following table :  \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  10 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nTable 6: Threat  criteria that an LoA must protect against  \n Criteri a LoA1 LoA2  LoA3  Attack cost  Access     \nA single available point of access     \nA difficult point of access or multiple available points of access     \nMultiple points of difficult access     \nTechnology     \nExisting public technology     \nLow implementation risk technology     \nTechnologically feasible     \nInvestment     \nMinimal investment of resources     \nA large multidisciplinary team     \nA nation scale directed priority     Attack utility  Value of e ffect     \nDisable or subvert a system     \nEstablish vulnerabilities (for future exploitation)     \nDegrade system performance     \nTargetability     \nInherently targetable and controllable     \nAffects only a subset of systems     \nBlind attacks ( Difficult to precisely target  or control the outcome)3    \n \n                                                \n3   As will be discussed later in this document, LoA3 systems are best approached with a full risk analysis to identify which bli nd attacks are of concern to a given \nsystem. Realistic risks in this space are often idiosyncratic, and the most concerning blind attacks are typically not the mo st expensive. LoA3 is the least one \nsize fits all of all the categories specifically because ma ny such systems are judged to need to concern themselves with such unpredictable effects.  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  11 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \n2 Levels of assurance  \nLevels of assurance are achieved when the protections i mplemented on a system \nmitigate specific levels of threats. The threats are categorized according to the five \ncriteria  outlined in the preceding section : \n Access , \n Technology , \n Investment,  \n Value of effect, and  \n Targetability.  \n2.1 LoA1 threats  \nTo meet LoA1, a system must protect against the following threat \ncategories  of LoA1 attacks.  \nLoA1 attacks:  \n Exploit a single available point of access,  \n Use existing public technology,  \n Require minimal investment of resources,  \n Disable or subvert system capabi lities, and  \n Are inherently targetable and controllable.  \nLoA1 threats present an attack that is relatively inexpensive for a nation -state adversary \nto carry out and has both high -value and targetable outcomes. Using the criteria, these \nattacks require only  a single available point of access and a minimal investment of \nresources; are carried out using existing public technology; and are inherently \ntargetable with high utility to an adversary.  \nThreats that exceed any of these LoA1 criteria must be resolved a t a higher LoA.  \nAccess  A single available point of access  to some portion of the device \nsupply chain  is defined as the following:  \n An Internet connected network, regardless of other security measures4; \n                                                \n4   The final version of NIST 800 -172 (currently a draft) may provide a standard by which an Internet connected network could be considered sufficiently secure.  \nLoA1  \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  12 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \n Any single uncleared U.S. person5; \n A group of associated foreign nationals within a U.S. organization, such as a \ncorporate office operated in a foreign country ; \n A foreign -owned company servicing part of the supply chain ; or \n Any number of foreign nationals from a high -threat country or its allies with  \naccess to parts of the CMC supply chain . \nTechnology  Existing public technology  means that an attack can be \nconducted using tools that are already available in the public or commercial \ndomain or are straightforward advances of public technology. Examples  would include:  \n Development tools provided by  Engineering Design Automation  (EDA) vendors , \n Internal debugging features that are capable of changing device configuration s, \n Laboratory or fabrication equipment used as intended , \n Publicly available open -source  projects , \n Published academic research , and  \n Results of USG Research & Development (R&D) investment at the unclassified \nlevel, even when protected by International Traffic in Arms Regulations (ITAR).  \nInvestment  Minimal investment of resources  means that  an attack \nrequires a team with existing knowledge and skills as well as individuals with \ndomain knowledge in the technology area of the system being assured. For the LoA \nanalysis, minimal resources is defined as any effort consisting of approximately  the \nequivalency of six person -years of specific CMC/domain expertise or less, focused \nsolely on attacking the target of interest.  \nValue of Effect  Attacks that disable or subvert a system  capability enable \nan adversary to remove a capability from service or  cause it to perform specific \ndeleterious actions. When combined with high targetability, these represent the worst -\ncase scenario for a failure of hardware assurance , enabling an adversary to take over or \ndisable capabilities on command.  \nTargetability   Inherently  targetable  and controllable  threat  operations  are \nexecuted  in a way that provides  straightforward  means  to understand  and \n                                                \n5   The use of a clearance in this context is complex, as a program may be unclassified. As of now, the USG does not have a speci fic means of assessing \nindividuals for risk of involvement in sabotage that can cause harm to the security of the USA. Should such a system be developed, it would be a better choice for \nthis role. As it is, redundancy serves as an equally valid method to meet the requirements that can be inferred from this sta tement.  \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  13 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \npredict  the effect  of an attack  and provide  a mechanism  to control  or time the attack.  For \nexample,  an adversary  who introduces new code  into a system  design  can implement  a \nbroad  number  of malicious  functions.  \nA denial -of-service  attack  falls in this category , if and only if, it is possible  for the \nadversary  to control  when  it takes  effect  after the device  is fielde d. However,  a simple  \nreduction  in reliability  not tied to any trigger6, which  therefore  cannot  be controlled  or \ntimed  in a planned way, does  not fall in this category.   \nPrograms with s ystems required to achieve LoA1  based on the national impact of their \ncompromise can refer to the corresponding Assurance Threats Catalog  to determine the \ncategories of threats against which it will protect . Accompanying that document are LoA \nmitigations packages, which specify mitigati ons that resist attacks against the \ntrustworthiness of the device. The Level of Assurance 1 Best Practices Overview  \nspecifies a pre -evaluated list of options that can sufficiently mitigate each threat of \ninterest. JFAC can provide c ustom guidance if the su ggested mitigations prove \ninfeasible or uniquely costly for some applications. While these mitigations are in place, \nthe CMC can be considered to have achieved LoA1 . \n2.2 LoA2 threats  \nTo meet LoA2, a system must protect against the threat of LoA2 attacks.   \n \nLoA2 attacks:  \n Exploit a difficult point of access,  \n Use technology with low risks of implementation,  \n Require a large multidisciplinary team,  \n Establish vulnerabilities, and  \n Affect only a subset of systems.  \n \nCompared  to LoA1  threats , LoA2 threats require  an increased  level of cost, limited  utility  \nfor the adversary , or both .  \n                                                \n6   A sufficient trigger can be as simple as a change to an operatio nal environment, when such an environment has unique characteristics.  \nLoA2  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  14 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nUsing  the following  criteria , LoA2 threats  require  either  a single  difficult  point  of access  \nor multiple  points  of simple  access  in the supply  chain  to carry  out. They  may also \nrequire  known  nation -state  developed  techniques  and use a large  multidisciplinary  team  \nto implement.  In addition  to the high-utility  threats  included  in LoA1 , LoA2 threats  \ninclude  attacks  that open  the door to future  attacks,  without  being  useful  in isolation.  For \nexample,  attacks  that pre-position  vulnerabilities  or access  for future  attacks  are of \nspecific  interest.  As such,  these  attacks  may not necessarily  be targeted  or predictable  \nat the time of their execution.  \nAccess   A difficult  point  of access  requires  the adversary  to compromise  a \nsystem  or an individual  to circumvent  extensive  practices  taken  to protect  that \naccess.  Difficult points of access  include the following:  \n A single  air-gapped  computer  network , \n A single  cleared  U.S. person , \n A group  of uncleared  U.S. persons,  such  as a small  corporate  office  operated  in \nthe U.S., and  \n Shipping  practices  that are approved  for transport  of information  or equipment \nclassified  Secret  or Top Secret . \nIn addition,  these threats may take advantage of multiple available points of access . \nTechnology   Low implementation  risk technology  includes  any technology  \nwhich,  while  not publicly  available  now,  could  be implemented  with sufficient  \neffort  and minimal  risk of outright  failure.  This include s: \n Capabilities  that public  academic  research  has identified  or internal  USG  R&D  \nhas shown  to be practical ; and  \n Techniques  that have,  according  to substantial  amounts  of open  research,  been  \nperformed  successfully,  but for which  commercial  tools  are not availa ble. \nIn addition, these threats may take advantage of existing public technology.  \nInvestment  A large multidisciplinary team  indicates a team conducting the \noperation that may draw on multiple skills not necessarily associated with either \nthe CMC or the application domain. For the LoA analysis, a large multidisciplinary team \nis defined as any effort consisting of at most 50 work -years of a wide range of technical \nexpertise, focused solely on attacking the device of interest.  \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  15 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nFor example, physics and materials science experts may have suitable technical skills. \nThis level also accounts for a more substantial amount of effort, potentially a sizeable \norganization working on th e attack for a year or more.  \nValue of Effect   Attacks that introduce a vulnerability that is not by itself a \ncomplete attack  may still establish vulnerabilities . These attacks would also \nrequire additional access and technical development to develop into  a complete attack . \nIn addition , attacks  that disable or subvert capabilities  are included  at LoA2 . \nTargetability  Attacks that  affect only a subset of systems  where the \nadversary has no control over that subset. For systems that are affected, the \nbehavior must still be inherently targetable and controllable.  In addition,  any inherently \ntargetable and controllable  attacks from LoA1 are relevant at this level.  \nPrograms with s ystems required to achieve LoA2 based on the national impact of \ncompromise should  refer to the corresponding Assurance Threats Catalog  to determine \nthe specific attacks against which it will need to protect. Accompanying that document \nare CMC LoA mitigations packages, which specify mitigations that resist attacks against \nthe trust worthiness of the device . \nLevel of Assurance 2 Best Practices specifies a pre -evaluated list of options that can \nsufficiently mitigate each threat of interest. Further, custom guidance from JFAC can \nalso be made available if the suggested mitigations prove  infeasible or uniquely costly in \nsome application s. While these mitigations are in place, the CMC can be considered to \nhave achieved LoA2 . \n2.3 LoA3 threats  \nSimilar  to the threats  in LoA2 , threats  at LoA3 have  a high cost and/or a \nlow utility  to the adversary.  In the extreme  case  of high cost and low utility  \nattacks,  a system -specific  threat  analysis  is appropriate  to eliminate  all \nthreats  that may be present  but are not necessarily  relevant  to the system  under  \nconsideration.   \nLoA3 attacks:  \n Exploit multiple points of difficult access,  \nLoA3  \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  16 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \n Use technology an adversary could feasibly develop with some investment,  \n Require the coordination of many resources and prioritized direction from a \nnation -state,  \n Degrade the behavior or performan ce of a system, and  \n Blindly impact parts, devices, or users while offering the adversary limited \ncontrol.  \nUsing  the previously described criteria , these  threats  may require  multiple  difficult  points  \nof access,  are not technologically  realized  but feasible,  and are generally  blind  attacks.  \nThese  may be difficult  to use for precision  targeting  or may exist solely  for pre-\npositioning.  \nAccess   Multiple  points of difficult access  in different areas of the CMC \nsupply chain  could include:  \n Multiple people  working on different elements of the CMC or government design \nteams . These people can be cleared or uncleared , or \n Multiple people performing different functions in the fabrication process.  \nTechnology   Technologically  feasible  threats  are those  where  existing  \nresearch  indicates  that the technology  could  be developed  with an investment  \nthat would  be feasible  for a known  adversary.  These  threats  might not be associated  \nwith existing  or known  tools  and might not have  associated  reporting  indicating  \nadversary  activity.  Moreover,  while  all of the threats  are possible,  it may be that there  is \nno known  or ongoing  adversary investment  in the capability.  \nInvestment  A directed  nation -scale  priority  refers to a substantive \nprogram conducted by a nation -state that coordinates resources from many \nspecialties and organizations across a wide scope to facilitate an attack.  \nValue of Effect   Those that degrade the behavior or performance of a \nsystem  without fully disabling any specific feature or  a reliable an d specific \nplanned effect.7 For instance, a communications link might be degraded in a way that \nprevents all meaningful communication. Such an attack would fall under disabling a \n                                                \n7 The term degradation  may be used in some domains in a different way.  \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  17 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \ncapability.  In addition,  this LoA must include  all higher value effects described in LoA1 \nand LoA2.  \nTargetability  Blind  attacks  are attacks  that impact  large  numbers  of parts,  whole  \ndevice  families,  or users  without  effort  to impact  a specifically  targeted  part and in a way \nthat has a significant  likelihood  of discovery .  \nBlind  attacks  are those  where  it is hard to predict  the interaction  between  what  \nthe adversaries  do and the consequence  of the attack.  This could  include  attacks  that \nare performed  against  far more  targets  than expected  or, without  an outside  trigger  or \nwithout  foreknowledge  of the attack  outcome  that would  inform  the adversary  of its \nexecution.  These  attacks  can also include  activation  times  that cannot  be controlled  \nonce  fielded; that is to say, a pre-determined  time at which  devices  will fail. In addition,  \nthis LoA must consider all higher targetability attacks described in LoA1 and LoA2.  \nWhen a system is required to achieve LoA3, the program management can refer to the \ncorresponding Assurance Threats  Catalog  document to  determine the categories of \nthreats against which it will need to provide protections. Typically, LoA3 will require a \nspecific threat analysis to determine which attacks are relevant to that system. \nSpecifically, such an analysis may eliminate some attack s that are blind, of low value, \nand of extremely high cost to the adversary while preserving attacks that do not share \nall of those criteria, such as low cost blind attacks, or high utility blind attacks. Such an \nanalysis must be system -specific.  \nOne way to access subject matter expertise and develop such a plan  is direct \nengagement with a JFAC lab. An appropriate JFAC lab can conduct a tailored threat \nassessment to evaluate critical mitigations on a system -by-system basis. While these \nmitigations are in p lace, the CMC can be considered to have achieved LoA3.  \n3 Implementation s trategy  \nAs part of the PPP process, each program must develop a plan for assurance. This \nreport  establishes a specific approach designed to meet this requirement for CMC \nsystems by as signing the system or sub -system to one LoA. The mitigation packages \navailable from JFAC represent pre -evaluated sets of mitigations that, if implemented \ncorrectly, achieve the desired LoA and satisfy the assurance requirements  for the \nidentified threat . In cases where an existing mitigation package is not sufficient, \n\n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  18 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nprograms may engage directly with JFAC to develop alternatives. As with other \nelements of the PPP, the program office provides requirements to performers and \nauditing to validate that the corr esponding requirements were met.  \nTo enable this process, ongoing strategic technology development is required to \nguarantee that appropriate technology is both available and cost -effective. The \nparagraphs b elow describe  a way of evaluating when additional R&D in assurance \ntechnology is necessary.  \nLoA1  should be achievable through the use of purely commercial, non -protected \ntechnology or other approved standards -based guidance when programs are \nimplemented using available  technology that is currently in production. This means  \nprograms must stay apprised  of technology and standards to protect against the \nrelevant threats. Specialized capabilities may still be required to provide assurance in \ncases where legacy CMC are in us e. \nLoA2 and LoA3 may require the use of government IP or specialized commercial IP. It \nmay also require additional design processes at the program level; specialized \nscreening of devices by commercial anti -counterfeiting labs; and evaluation of  \nplatforms and practices by JFAC labs or others on a per CMC platform basis.  \nAt LoA3 , program s will likely be required to work directly with the JFAC labs or other \ndomain experts to ensure their procurement processes and test methods are sufficient \nto validate their use in national security systems.  \nPrograms should document their LoA analysis, dete rminations, and mitigations in the \nPPP. Programs without experience selecting and/or implementing technical mitigations \nfor CMC HwA are strongly encouraged to engage their appropriate JFAC \nrepresentatives as early in the program lifecycle as possible. The JFAC representative \nwill guide the program through the process to ensure efficient and effective mitigation \nstrategies. Furthermore, it is highly recommended that programs implementing LoA2 \nand LoA3 protections consult JFAC prior to entering each MDA miles tone and before \neach major design review.  \nIn preparation for the preliminary design review  (PDR) , JFAC can be consulted on the \nappropriate LoA for any component when the program is uncertain of the correct \ndesignation. In preparation for the critical design review  (CDR), JFAC can be consulted \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  19 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \non mitigation plans. At later stages in the design and manufacturing, JFAC can be \nconsulted for HwA recommendations or investigations. At a minimum, all programs \nshould engage with JFAC for a review to prepare for the  CDR to obtain a JFAC \nevaluation of the assurance risk analysis and risk plan so the  appropriate information is  \nincorporated into the PPP.  \n4 Summary  \nIn practice, each program must identify and implement the LoA required to resolve \nspecific risks to that pr ogram. Achieving these LoAs will depend on both the CMC \nplatforms assurance (both the hardware and software tools) and the actions of the \napplication developers using the platform. This includes all steps of implementation of \nthe system using the CMC.  \nConducted properly, this LoA framework  can minimize the impact of hardware \nassurance CMC threats . Additionally, it equips  the program with the understanding \nnecessary to implement a response in the case of a compromise. JFAC is available to \nguide programs through this process. Additional information for JFAC may be found at \nhttps://jfac.navy.mil . \n  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  20 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nAppendix  A: JFAC FPGA Documents Overview  \nThis appendix describes the JFAC FPGA set of documents as well as a brief content \ndescription.  \n1. Levels of Assurance Definitions and Applications   This document describes  the \nthree levels of assurance. It also provides instructions on how to select the LoA for a \ngiven system or mission.  \n2. Threat Catalog   This document details and defin es the hardware assurance \nthreats within the FPGA space. It identifies which threats are of concern at a given \nLoA. It provides context  to understand the reason for the proposed mitigations in the \nsubsequent documents. Reviewing this document is not requir ed to  implement the \nJFAC FPGA hardware assurance best practices, but it may provide context that \nexplains the rationale behind certain decisions.  \n3. Level of Assurance 1 Best Practices  This series of documents provides a set of \nmitigations that must be applied to reach LoA1 in the JFAC FPGA assurance flow. \nFor each threat of interest at LoA1, it provides one or more proposed mitigations. \nSome mitigations are sufficiently straightforwar d and stable to be described within \nthe document itself. Other mitigations are more detailed and are described in \nadditional documents, as listed below:  \n Standards of Counterfeit Screening for LoA1  \n Design Flow Assurance for LoA1   \n Platform Design Review for LoA1   \n Cryptographic IDs for Counterfeit Discovery for LoA1  \n Third Party IP Review for LoA1  \n Built-In Configuration Authentication for LoA1  \n4. Level of Assurance 2 Best Practices   This series of documents provide s a set of \nmitigations that must be applied to  reach LoA2 in the JFAC FPGA assurance flow .  \nThe series includes the following set of documents:  \n Standards of Counterfeit Screening for LoA2  \n Approved Second Order Effects Screening Methods for LoA2  \n Post Assembly Analysis for LoA2  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  21 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \n Third Party IP Review for LoA2  \n Platform Design Review for LoA2  \n5. Level of Assurance 3 Best Practices  This series of documents provide s a set of \nmitigations that must be applied to reach LoA3 in the JFAC FPGA assurance flow.  \n  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  22 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nAppendix B : Standardized T erminology  \nThe following terms are used in the Joint Federated Assurance Center Field \nProgrammable Gate Array Best Practices documents. These terms are  modified from \nDefense Acquisition University definitions to support common understanding.  \nApplication design   The collection of schematics, constraints, hardware description \nlanguage (HDL) , and other implementation files developed to generate an FPGA \nconfiguration file for use on one or many FPGA platforms.  \nApplication domain   This is the area of technolo gy of the system itself, or a directly \nassociated area of technology. For instance, the system technology domain of a radar \nsystem implemented using FPGAs would be \"radar\" or \"electronic warfare.\"  \nConfiguration file  The set of all data produced by the ap plication design team and \nloaded into an FPGA to personalize it. Referred to by some designers as a bitstream, \nthe configuration file includes that information, as well as additional configuration \nsettings and firmware, which some designers may not consi der part of their bitstream.  \nControllable effect   Program -specific , triggerable function allowing the adversary to \nattack a specific target.  \nDevice/FPGA device   A specific physical instantiation of an FPGA.  \nExternal facility   An unclassified facility that is out of the control of the program or \ncontractor.  \nField  programmable gate array (FPGA)   In this context  FPGA includes the full range \nof devices containing substantial reprogrammable digital logic. This includes devices \nmarketed as FPGAs, complex pr ogrammable logic device s (CPLD), system -on-a-chip \n(SoC) FPGAs, as well as devices marketed as SoCs and containing reprogrammable \ndigital logic capable of representing arbitrary functions. In addition, some FPGAs \nincorporate analog/mixed signal elements alo ngside substantial amounts of \nreprogrammable logic.  \nFPGA platform   An FPGA platform refers to a specific device type or family of devices \nfrom a vendor.  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  23 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nHard IP   Hard IP is a hardware design captured as a physical layout, intended to be \nintegrated into a hardware design in the layout process. Hard IP is most typically \ndistributed as Graphic Design System II (GDSII). In some cases, Hard IP is provided by \na fabrication company and the user of the IP does not have access to the full layout, but \nsimply a siz e and the information needed to connect to it. Hard IP may be distributed \nwith simulation hardware description language (HDL) and other soft components, but is \ndefined by the fact that the portion that ends up in the final hardware was defined by a \nphysica l layout by the IP vendor.  \nLevel of assurance (LoA)   A Level of Assurance is an established guideline that \ndetails the appropriate mitigations necessary for the implementation given the impact to \nnational security associated with subversion of a specific system, without the need for \nsystem -by-system custom evaluation.  \nPhysical unclonable function (PUF)   This function provides a random string of bits of \na predetermined length . In the context of FPGAs, the randomness of the bitstring is \nbased upon  variations in the silicon of the device due to manufacturing. These bitstrings \ncan be used for device IDs or keys.   \nPlatform design   The platform design is the set of design information that specifies \nthe FPGA platform, including physical layouts, co de, etc.  \nSoft IP   Soft IP is a hardware design captured in hardware description language \n(HDL), intended to be integrated into a complete hardware design through a synthesis \nprocess. Soft IP can be distributed in a number of ways, as functional HDL or a n etlist \nspecified in HDL, encrypted or unencrypted.  \nSystem   An aggregation of system elements and enabling system elements to achieve \na given purpose or provide a needed capability.  \nSystem design  System design is the set of information that defines the \nmanufacturing, behavior, and programming of a system. It may include board designs, \nfirmware, software, FPGA configuration files, etc.  \nTarget  A target refers to a specific deployed instance of a given system, or a specific \nset of systems with a common des ign and function.  \n\n \n \nU/OO/ 173659 -22 | PP-22-1079 | JUL 2022 Ver. 1.0  24 \nNational Security Agency | Cybersecurity Technical Report  \nDoD Microelectronics: Levels of Assurance Definitions and Applications  \nTargetability  The degree to which an attack may have an effect that only shows up in \ncircumstances the adversary chooses. An attack that is poorly targetable would be more \nlikely to be discovered accidentally, have unintended consequenc es, or be found in \nstandard testing.  \nThird -party intellectual property  (3PIP)   3PIP is a functional unit designed by a \ndifferent organization than the principal design team. Typically, 3PIP is a pre -existing \ndesign, offered for sale by a commercial organi zation.  \nThreat category  A threat category refers to a part of the supply chain with a specific \nattack surface and set of common vulnerabilities against which many specific attacks \nmay be possible.  \nUtility  The utility of an attack is the degree to which an effect has value to an \nadversarial operation. Higher utility effects may subvert a system or provide major \ndenial of service effects. Lower utility attacks might degrade a capability to a limited \nextent.   \nVulnerability  A flaw in a software, firmware, hardware, or service component \nresulting from a weakness that can be exploited, causing a negative impact to the \nconfidentiality, integrity, or availability of an impacted component or components. \n(MITRE, https://cve.mitre.org/about/terminology.html ) \n\n",
  "cves": [],
  "techniques": [],
  "advisory": "cybersecurity-alerts",
  "title": "ctr_dod_microelectronics_levels_of_assurance_definitions_and_applications_20220714",
  "source": "nsa",
  "id": "88c2049756db90884735b7b0c468181521091ae8edec8d9b43e5874c10d36797"
}