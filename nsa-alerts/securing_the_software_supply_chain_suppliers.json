{
  "markdown": "\u0016\u0018\u0013\u0013\u000f\f\b\u0015\u0016\u0016\b\u0006\u0018\u0015\f\u0011\n\u0003\u0017\u000b\b\u0003\n\u0016\u0012\t\u0017\u001a\u0004\u0015\b\u0003\u0016\u0018\u0013\u0013\u000f\u001c\u0003\u0006\u000b\u0004\f\u0011\n\u0015 \b \u0006 \u0012 \u0010 \u0010 \b \u0011 \u0007 \b \u0007 \u0003 \u0013 \u0015 \u0004 \u0006 \u0017 \f \u0006 \b \u0016 \u0003 \n \u0018 \f \u0007 \b \u0003 \t \u0012 \u0015 \nEnduring Security Framework \nSeptember 2022 \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers ii \n \n \n\b  \u0016  \nCyberattacks are conducted via cyberspace and targe ts an enterprises use of cyberspace for the \npurpose of disrupting, disabling, destroying, or ma liciously controlling a computing environment or \ninfrastructure; or destroying the integrity of the data or stealing controlled information.1 \nRecent cyberattacks such as those executed against SolarWinds and its customers, and exploits that \ntake advantage of vulnerabilities such as the Log4j , highlight weaknesses within software supply \nchains, an issue which spans both commercial and op en source software and impacts both private \nand Government enterprises. Accordingly, there is a n increased need for software supply chain \nsecurity awareness and cognizance regarding the pot ential for software supply chains to be \nweaponized by nation state adversaries using simila r tactics, techniques, and procedures (TTPs).  \nIn response, the White House released an Executive Order on Improving the Nations Cybersecurity \n(EO 14028). EO 14028 establishes new requirements t o secure the federal governments software \nsupply chain. These requirements involve systematic  reviews, process improvements, and security \nstandards for both software suppliers and developer s, in addition to customers who acquire \nsoftware for the Federal Government. \nSimilarly, the Enduring Security Framework2 (ESF) Software Supply Chain Working Panel has \nestablished this guidance to serve as a compendium of suggested practices for developers, \nsuppliers, and customer stakeholders to help ensure  a more secure software supply chain. This \nguidance is organized into a three part series: Par t 1 of the series focuses on software developers; \nPart 2 focuses on software suppliers; and Part 3 fo cuses on software customers. \nCustomers (acquiring organizations) may use this gu idance as a basis of describing, assessing, and \nmeasuring security practices relative to the softwa re lifecycle. Additionally, suggested practices \nlisted herein may be applied across the acquisition , deployment, and operational phases of a \nsoftware supply chain.  \nThe software supplier (vendor) is responsible for li aising between the customer and software \ndeveloper. Accordingly, vendor responsibilities inc lude ensuring the integrity and security of \nsoftware via contractual agreements, software relea ses and updates, notifications, and mitigations \nof vulnerabilities. This guidance contains recommen ded best practices and standards to aid \nsuppliers in these tasks.  \nThis document will provide guidance in line with in dustry best practices and principles which \nsoftware developers are strongly encouraged to refe rence. These principles include security \nrequirements planning, designing software architect ure from a security perspective, adding \nsecurity features and maintaining the security of s oftware and the underlying infrastructure (e.g., \nenvironments, source code review, testing). \n \n \n1 Committee on National Security Systems (CNSS)  \n2 The ESF is a cross-sector working group that opera tes under the auspices of Critical Infrastructure P artnership \nAdvisory Council (CIPAC) to address threats and ris ks to the security and stability of U.S. national se curity systems. \nIt is comprised of experts from the U.S. government  as well as representatives from the Information Te chnology, \nCommunications, and the Defense Industrial Base sec tors. The ESF is charged with bringing together \nrepresentatives from private and public sectors to work on intelligence-driven, shared cybersecurity c hallenges. \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers iii \n \n \n\u0007\f\u0016\u0006\u000f\u0004\f\u0010\b\u0015  \n\u0007\f\u0016\u0006\u000f\u0004\f\u0010\b\u0015  \u0012\t \b\u0011\u0007\u0012\u0015\u0016\b\u0010\b\u0011\u0017  \nThis document was written for general informational  purposes only. It is intended to apply to a \nvariety of factual circumstances and industry stake holder, and the information provided herein is \nadvisory in nature. The guidance in this document i s provided as is. Once published, the \ninformation within may not constitute the most up-t o-date guidance or technical information. \nAccordingly, the document does not, and is not inte nded to, constitute compliance or legal advice. \nReaders should confer with their respective advisor s and subject matter experts to obtain advice \nbased on their individual circumstances. In no even t shall the United States Government be liable \nfor any damages arising in any way out of the use o f or reliance on this guidance. \nReference herein to any specific commercial product , process, or service by trade name, trademark, \nmanufacturer, or otherwise, does not constitute or imply its endorsement, recommendation, or \nfavoring by the United States Government, and this guidance shall not be used for advertising or \nproduct endorsement purposes. All trademarks are th e property of their respective owners.  \n\u0013\u0018\u0015\u0013\u0012\u0016\b  \nNSA, ODNI, and CISA developed this document in furt herance of their respective cybersecurity \nmissions, including their responsibilities to devel op and issue cybersecurity recommendations and \nmitigations. This information may be shared broadly  to reach all appropriate stakeholders.  \n\u0006\u0012\u0011\u0017\u0004\u0006\u0017  \n\u0006  \u0015   \f : Enduring Security Framework nsaesf@cyber.nsa.gov ,  \n\u0010  \f   \u0013  \u0007  \nx NSA Media Relations, 443-634-0721, MediaRelations@nsa.gov  \nx CISA Media Relations, 703-235-2010, CISAMedia@cisa.dhs.gov  \nx ODNI Media Relations, dni-media@dni.gov  \n  \n\n\n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 1 \n \n \n \f  \nUnmitigated vulnerabilities in the software supply chain pose a significant risk to organizations. \nThis series presents actionable recommendations for  a software supply chains development, \nproduction and distribution, and management process es to increase the resiliency of these \nprocesses against compromise.  \nAll organizations have a responsibility to establis h software supply chain security practices to \nmitigate risks, but the organizations role in the software supply chain lifecycle determines the \nshape and scope of this responsibility.  \nBecause the considerations for securing the softwar e supply chain vary based on the role an \norganization plays in the software supply chain, th is series presents recommendations geared \ntoward these important roles, namely, developers, s uppliers, and customers (or the organization \nacquiring a software product). \nThis guidance is organized into a three part series  and will be released coinciding with the software \nsupply chain lifecycle. This is Part 2 of the serie s which focuses on the software supplier. Part 1 of \nthe series focused on software developers and Part 3 of the series will focus on the software \ncustomer. This series will help foster communicatio n between these three different roles and \namong cybersecurity professionals that may facilita te increased resiliency and security in the \nsoftware supply chain process.  \nIn this series, terms such as risk, threat, exploit , and vulnerability are based on descriptions defin ed \nin the Committee on National Security Systems Gloss ary (CNSSI 4009).3  \n1.1 \u0005  \nHistorically, software supply chain compromises lar gely targeted commonly known vulnerabilities \norganizations that were left unpatched. While threat  actors still use this tactic to compromise \nunpatched systems, a new, less conspicuous method o f compromise also threatens software supply \nchains and undermines trust in the patching systems  themselves that are critical to guarding \nagainst legacy attacks. Rather than waiting for pub lic vulnerability disclosures, threat actors \nproactively inject malicious code into products tha t are then legitimately distributed downstream \nthrough the global software supply chain. Over the last few years, these next-gen software supply \nchain compromises have significantly increased for both open source and commercial software \nproducts.  \nTechnology consumers generally manage software down loads and broader, more traditional \nsoftware supply chain activities separately. Consid ering both the upstream and downstream phases \nof software as a component of supply chain risk man agement may help to identify problems and \nprovide a better way forward in terms of integratin g activities to achieve systemic security. \nHowever, there are also some differences to account  for in the case of software products. A \ntraditional software supply chain cycle is from poi nt of origin to point of consumption and generally \nenables a customer to return a malfunctioning produ ct and confine any impact. In contrast, if a \n \n3 CNSSI-4009.pdf \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 2 \n \n \nsoftware package is injected with malicious code wh ich proliferates to multiple consumers; the \nscale may be more difficult to confine and may caus e an exponentially greater impact. \nCommon methods of compromise used against software supply chains include exploitation of \nsoftware design flaws, incorporation of vulnerable third-party components into a software product, \ninfiltration of the suppliers network with malicio us code prior to the final software product being \ndelivered, and injection of malicious software that  is then deployed by the customer. \nStakeholders must seek to mitigate security concern s specific to their area of responsibility. \nHowever, other concerns may require a mitigation ap proach that dictates a dependency on another \nstakeholder or a shared responsibility by multiple stakeholders. Dependencies that are \ninadequately communicated or addressed may lead to vulnerabilities and the potential for \ncompromise. \nAreas where these types of vulnerabilities may exis t include:  \nx Undocumented features or high risk functionality, \nx Unknown and/or revisions to contractual, functional ity or security assumptions between \nevaluation and deployment, \nx Suppliers change of ownership and/or of geo-locati on, and \nx Poor supplier enterprise or development hygiene. \n \u0007  o  \nThis document contains the following additional sec tions and appendices:  \n\u0016   provides best practices and standards recommended for suppliers to help ensure the \nintegrity and security of software from production through delivery.  \n\u0016   is a collection of appendices supplementing the pr eceding sections: \n\u0004  \u0004: Crosswalk Between the NIST SP800-218; Mitigating the Risk of Software \nVulnerabilities by Adopting a Secure Software Devel opment Framework  (SSDF) 4 and Use Cases \ndescribed herein. \n\u0004  \u0005: Dependencies  \n\u0004  \u0006: Supply-Chain Levels for Software Artifacts (SLSA)5 \n\u0004  \u0007: Recommended Artifacts and Checklist \n\u0004  \b: Informative References \n\u0004  \t: Acronyms. \n  \n \n4 NIST SP 800-218, Secure Software Development Framew ork (SSDF) Version 1.1: Recommendations for Mitigat ing \nthe Risk of Software Vulnerabilities  \n5 GitHub - slsa-framework/slsa: Supply-chain Levels f or Software Artifacts  \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 3 \n \n \nEach section contains examples of threat scenarios and recommended mitigations. Threat scenarios \nexplain how processes that compose a given phase of  the software development lifecycle (SDLC) \nrelate to common vulnerabilities that could be expl oited. The recommended mitigations present \ncontrols and mitigations that could reduce the impa ct of the threats. \n  \n\n\n\n\n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 6 \n \n \nx Ensure the code repository, build, and test environ ments have at least the same security \nprotections as other critical network capabilities such as network segmentation, firewalling, \nmonitoring, automated encryption, and remote backup s, \nx Ensure only corporate-issued or approved developmen t systems can access the \ndevelopment, build, and test environments using mul ti-factor authentication (MFA) or \ncontinuous authentication based on behavior analyti cs7 and only through office networks \nwith physical security or through secure virtual pr ivate networks (VPNs). Ensure that failed \naccess attempts are detected, reported, and investi gated. This is particularly important for \nmobile or remotely working employees, \nx Conduct reviews of third-party software (e.g., usin g binary software composition analysis) \nand assure the security of those included modules, \nx Deliver digitally signed code and associated suppor ting files using a code-signing system \nthat protects sensitive signing keys and that uses hardware protection such as a Federal \nInformation Processing Standards (FIPS) 140-2/-3 Har dware Security Module (HSM). This \nrequires at least two individuals to activate the s igning keys and approve the software \nrelease package (i.e., code, supporting files, and metadata), \nx Establish a strong security culture in the developm ent and operations support teams,  \nx Review personnel, tasks, systems, and policies to e nsure they continue to be appropriate, \nnecessary, and complete. Conduct reviews both on a schedule and as triggered by events. \nThreat scenarios: SaaS  \nThe following are examples of cloud-native software  development scenarios that could be exploited \nsuch as: \nx Software development process that promises faster t ime to market, better scalability and \nmanagement, and lower costs, all while maintaining the same levels of development \nsecurity and integrity, \nx Adoption of a new approach which requires changes t o on-premises development and \ndistribution processes as well as security and secu rity management regimes, \nx Key changes that include adoption of containerizati on and micro services architectures. \nRecommended mitigations  \nThe following mitigations can help reduce threats a nd risks associated with the development \nprocess: \nx Use of strong authentication, authorization, code s cans, vulnerability analyses, and digital \nsigning of applications, \nx These practices should be broadened, as needed, to address any additional authentication \nchallenges associated with endpoint and operational  cloud security. \n \n7 Zero Trust Architecture (nist.gov)  \n\n\n\n\n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 9 \n \n \n4. The media used to store archives is determined by t he organization, and the decision \nusually hinges on its convenience, reliability, and  availability. Organizations have \ntraditionally used network storage and other media such as tape devices: \na) Tape media is standard for some organizations that need a low-cost way to store \nlarge amounts of data in a small space. However, re trieval and restore for this media \ncan become a problem, \nb) Attached network drives are also common, but this m edia is much more expensive. \nNetwork storage requires the real estate to host it  and expensive hardware to \nsecure and maintain it. However, unlike most tape s ystems, network drives offer \narchive data that is readily available should the o rganization or investigators need \nto access it, \nc) Cloud storage has the advantages of availability an d low costs, but the speed is \ndependent on the organizations bandwidth and netwo rk speed. Many organizations \nhave moved to cloud storage for its convenience and  savings. However, it is still the \nresponsibility of the organization to keep the data  secure, \nd) Based on the organization, other storage types are listed below: \nx Block storage services, which expose software-defin ed block devices that \ncan be presented to virtual hosts running in the cl oud, \nx Object storage services, which can be mapped to hos ts, applications, or even \nother cloud services, and allow addressing discrete , unstructured data \nelements by ID or metadata, \nx Scalable shared file systems, which allows a scalab le set of hosts to access \nthe same file system at a high speed, \n5. The process of archiving data is often automated us ing software. The features and \ncapabilities offered by archiving software depend o n the supplier, but most have standard \nfeatures across every platform:  \na) A system administrator configures the time, locatio n, and frequency for software to \nbe archived. An archiving policy is created to dete rmine the rules behind moving \ndata. Using archive policies, an administrator ensu res that data moved to the \nstorage location follows the proper regulatory stan dards and requirements, \nb) In conjunction with other rules about archiving, a retention policy is also necessary. \nA retention policy determines the amount of time an  archive stays available before \nthe data can be overwritten or destroyed. A typical  retention policy for backups is \nabout 30 days, but archived data might be retained longer before it is destroyed. \nSome organizations keep archived data for years bef ore media is rotated or archives \nare deleted. For the most sensitive data, archives may never be overwritten or \ndestroyed. Archiving and compliance standards may h ave a retention policy \nrequirement, so organizations should ensure that th eir configuration does not \nviolate any regulatory standards. \n\n\n\n\n\n\n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 13 \n \n \nx An adversary with access to software processes and tools within the production build \nenvironment may insert malicious software into comp onents, \nx Inadequately configuring the compilation and build process may compromise the \nexecutables security, \nx Improperly safeguarding the integrity of the produc tion build process and the binary \nartifacts which it generates. \nRecommended mitigations \nThe processes that are used to compile and build so ftware components must be properly \nconfigured to be secure by default in order to insu re the integrity of all binary production code \nartifacts. The following controls should be impleme nted to harden software compilation and build \nprocesses: \n1. Organizations should establish and maintain a trust ed toolchain for all tools involved in the \ncompilation and building of software; these tools s hould be configured to a known secure \nbaseline state, recorded, and tracked via an invento ry maintained in a Configuration \nManagement Database, continuously monitored for eme rgent security vulnerabilities, and \nreceive appropriate security updates in accordance with defined remediation timelines. \n2. All build processes should be automated and the res ulting scripts and metadata should be \nstored securely in a version control system with ac cess limited to the individuals \nresponsible for building the components. \n3. Non-interactive service accounts should be used to invoke automated build processes to \nensure build outputs are service-generated and non- falsifiable. \n4. The authentication credentials of service accounts which execute automated compilation \nand packaging processes should be verified using an  approved method to validate the \nprocesses as trusted. \n5. Automated build processes should execute in an ephe meral environment which is logically \nisolated and free from external influence. \n6. Automated build processes should generate and maint ain a build manifest identifying \nbuilder, sources, entry point, and parameters to en sure build reproducibility. \n7. Secure compiler settings should be enabled to help prevent or limit the effectiveness of \nsome types of security issues, most notably buffer overflows (both stack and heap-based). \nExamples of secure compiler settings may include, b ut are not limited to, the following:  \na) Enable stripping of symbols from binary output, \nb) Enable data execution prevention, \nc) Enable safe structured exception handling, \nd) Runtime checks for security, \ne) Enable address space layout randomization, \nf) Emit an error if an array index can be determined a t compile time to be out of \nbounds, \ng) Emit a warning upon the detection of a suspicious u se of an address pointer. \n\n\n\n\n\n\n\n\n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 18 \n \n \n1. Create a vulnerability assessment team consisting o f architects, developers, testers, \ncryptologists, and human factor engineers whose goa l is to identify exploitable weaknesses \nin software. \n2. For the software capability define a process that u ses known environment analysis, monitor \nvulnerabilities associated with the software capabi lity, and unknown environment fuzz \ntesting of individual units within the combined sys tem. \n3. For the software components define a process that u ses known environment analysis, uses \nsource or binary composition analysis tools to moni tor vulnerabilities associated with the \nidentified software components, and unknown environ ment fuzz testing of individual units \nwithin the combined system. \n4. Invest in static and dynamic evaluation tools that are state of the art. Keep them current and \nimplement them according to supplier documentation.  \n5. Create a central company-wide Product Security Inci dent Response (PSIRT) team. Public-\nfacing PSIRT information (e.g., on a web page) shou ld be easily accessible for external \nresearchers to report vulnerabilities in the organi zations products. The PSIRT team should \nwork with external researchers to acknowledge and g ather information on any reported \nvulnerabilities, as well as to ensure that any repo rted vulnerability is fixed. Organizations \nshould practice responsible disclosure on all vulne rabilities. \n6. All known security issues and/or vulnerabilities sh ould be tracked as product defects in the \norganizations defect tracking tool. Items tracked should include CVSS scores, specific \nimpacts on the component, and any other relevant su pporting data. Vulnerability \ninformation should only be stored in access-control led pages in a bug tracking system and \nbased on the potential sensitivity. \n7. Provide sufficient human and compute resources, sof tware testing, and time to test based \non the multiple factors and complexity that could c onstitute a software component or \npackage. Factors may include load, branches, race c onditions, corner cases, etc.. \n8. Review and either eliminate or document any weaknes ses found. \n9. Refer to the SBOM (or a similar mechanism) related to third-party software and open-\nsource components associated with the software. Est ablish and follow corporate guidance \non the upgrade of embedded components as issues are  announced. \n10. When a software component is modified, repeat the r ecommended process herein for that \nunit and the system. \nThreat scenarios: SaaS \nThe following are example scenarios that could be e xploited:  \nx The deployment and implementation of SaaS applicati ons at the expense of security, \nx Organizations which have been provided with the cap ability to enhance, improve, and \noptimize their overall workflow, \nx Speedy and fast adoption and acquisition of SaaS to ols and products (especially to satisfy \nrapid post-COVID work from home requirements) may h ave inherent risk(s) and may \nultimately impact the overall security posture of a n organization. \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 19 \n \n \nRecommended mitigations: SaaS \nThe following are example mitigations to threats: \n1. Implement a stringent security policy towards SaaS application security. \n2. Design a mechanism to monitor and scan third-party applications which are directly \nconnected to the cloud environment. \n3. Develop a comprehensive and reliable backup solutio n. \n4. Implement identity and access control mechanisms. \n5. Develop mature security assessments (this may possi bly include utilizing Cloud Access \nSecurity Brokerage capabilities) so that any securi ty gaps between the cloud service \ncustomer and cloud service provider may be bridged.  \n6. Implement industry standard encryption algorithms. \n  \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 20 \n \n \n \u0004  \n \u0004  \u0004 \u0006 k \u0005  \u0016    \u0016\u0016\u0007\t  \nThe section reference numbers in the below crosswal k may look similar for each role (Developer, \nSupplier and Customer) however they are from the re spective parts of the Series. (PO  Prepare \nOrganization; PW - Produce Well-Secured Software; P S  Protect Software; and RV  Respond to \nVulnerabilities) \n\u0016\u0016\u0007\t   \u0007   \u0016  \u0006  \n\u0013\u0012  2.2.3 Secure Development \nPractices 2.1.1 Define criteria for \nsoftware security checks  \n\u0013\u0016  2.2.1.1 Source Control \nCheck-in Process \n2.2.1.4 Code Reviews \n2.2.6 External \nDevelopment Extensions \n2.3.2 Selections and \nIntegration \n24.1 Build Chain Exploits \n2.5.3 Secure the \nDistribution System 2.2.1 Protect all forms of \ncode from unauthorized \naccess  \n \n2.2.2 Provide a mechanism \nfor verifying software \nrelease integrity (PS.1, \nPW.9)  \n\u0013\u0016  2.2.1.1 Source Control \nCheck-in Process \n2.2.1.2 Automatic and \nManual Dynamic and Static \nSecurity / Vulnerability \nScanning \n2.3.2 Selections and \nIntegration \n2.3.3 Obtain Components \nfrom a Known and Trusted \nSupplier \n2.4.1 Build Chain Exploits 2.2.3 Archive and protect \neach software release  \n\u0013\u001a  2.3.2 Selections and \nIntegration 2.3.1 Design software to \nmeet security requirements   \n\u0013\u001a  2.2.3 Secure Development \nPractices \n2.3.2 Selections and \nIntegration 2.3.2 Verify third-party \nsoftware complies with \nsecurity requirements 2.1 Procurement/Acquisition \n(1) Requirements Definition / \nRecommended Controls \n(viii)(viii) \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 21 \n \n \n2.3.3 Obtain Components \nfrom a Known and Trusted \nSupplier \n2.3.4 Component \nMaintenance \n2.3.5 Software Bill of \nMaterial (SBOM) 2.2 Deployment (6) \n(2) Testing  Functionality (c) \nRecommended Controls (ii) \nVerify contents in SBOM \n2.2 Deployment (6)  \nDeploy (3) Contracting / \nRecommended Controls (v) \n(viii) (ix)(x) \n\u0013\u001a  2.2.3.2 Use of Unsecure \nDevelopment Build \nConfigurations \n2.4.1 Build Chain Exploits 2.3.3 Configure the \ncompilation and build \nprocesses   \n\u0013\u001a  2.2.1.4 Code Reviews \n2.2 Open source \nManagement Practices \n2.2.6 External \nDevelopment Extensions \n23.2 Selections and \nIntegration \n2.3.3 Obtain Components \nfrom a Known and Trusted \nSupplier 2.3.4 Review and/or analyze \nhuman-readable code   \n\u0013\u001a  2.2.1.3 Nightly Builds with \nRegression Test \nAutomation \n2.3.2 Selections and \nIntegration \n2.4.1 Build Chain Exploits 2.3.5 Test executable code   \n\u0013\u001a  2.2.3.2 Use of Unsecure \nDevelopment Build \nConfigurations \n2.4.1 Build Chain Exploits 2.2.2 Provide a mechanism \nfor verifying software \nrelease integrity (PS.1, \nPW.9) \n2.3.6 Configure the software \nto have secure settings by \ndefault   \n\u0015\u0019  2.3.4 Component \nMaintenance \n2.4.1 Build Chain Exploits 2.4.1 Identify, analyze, and \nremediate vulnerabilities on \na continuous basis  \n  \n\n\n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 23 \n \n \n \u0004  \u0006 \u0016\u0006  \u000f  r \u0016 re \u0004  \u0016\u000f\u0016\u0004  \n\u0016\u0006  \u000f  r \u0016  \u0004  (SLSA) is a security framework from source to serv ice, \ngiving anyone working with software a common langua ge for increasing levels of software security. \nThe framework is currently in Alpha stage and const antly being improved by supplier-neutral \ncommunity. Google has been using an internal versio n of SLSA since 2013 and requires it for all their \nproduction workloads. http://slsa.dev  \n\u0015  \u0007  \u000f \u000f \u000f \u000f \n\u0016 d   All build steps were fully defined in some sort of build \nscript. The only manual command, if any, was to in voke \nthe build script. \nExamples: \nx Build script is Makefile, invoked via make all. \nx Build script is. github / workflows / build.yaml, \ninvoked by GitHub Actions.     \n d   All build steps ran using a build service, not on a  \ndevelopers workstation. \nExamples: GitHub Actions, Google Cloud Build, Travi s CI.  \n   \n  \n  The build service ensured that the build steps ran in an \nephemeral environment, such as a container or virtu al \nmachine (VM), provisioned solely for this build, an d not \nreused from a prior build.   \n  \n  The build service ensured that the build steps ran in an \nisolated environment free of influence from other b uild \ninstances, whether prior or concurrent. \nx It MUST NOT be possible for a build to access any \nsecrets of the build service, such as the \nprovenance signing key. \nx It MUST NOT be possible for two builds that \noverlap in time to influence one another. \nx It MUST NOT be possible for one build to persist or \ninfluence the build environment of a subsequent \nbuild. \nx Build caches, if used, MUST be purely content-\naddressable to prevent tampering.   \n  \n  The build output cannot be affected by user paramet ers \nother than the build entry point and the top-level \nsource location. In other words, the build is fully  \ndefined through the build script and nothing else. \nExamples: \nx GitHub Actions workflow dispatch  inputs MUST be \nempty.    \n \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 24 \n \n \nx Google Cloud Build user-defined substitutions  \nMUST be empty. (Default substitutions, whose \nvalues are defined by the server, are acceptable.) \n\u000b  All transitive build steps, sources, and dependenci es \nwere fully declared up front with immutable references , \nand the build steps ran with no network access. \nThe developer-defined build script: \nx MUST declare all dependencies, including sources \nand other build steps, using immutable references  \nin a format that the build service understands. \nThe build service: \nx MUST fetch all artifacts in a trusted control plane.  \nx MUST NOT allow mutable references. \nx MUST verify the integrity of each artifact. \no If the immutable reference  includes a \ncryptographic hash, the service MUST verify \nthe hash and reject the fetch if the verification \nfails. \no Otherwise, the service MUST fetch the artifact \nover a channel that ensures transport \nintegrity, such as TLS or code signing. \nx MUST prevent network access while running the \nbuild steps. \no This requirement is best effort. It SHOULD \ndeter a reasonable team from having a non-\nhermetic build, but it need not stop a \ndetermined adversary. For example, using a \ncontainer to prevent network access is \nsufficient.    \n \n  Re-running the build steps with identical input art ifacts \nresults in bit-for-bit identical output. Builds tha t cannot \nmeet this MUST provide a justification why the buil d \ncannot be made reproducible. \n\u0003\u0003\u0003\u0003\u0003\u0003\u0003 fort. The \ndeveloper-provided build script SHOULD declare \nwhether the build is intended to be reproducible or  a \njustification why not. The build service MAY blindl y \npropagate this intent without verifying reproducibi lity. \nA customer MAY reject the build if it does not \nreproduce.    \n \n  \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 25 \n \n \n \u0004  \u0007 \u0004  d \u0006  \nIn principle, any artifacts created during the life cycle of the software development process are owned  \nby and private to a developing organization. These organizations can determine what artifacts are \nmade available with potential and current users of a product with or without a Non-Disclosure \nAgreement (NDA). Availability of information must t ake into consideration regulatory and legal \nrequirements, the customer requirements for the inf ormation and the risk involved by exposing \ninformation leading to the exploitation of the prod uct. Exceptions may include open-source \ndevelopment organizations, which are more inclined to make all development information available, \nto include source code. \nWhen defining the availability of an artifact, the general terms used in this section will be the \nfollowing: \n1. Publicly disclosed \n2. Externally available \na) under a Non-Disclosure Agreement (NDA) \nb) government agency mandated requirement \n3. Private / company confidential \nThe availability of an artifact varies between comp anies and agencies and is only described here as a \nreference for what might be possible when using art ifacts to validate the software supply chain \nprocess. Some artifacts, such as a high-level archi tecture document may be intentionally generated \nto allow any perspective consumers an introductory artifact detailing the overall strategies used in \nthe design, development, and operation of a product . These publicly disclosed documents may \ndescribe common industry nomenclature, such as Fede ral Information Process Standards (FIPS) \ncompliance, cryptography standards used, developmen t processes adhered to or certifications \nprocesses passed. NDA and government mandated avail ability require contractual agreements \nproviding access to artifacts that would not normal ly be exposed by the organization that produced \nthe product. While private/company confidential art ifacts are generally low-level and detailed work \nproducts that may contain sensitive secrets and kno whow and if exposed, provide potential insight \ninto products competitive implementation and threa t vectors that may not be addressed in the \nproduct, therefor posing a threat if exposed outsid e of the producers environment. Private/company \nconfidential artifacts are generally maintained by the Suppliers and Developers of the product to \nfacilitate the auditing and validation of adherence  to the Secure Software Development Lifecycle \n(Secure SDLC) and Security practices set forth by t he product owner, company, or organization. For \nmore information on the Secure SDLC process, refer to Section  \u0016  \u0013  \u0006  d \n\u0010  subsection Recommended Mitigations, Item 8 of th e Part 1 Developer of the series.  \nMost of the artifacts collected during the developme nt lifecycle are not meant to be shared outside the  \ndeveloping organization yet may be preserved in per sistent storage as evidence to verify the integrity  \nof the policies and processes used during the devel opment of a product. A developer should securely \nretain artifacts of software development for a cert ain duration according to its secure software \ndevelopment policies and processes. As a by-product  of the process used to implement and mitigate \nthe attack surface and threat model of the software  as well as the software build pipeline during the \ndevelopment process, the following artifacts may be  created, and collected:   \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 26 \n \n \n\u0004  \b  \u0007\u0013  \n\u000b  \u0016 e \n\u0007  \n\u000f  \u0013  \n  Attestation to secure development practices which c an cover: \nx Secure software architecture/design process \nx Attack surface investigation and threat modeling pr ocess \nx Secure software development/programming training  \nx Software security testing process \nx Source control check-in process \nx Trusted repository for modules and processes \nx Continuous integration and delivery (CI/CD) process es \nx Defect/vulnerability reporting and customer update process \nx Code reviews process for security and continuous so ftware \nsecurity improvement  \nx Continuous verification of third-party binaries \nx Open-source management practices \nx Hardening the build environment \nx Secure relationship with a third-party supplier \nx Process to secure the signing server \nx Final package validation process \n\u0013  \u0015  \n  Attestation to product release and secure shipping criteria and product \nreadiness for shipment which can cover: \nx No pending known critical bugs and vulnerabilities (e.g. bug track \nreport) \nx Cryptographically signed components  \nx Proper software licensing \n\u0013  \n\u0016\u0015  \n\u0013  Attestation to vulnerability discloser and response  process (e.g. handling \nof policy violation and anomalies) \n\u0016  \u0005ll  \n\u0010  (\u0016\u0005\u0012\u0010  x Attestation to the integrity of the producer \nx Attestation to the security and authenticity of com ponents \nincluded in the product \nx Attestation to the third-party software components \nx Attestation to the integrity of software licenses \n\u0004\u0007  \n\u0007  x Attestation to secure architecture/design practices  \nx Mitigation of attack surface vulnerabilities \nx Attestation to mapping between secure requirements to software \narchitecture and components \n\u0007  \u0017 g \n\u0006\u0017 g \n  \n\u0016  x Attestation to secure development practices \nx Attestation to secure coding practices \n\u0017  \u0010  \u0015  \n\u0007   x Attestation to secure design practices \nx Attestation to secure third-party component integra tion practices \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 27 \n \n \n\u000b l \u0016  \n\u0016 y \u0017  \u0013    \n\u0015  High-level, system and unit level test plan and res ults (A set of tests should \nbe commensurate with the requirements and risk prof ile of the product or \nservice.) \nx Coverage details \nx SAST - Static Application Security Testing \nx DAST - Dynamic Application Security Testing  \nx SCA - Software Composition Analysis  \nx Fuzzing/Dynamic \nx Penetration \nx Red team testing \nx Black box testing \nx QA security feature analysis \n\u0004  d \u0010  \n\u0007  d \u0016  \n\u0016\u0019  \n\u0016 y \u0016 g \n\u0015  \u0015  The reports can cover: \nx Security Scanning Results for Static, Dynamic, Soft ware \nComposition Analysis and Fuzzing  \nx Security Scanning Results for Penetration or Red-Te aming \nx Attestation to secure development/build/test practi ces \nx Mitigation against known software weakness classes in the \nCommon Weakness Enumeration (CWE) \nx Mitigation against publicly known vulnerabilities a nd Common \nVulnerabilities and Exposures (CVEs) \n\u0012\u0016  \u0015  \n\u0013  \u0007  \n  \u0004  \u000f  Attestation to secure open-source review process an d management \n\u0005 d \u000f x Attestation to the integrity of securely built prod ucts \nx Attestation to no known critical errors/warnings \nx Attestation to use of tool-chain defenses (stack ch ecking, ASLR, \netc.) \n\u0016 e \u0007  \n\u0005 d \u0006  \n\u000f  x Attestation to secure build environment \n\u0017\u0013  \u0016  \n\u0017\u0006  \u000f  x Attestation to secure build environment \nThe artifacts described in the table above may be u sed for attestation of the integrity of an \norganizations secure development process that was used to produce a given product. Organization \ncan then provide a high-level checklist, illustrate d below, which may utilize artifacts created during  \nthe development process that attest to the adherenc e, at some level, of the recommended practice \nduring the development process. The developer may a dd a brief description regarding how the \norganization supports a check list item in addition  to Yes/No/Not Applicable (NA)/Incomplete \n(Inc) response, e.g. alternative practices to suppo rt it and reasons for non-applicability.  \nThe document references in the following table are focused on the Supplier Section of the Guidance \nrelease. \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 28 \n \n \n\u0010  \u0012  \n\u0007   \u0013  \n\u0012  \n\u001c, \u0011 \n\u0011\u0004, \f \u0016\u0016\u0007\t  \n\u0017  \u0004  \b   \u0007  \u0015  \n\u0016  \u0013  \u0006   \u0010   \nDo you define policies that \nspecify risk-based software \narchitecture and design \nrequirements?  \u0013\u0012  Architecture/Design \nDocuments  \nDo you require team members \nto regularly participate in \nsecure software architecture, \ndesign, development, and \ntesting training and monitor \ntheir training completion?   \u0013\u0012  \n\u0015\u0019  Training Completion \nData/Statistics \nDeveloper Training \nCertificates  \nHave development team \nmembers attended training \nprograms specific to their \nroles, development tools and \nlanguages to update their \nskills?  \u0013\u0012  Training Completion \nData/Statistics  \nDeveloper Training \nCertificates  \nAt a minimum, for all critical \nsoftware components and \nexternal services that your \nteam operates and own, have \nyou completed the attack \nsurface survey and threat \nmodels for all such services?  \u0013\u001a 1 \n\u0013\u001a  Threat Model Results \nDocuments  2.3.5 Test Executable \nCode \nDo you have up to date threat \nmodels for all critical \ncomponents your team ships \nthat have been reviewed by a \nperson trained in software \nsecurity and do you make this \ndocument available to other \nteams that pick up your \ncomponent?  \u0013\u001a , \n\u0013\u001a  Threat Model Results \nDocument  2.3.5 Test Executable \nCode \nHas your team held a black-\nbox investigation for security?   Black box test results  \nDo you have and use security \ntools and methodology (e.g. \nrecommended by NISTIR \n8397) for static, dynamic and \nSoftware Composition Analysis  \u0013\u0012  SAST, DAST, SCA test \nresults 2.3.5 Test Executable \nCode \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 29 \n \n \nand ensure that all high \nseverity issues are addressed? \nDo you perform input fuzzing \nas part of a regular process for \nyour component or product's \ninputs?  \u0013\u001a  Fuzzing/Dynamic \ntest results 2.3.5 Test Executable \nCode \nDo you have security testing as \npart of your overall QA plan to \nenhance the testing of specific \nfeatures of your product?   Product test results 2.3.5 Test Executable \nCode \nHave your product or \ncomponents been identified as \nneeding penetration testing? If \nso, are all issues found \nrecorded in a bug tracker, with \nhigh priority defects set to \nprevent shipment of the \nproduct?   \u0013\u001a  Penetration Test \nResults  2.3.5 Test Executable \nCode \nHave your product or \ncomponents been identified as \nneeding red-team testing? If \nso, are all issues found \nrecorded in a bug tracker, with \nhigh priority defects set to \nprevent shipment of the \nproduct?    Red-Team Test \nResults  \nHave your product or \ncomponents been identified as \nneeding testing for security \ngaps by an external party? If \nso, has your code or systems \nbeen tested for security gaps \nby an external party (e.g. JFAC \nSoftware Assurance providers, \npen testing, threat model \nreviews, vulnerability scan \ntools and red-teams)?   Third-party Test \nResults 2.3.5 Test Executable \nCode \nDoes your release include an \nSBOM and confirmation that \nno unacceptable security \nvulnerabilities are pending, \nbinaries are digitally signed \nand meet cryptographic \nstandards?   SBOM \nProduct Bug \nTracking Report  \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 30 \n \n \nAre all public cloud resources \ncontinuously monitored by a \ntool that analyzes and alerts \nfor policy violations and \nanomalies?   Product Support / \nResponse Plan 2.4.1 Identify, analyze, \nand remediate \nvulnerabilities on a \ncontinuous basis \nAre the alerts being actively \nmonitored?   Product Support / \nResponse Plan  \nIs there a process in place to \nresolve policy violations \nwithin a specific amount of \ntime?   Product Support / \nResponse Plan 2.4.1 Identify, Analyze, \nand Remediate \nVulnerabilities on a \nContinuous Basis \n\u0007  \u0016 e \u0006  \nAre all your security issues \ntracked with a bug tracker and \nscored, for example using \nCVSSv3 scores to help \ndetermine fix prioritization \nand release scheduling?  \u0015\u0019  Secure Software \nDevelopment \nLifecycle Process \ndocument \nBug Tracker Report 2.2.3 Archive and \nProtect Each Software \nRelease \n2.3.5 Test Executable \nCode \nDo you use access-controlled \napplications to store sensitive \nvulnerability information for \nall issues affecting production \ncode that is more restrictive \nthan plain bug tracker defects?  \u0013\u0012  Secure Software \nDevelopment \nLifecycle Process \ndocument 2.2 Protect Software \n2.4.1 Identify, Analyze, \nand Remediate \nVulnerabilities on a \nContinuous Basis \nDoes your team have a process \nto reduce a class of \nvulnerabilities based on \npreviously identified \nvulnerabilities or attacks?  \u0013\u001a  Secure Software \nDevelopment \nLifecycle Process \ndocument 2.3.4 Review and/or \nAnalyze Human-\nReadable Code \nDo you perform nightly builds \nwith automated regression \nand security test to quickly \ndetect problems with recent \nbuilds?   Secure Software \nDevelopment \nLifecycle Process \ndocument  \nAre code check-ins gated by \ncode collaborators and source \ncontrol to prevent anyone \nfrom accidentally or \nintentionally submitting un-\nreviewed code changes?  \u0013\u001a  Secure Software \nDevelopment \nLifecycle Process \ndocument  \nDoes the team require code \nreviews for all code and build \nscripts / configuration \nchanges?  \u0013\u001a  Secure Software \nDevelopment \nLifecycle Process \ndocument  \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 31 \n \n \nDoes the team measure and \nanalyze the quality of the code \nreview process?   Secure Software \nDevelopment \nLifecycle Process \ndocument  \nDo you ensure only required \nmodules are included in the \nproduct and unused modules \nand code out of scope of the \nrequirements and design \ndocument are uninstalled or \nremoved, mitigating living-\noff-the-land attacks and \ndecreasing the attack surface?   Secure Software \nDevelopment \nLifecycle Process \ndocument \nRequirements \nDocument  \nDo you map all your security \nrequirements to the software \ncomponent of the product and \ntrack their \ncompletion/adherence?   Secure Software \nDevelopment \nLifecycle Process \ndocument \nSecurity \nRequirements \nDocument  \nAre unmodified third-party \nlibraries retrieved from a \ncommon location such as a \nsecured persistent storage or \nshared repository location out \nof band of the development \nprocess and not individually \nbuilt by your team?   Secure Software \nDevelopment \nLifecycle Process \ndocument  \nDo you monitor new \nvulnerabilities applicable to \nyour software e.g. using \nregistered vulnerability \nnotification services?  \u0015\u0019  Secure Software \nDevelopment \nLifecycle Process \ndocument  \nDo you have and adhere to \nresponsible disclosure \nrequirements for all externally \nidentified vulnerabilities?   Secure Software \nDevelopment \nLifecycle Process \ndocument  \nAre all your builds \ncontinuously built and tested?   Secure Software \nDevelopment \nLifecycle Process \ndocument  2.3.3 Configure the \nCompilation and Build \nProcess \nDoes a check-in immediately \ntrigger a build?   Secure Software \nDevelopment \nLifecycle Process \ndocument  2.3.3 Configure the \nCompilation and Build \nProcess \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 32 \n \n \nDoes a completed build \nautomatically go through some \nacceptance testing?   Secure Software \nDevelopment \nLifecycle Process \ndocument   \nIf the testing passes, is the \nbuild automatically deployed \nso others can consume it?  \u0013\u0012  Secure Software \nDevelopment \nLifecycle Process \ndocument   \n\u0019 y \u0017\u0013  \u0006  \nDo you track all third-party \ncomponents you use directly \nand all internal components in \na secure and persistent \nrepository?  \u0013\u0016  \n\u0013\u001a 1  Secure Software \nDevelopment \nLifecycle Process \ndocument \nOSRB Approved List \nProduct/Component \nScan Results   \nDo you have the requirement \nfor an Open-Source Review \nBoard to approve third-party \nlibraries included in a product \nand audit approved third-\nparty libraries for version \nadherence and vulnerabilities?  \u0013\u001a  \n\u0013\u001a  Secure Software \nDevelopment \nLifecycle Process \ndocument \nOSRB Approved List  \nDo you remove or mitigate \ncritical known vulnerabilities \nor end of life issues of third-\nparty components before each \nrelease?  \u0013\u001a  Secure Software \nDevelopment \nLifecycle Process \ndocument \nOSRB Approved List 2.2.2 Provide a \nMechanism for \nVerifying Software \nRelease Integrity \n2.3.2 Verify Third-Party \nSoftware Complies with \nSecurity Requirements \nWhen considering the \nselection of a third-party \ncomponent, do use a known \nand trusted supplier that has a \nproven record for secure \ncoding practices and quality \ndelivery of their components?  \u0013\u0012  Secure Software \nDevelopment \nLifecycle Process \ndocument \nOSRB Approved List  \nWithin a developer \nenvironment, do you monitor \nand approve of all IDEs and \nthird-party \ndevelopment/debugging \nextension to ensure their \nadoption does not weaken the   Secure Software \nDevelopment \nLifecycle Process \ndocument  \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 33 \n \n \nsecurity posture of the local \ndevelopment environment? \nDo you have a trusted \nrepository to support ongoing \nsoftware composition analysis \nand security testing for all \nexternal and downloaded \nmodules?   Secure Software \nDevelopment \nLifecycle Process \ndocument  \n\u000b   \u0005 d \b  \nHave you completed attack \nsurface investigation and \nthreat modeling for your build \nenvironment?   Threat/Risks Model \nResults Documents  \nDo you ensure that only in \nvery rare cases, the build \nprocess accesses the open \nInternet and these cases are \ndocumented and approved \nwithin the security plan?  \u0013\u0012  Secure Software \nDevelopment \nLifecycle Process \ndocument  \nDo you limit and secure access \nto your development \nenvironment to essential \nadministrators?   Secure Software \nDevelopment \nLifecycle Process \ndocument  \nDo you monitor the build chain \nfor unauthorized access and \nmodifications?   Secure Software \nDevelopment \nLifecycle Process \ndocument  \nDo you document approval \nand audit logs of build chain \nmodifications?   Secure Software \nDevelopment \nLifecycle Process \ndocument  \nDo you enforce build-chain \nconfiguration defensive \ntechniques required to narrow \nthe attack vectors of the \ncomponents and products \nbeing developed?   Secure Software \nDevelopment \nLifecycle Process \ndocument \nBuild Logs  \nDo you ensure the integrity of \nthe individual development \nenvironment, caring to harden \nthe development systems \nwithin the build pipeline?   Secure Software \nDevelopment \nLifecycle Process \ndocument  \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 34 \n \n \nDoes your build process \nencrypt data in transit?   Secure Software \nDevelopment \nLifecycle Process \ndocument 2.2.1 Protect all Forms \nof Code from \nUnauthorized Access \n2.3.6 Configure the \nSoftware to have Secure \nSettings by Default \nDoes each critical server \nwithin the build chain owned \nby the team have a clearly \ndefined owner responsible for \npatch maintenance?  \u0013\u0012  Secure Software \nDevelopment \nLifecycle Process \ndocument  2.2.1 Protect all Forms \nof Code from \nUnauthorized Access \nDo you have a requirement \nthat server patch levels are \nchecked periodically?   Secure Software \nDevelopment \nLifecycle Process \ndocument   \nIs unnecessary outbound \ninternet connectivity blocked?  \u0013\u0012  Secure Software \nDevelopment \nLifecycle Process \ndocument   \nIs unnecessary inbound \ninternet connectivity blocked?  \u0013\u0012  Secure Software \nDevelopment \nLifecycle Process \ndocument   \nIs the integrity of the builds \nverified to ensure no malicious \nchanges have occurred during \nthe build and packaging \nprocess, for example, are two \nor more builds performed in \ndifferent protected \nenvironments and the results \ncompared to ensure the \nintegrity of the build process?   Secure Software \nDevelopment \nLifecycle Process \ndocument   \nDo you use the toolchain to \nautomatically gather \ninformation that informs \nsecurity decision-making?  \u0013  Secure Software \nDevelopment \nLifecycle Process \ndocument  2.3.3 Configure the \nCompilation and Build \nProcess \nDoes the tool chain \nautomatically scan for \nvulnerabilities and stop the \nbuild process and report \nerrors when detected, if so \nconfigured?  \u0013\u0016  \n\u0013\u001a  Secure Software \nDevelopment \nLifecycle Process \ndocument  2.4.1 Identify, Analyze, \nand Remediate \nVulnerabilities on a \nContinuous Basis \nDo you store access \ncredentials (e.g. hashes for     \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 35 \n \n \n \n  passwords) and secrets in a \nsecure (e.g. encrypted) \nlocation such as a secure vault? \n\u0016 e \u0006 e \u0007  \nDo you perform binary \ncomposition analysis of the \nfinal package?   Secure Software \nDevelopment \nLifecycle Process \ndocument   \nDo you have a Software Bill of \nMaterials (SBOM) that satisfies \nthe contracts?  \u0013\u0016  \n\u0013\u001a    \nDo you digitally sign all \nrequired binaries you ship?  \u0013\u0016  \n\u0013\u0016  Secure Software \nDevelopment \nLifecycle Process \ndocument   \nDo you ensure that globally-\ntrusted certificates are not \ndirectly accessible and use a \ndedicated, protected signing \nserver when signing is \nrequired?   Secure Software \nDevelopment \nLifecycle Process \ndocument  2.2.2 Provide a \nMechanism for \nVerifying Software \nRelease Integrity  \nAre you using organization \napproved Configuration \nManagement tools to sign your \nshipping binaries?   Secure Software \nDevelopment \nLifecycle Process \ndocument 2.2.2 Provide a \nMechanism for \nVerifying Software \nRelease Integrity \nDo you comply with the use of \ncryptography recommended \nby organizations security \npolicy?  \u0013\u0016  Secure Software \nDevelopment \nLifecycle Process \ndocument   \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 36 \n \n \n \u0004  \b \f ve \u0015  \n\u0004  \u0007  \u0011  \n\u0004\u0006\u0010  Communications of the ACM  17, The Protection of Information in Computer \nSystems . Available at \n(http://web.mit.edu/Saltzer/www/publications/protec tion/index.html) \n\u0005\u0016\u0004  BSA (2019) Framework for Secure Software. Available  at \n(https://www.bsa.org/reports/bsa-framework-for-secu re-software) \n\u0005\u0016\f\u0010\u0010  Migues S, Steven J, Ware M (2019) Building Security  in Maturity Model (BSIMM) \nVersion 10. Available at (https://www.bsimm.com/dow nload/)  \n\u0006\f\u0016\u0004  Cybersecurity & Infrastructure Security Agency. Ava ilable at \n(https://www.cisa.gov/defining-insider-threats)  \n\u0006\f\u0016\u0006\u0012\u0016\u0007\u000f\u0006  Cisco. 2021. Cisco Secure Development Lifecycle. Av ailable at \n(https://www.cisco.com/c/dam/en_us/about/doing_busi ness/trust-\ncenter/docs/cisco-secure-development-lifecycle.pdf)  \n\b\u0012  EOP. 2021. Improving the Nations Cybersecurity, Executive Order 14028, 86 \nFR 26633, Document number 2021- 10460. Available at  \n(https://www.whitehouse.gov/briefing-room/president ial-\nactions/2021/05/12/executive-order-on-improving-the -nations-\ncybersecurity/) \n\t\f\u0013\u0016  National Institute of Standards and Technology. 201 9. Security Requirements \nfor Cryptographic Modules. Available at \n(https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.1 40-3.pdf ). \n\f\u0007\u0004\u0016\u0012\u0004\u0015  Hong Fong EK, Wheeler D, Henninger A (2016) State-o f-the-Art Resources \n(SOAR) for Software Vulnerability Detection, Test, and Evaluation 2016. \n(Institute for Defense Analyses [IDA], Alexandria, VA), IDA Paper P-8005. \nAvailable at (https://www.ida.org/research-and-\npublications/publications/all/s/st/stateoftheartres ources-soar-for-software-\nvulnerability-detection-test-and-evaluation-2016) \n\f\u0011\u0017\b\u000f  Intel. Software Supply Chain Threats; A White Paper  \n\f\u0016\u0012  International Organization for Standardization/Inte rnational Electrotechnical \nCommission (ISO/IEC), Information technology  Secur ity techniques  \nApplication security  Part 1: Overview and concepts , ISO/IEC 27034-1:2011, \n2011. Available at (https://www.iso.org/standard/44 378.html) \n\u0010\f\u0017\u0015\b\u0006\u0004\u0013\b\u0006  MITRE. 2021. Common Attack Pattern Enumeration and Classification. Available \nat (https://capec.mitre.org/data/definitions/437.ht ml) \n\u0010\f\u0017\u0015\b\u0006\u0019\b  MITRE. 2021. Common Vulnerability and Exposure, CV E. 2021. Available at \n(https://cve.mitre.org/index.html). \n\u0010\u0016\u0016\u0007\u000f  Microsoft (2019) Security Development Lifecycle. Av ailable at \nhttps://www.microsoft.com/en-us/sdl \n\u0011\u0004\u0016\u0004\u0016\u0017\u0007  National Aeronautics and Space Administration. 2021 . SOFTWARE ASSURANCE \nAND SOFTWARE SAFETY STANDARD, NASA-STD-8739.8A. Av ailable at \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 37 \n \n \n(https://standards.nasa.gov/sites/default/files/sta ndards/NASA/PUBLISHED/A\n1/nasa-std-8739.8a.pdf). \n\u0011\f\u0006\u0006\u0016  National Initiative for Cybersecurity Careers and S tudies, National Initiative for \nCybersecurity Education. 2021 Workforce Framework f or Cybersecurity (NICE \nFramework). Available at (https://niccs.cisa.gov/wo rkforce-\ndevelopment/cyber-security-workforce-framework) \n\u0011\f\u0016\u0017\u0006\u0016\t  National Institute of Standards and Technology. 201 8. Framework for \nImproving Critical Infrastructure Cybersecurity, Ve rsion 1.1. Available at \n(https://doi.org/10.6028/NIST.CSWP.04162018) \n\u0011\f\u0016\u0017\u0010\u0016\u0007\u0019  National Institute of Standards and Technology. 201 8. Guidelines on Minimum \nStandards for Developer Verification of Software. available at \n(https://www.nist.gov/system/files/documents/2021/0 7/13/Developer%20Ve\nrification%20of%20Software.pdf) \n\u0011\u0017\f\u0004\u0016\u0005\u0012\u0010  National Telecommunications and Information Adminis tration. 2021. The \nMinimum Elements for a Software Bill of Materials ( SBOM). Available at \n(https://www.ntia.doc.gov/report/2021/minimum-eleme nts-software-bill-\nmaterials-sbom) \n\u0011\u0019\u0007  National Vulnerability Database. Available at (http s://www.nist.gov/programs-\nprojects/national-vulnerability-database-nvd) \n\u0012\u001a\u0004\u0016\u0013\u0004\u0016\u0019\u0016  Open Web Application Security Project (2019) OWASP Application Security \nVerification Standard 4.0. Available at https://git hub.com/OWASP/ASVS \n\u0012\u001a\u0004\u0016\u0013\u0016\u0004\u0010\u0010  Open Web Application Security Project (2017) Softwa re Assurance Maturity \nModel Version 1.5. Available at \n(https://www.owasp.org/index.php/OWASP_SAMM_Project )  \n\u0012\u001a\u0004\u0016\u0013\u0016\u0006\u0019\u0016  OWASP. 2021. OWASP Software Component Verification  Standard. Retrieved \nSep. 25, 2021 (https://owasp.org/www-project-softwa re-component-\nverification-standard/). \n\u0012\u001a\u0004\u0016\u0013\u0017\b\u0016\u0017  Open Web Application Security Project (2014) OWASP Testing Guide 4.0. \nAvailable at https://www.owasp.org/images/1/19/OTGv 4.pdf \n\u0013\u0006\f\u0016\u0016\u000f\u0015\u0004\u0013  Payment Card Industry (PCI) Security Standards Coun cil (2019) Secure Software \nLifecycle (Secure SLC) Requirements and Assessment Procedures Version 1.0. \nAvailable at \n(https://www.pcisecuritystandards.org/document_libr ary?category=sware_sec\n#results) \n\u0016\u0006\u0004\n\f\u000f\b  Software Assurance Forum for Excellence in Code (20 12) Practical Security \nStories and Security Tasks for Agile Development En vironments. Available at \n(http://www.safecode.org/publication/SAFECode_Agile _Dev_Security0712.pdf) \n\u0016\u0006\t\u0013\u0016\u0016\u0007  Software Assurance Forum for Excellence in Code (20 18) Fundamental Practices \nfor Secure Software Development: Essential Elements  of a Secure Development \nLifecycle Program, Third Edition. Available at (htt ps://safecode.org/wpcontent/ \nuploads/2018/03/SAFECode_Fundamental_Practices_for_ Secure_Software_Dev \nelopment_March_2018.pdf) \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 38 \n \n \n\u0016\u0006\u0016\f\u0006  Software Assurance Forum for Excellence in Code (20 10) Software Integrity \nControls: An Assurance-Based Approach to Minimizing  Risks in the Software \nSupply Chain. Available at \n(http://www.safecode.org/publication/SAFECode_Softw are_Integrity_Controls0\n610.pdf) \n\u0016\u0006\u0017\u0013\u0006  Software Assurance Forum for Excellence in Code (20 17) Managing Security \nRisks Inherent in the Use of Third-Party Components . Available at \n(https://www.safecode.org/wpcontent/uploads/2017/05 /SAFECode_TPC_Whit\nepaper.pdf) \n\u0016\u0006\u0017\u0017\u0010  Software Assurance Forum for Excellence in Code (20 17) Tactical Threat \nModeling. Available at \n(https://www.safecode.org/wpcontent/uploads/2017/05 /SAFECode_TM_White\npaper.pdf) \n\u0016\u000f\u0016\u0004  The Linux Foundation. 2021. Improving artifact int egrity across the supply \nchain  SLSA. Available at (https://slsa.dev/) \n\u0016\u0013  National Institute of Standards and Technology. 202 1. PRE-DRAFT Call for \nComments: Building a Cybersecurity and Privacy Awar eness and Training \nProgram, SPS 800-50 Rev 1. Available at \n(https://csrc.nist.gov/publications/detail/sp/800-5 0/rev-1/draft). Retrieved \nSep. 25, 2021. \n\u0016\u0013  National Institute of Standards and Technology. 202 0. Guidelines for the \nSelection, Configuration, and Use of Transport Laye r Security (TLS) \nImplementations, SP 800-52 Rev. 2. Available at \n(https://csrc.nist.gov/publications/detail/sp/800-5 2/rev-2/final). \n\u0016\u0013  National Institute of Standards and Technology. 202 0. Security and Privacy \nControls for \n\u0016\u0013  National Institute of Standards and Technology. 202 0. Recommendation for Key \nManagement: Part 1  General, SP 800-57 Part 1 Rev. 5. Available at \n(https://csrc.nist.gov/publications/detail/sp/800-5 7-part-1/rev-5/final) \n\u0016\u0013  National Institute of Standards and Technology. 201 8. Systems Security \nEngineering. Available at (https://doi.org/10.6028 /NIST.SP.800-160v1) \n\u0016\u0013  \"National Institute of Standards and Technology. 20 21. \"\"Supply Chain Risk \nManagement Practices for Federal Information System s and Organizations.\"\" \nAvailable at \n(https://nvlpubs.nist.gov/nistpubs/SpecialPublicati ons/NIST.SP.800-161.pdf)\" \n\u0016\u0013  Enhanced Security Requirements for Protecting Cont rolled Unclassified \nInformation: A Supplement to NIST Special Publicati on 800-171. Available at \n(https://nvlpubs.nist.gov/nistpubs/SpecialPublicatio ns/NIST.SP.800-172.pdf ) \n\u0016\u0013\u0005  National Institute of Standards and Technology. 202 0. Guideline for Using \nCryptographic Standards in the Federal Government: Cryptographic \nMechanisms. SP 800-175B Rev. 1. Available at \n(https://csrc.nist.gov/publications/detail/sp/800-1 75b/rev-1/final). \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 39 \n \n \n\u0016\u0013  National Institute of Standards and Technology, Nat ional Initiative for \nCybersecurity Education. 2020. Workforce Framework  for Cybersecurity (NICE \nFramework). Available at \n(https://nvlpubs.nist.gov/nistpubs/SpecialPublicati ons/NIST.SP.800-181r1.pdf) \n\u0016\u0013  National Institute of Standards and Technology. 201 8. Platform Firmware \nResiliency Guidelines, SP-800-193. Available at \n(https://csrc.nist.gov/publications/detail/sp/800-1 93/final). \n\u0016\u0013  National Institute of Standards and Technology. 202 0. Zero-Trust Architecture, \nSP-800-207. \nhttps://nvlpubs.nist.gov/nistpubs/SpecialPublicatio ns/NIST.SP.800-207.pdf \n\u0016\u0016\u0007\t  National Institute of Standards and Technology. 202 0. Mitigating the Risk of \nSoftware Vulnerabilities by Adopting a Secure Softw are Development \nFramework (SSDF). Available at \n(https://nvlpubs.nist.gov/nistpubs/CSWP/NIST.CSWP.0 4232020.pdf)  \n\u0016\u001a\b\u0005\u0012\u000e  IEEE Computer Society. 2014. Guide to the Software Engineering Body of \nKnowledge. Available at (https://www.computer.org/e ducation/bodies-of-\nknowledge/software-engineering/v3) \n\u0016\u001c\u0011\u0012\u0013\u0016\u001c\u0016  Synopsys. 2021. Synopsys Information Security Requ irements for Vendors. \nAvailable at https://www.synopsys.com/company/legal /info-security.html \n\u001d\u0007\u0011\b\u0017  IBM, ZDNET. 2021. Managing a Software as a Vendor Relationship: Best \nPractices. Available at (https://www.zdnet.com/art icle/managing-a-software-\nas-a-service-vendor-relationship-best-practices/) \n  \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 40 \n \n \n \u0004  \t \u0004 s  \n\u0004  \u0010  \n\u0004\u0016\u000f\u0015  Address Space Layout Randomization \n\u0006\f\u0006\u0007  Continuous Integration/Continuous Delivery \n\u0006\u0011\u0016\u0016\f  Committee on National Security Systems Instruction  \n\u0006\u0019\u0016\u0016  Common Vulnerability Scoring System \n\u0006\u0019\b  Common Vulnerabilities and Exposures \n\u0006\u001a\b  Common Weakness Enumeration \n\u0007\u0004\u0016\u0017  Dynamic Application Security Testing \n\u0007\u000f\u0013  Data Loss Prevention \n\b\u0012 Executive Order \n\b\u0012\u000f  End of Life \n\t\u0015\u0004\u0010\u0013  Federal Risk and Authorization Management Program \n\t\f\u0013\u0016  Federal Information Process Standards \n\u000b\f\u0013\u0004\u0004  Health Insurance Portability and Accountability Act  \n\u000b\u0016\u0010  Hardware Security Module \n\u000b\u0017\u0017\u0013\u0016  Hypertext Transfer Protocol (Secure) \n\u0010\t\u0004  Multi Factor Authentication \n\u0011\u0007\u0004  Non-Disclosure Agreement  \n\u0011\f\u0016\u0017  National Institute of Standards and Technology  \n\u0011\u0017\f\u0004  National Telecommunications and Information Adminis tration \n\u0012\u0016\u0015\u0005  Open-Source Review Board \n\u0012\u001a\u0004\u0016\u0013  Open Web Application Security Project \n\u0013\u0012 Prepare Organization \n\u0013\u0016 Protect Software \n\u0013\u0016\f\u0015\u0017  Product Security Incident Response Team \n\u0013\u001a Produce Well-Secured Software \n\u0014A Quality Assurance \n\u0015\u0004\u0006\f  Responsible, Accountable, Consulted, and Informed \n\u0015\u0005\u0004\u0006  Role-Based Access Control \n\u0015\u0010 Risk Management \n\u0015\u0019 Respond to Vulnerabilities \n\u0016\u0016  Software-as-a-Service \n\u0016\u0004\u0016\u0017  Static Application Security Testing \n\u0016\u0005\u0012\u0010  Software Bill of Material \n\u0016\u0006\u0004  Software Composition Analysis \n\n \nSecuring the Software Supply Chain: Recommended Pra ctices for Suppliers 41 \n \n \n\u0016\u0006\u0010  Supply Chain Management \n\u0016\u0006\u0010  Source Code Management \n\u0016\u0006\u0015\u0010  Supply Chain Risk Management \n\u0016\u0006\u0019\u0016  Software Component Verification Standard \n\u0016\u0007\u000f\u0006  Software Development Lifecycle \n\u0016\u000f\u0016\u0004  Supply-chain Levels for Software Artifacts \n\u0016\u0016\u0007\t  Secure Software Development Framework \n\u0017\u000f\u0016  Transport Layer Security \n\u0019\u0006\u0016  Version Control System \n\u0019\u0010 Virtual Machine \n\u0019\u0013\u0011  Virtual Private Network \n \n\n",
  "cves": [],
  "techniques": [],
  "advisory": "cybersecurity-alerts",
  "title": "securing_the_software_supply_chain_suppliers",
  "source": "nsa",
  "id": "b98434102718bae26ed9a7c771f88aef76968386da8256f3c7f413e4276cb367"
}